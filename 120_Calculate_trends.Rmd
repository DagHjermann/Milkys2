---
title: "120 Calculate time trends"
output: html_document
---

Note: Ca 35 minutes run time for running all trends    

This procedure uses data from script 110 and creates creates two data.frames: 120_result_10yr and 120_result_long  
  
Note: If you want to add or replace a few time series, and don't want to run this for 35 minutes:    
- go to the "SPECIAL" part below  
- set add_extra_series to TRUE  
- modify the filtering of df_series  
- the "save data" section will then automatically add the new series to the existing time trends  
  
## 1. Libraries and functions  
```{r, results='hide', message=FALSE, warning=FALSE}

library(dplyr)
library(purrr)
library(lubridate)
library(openxlsx)
library(mgcv)
library(AICcmodavg)   # AICc()
library(ggplot2)
source("001_Add_trends_functions.R")  # Copied from '16_Trend_functions.R' in Milkys_2018

#
# Define a couple of extra functions for shortening code
#
get_stats <- function(df){
  calc_models_one_station2(df, gam = TRUE, log = TRUE)$statistics_for_file
}

model_from_medians_stat <- function(...)
  model_from_medians(...)$statistics

```

## 2. Read data  

### a. Medians per year   
made in script 110  
```{r}
# Medians
# Read and reformat the most recent data (by default)  
files <- dir("Data", pattern = "110_mediandata_updated") %>% rev()

cat("Reading the last file downloaded:")
cat("\n", files[1])
cat("\n")
cat("If you want to read a different file, replace 'files[1]' with the file you want")
cat("\n")

filename <- files[1] 
data_med <- readRDS(paste0("Data/", filename)) %>%
  rename(Proref_median = Median,
         Median = Value) 

# We save the date part of the text (e.g., '2020-04-23')
# This will be used in part 10, when we save the resulting file
file_date <- substr(filename, 24, 33)    # pick out the part of the text from character no. 17 to no. 26

```

### b. Substance groups
```{r}

df_substancegroups <- read.xlsx("Input_data/Lookup table - substance groups.xlsx")

```

### c. Select substances   
```{r}
sel <- with(df_substancegroups,
            !is.na(Parameter_group) &
              Parameter_group != "Dioxins" & 
              (Parameter_group != "TBT (tinnorganisk)" | PARAM == "TBT")
)
pars <- df_substancegroups$PARAM[sel]

#
# Check if we have all sum variables (we don't) 
#
# c("CB_S7", "BDE6S", "P_S", "PFAS", "HBCDD", "BDESS", "PAH16", "KPAH", "DDTEP") %in% pars
# [1] FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE  TRUE

# Add sum variables and VDSI/Intersex
pars <- c(pars, c("CB_S7", "BDE6S", "PFAS", "HBCDD", "BDESS", "VDSI/Intersex", "TPTIN"))

```

## 3. Test - a single series     
Just one example of the output of `model_from_medians()`   
The output includes  
- N = number of years with data  
- Nplus = number of years with median > LOQ   
- p_linear and p_nonlinear = p-values for linear and non-linear (GAM) regression   
- AICc - "model goodness". AIC decreases when the model fits the data better, but is "punished" by model complexity (non-linear is more complex than linear).
The AICc decides whether we use the linear or the non-linear model.   
- Lin_slope = slope of theh linear model (the non-linear has no fixed slope)    
- Lin_yr1 and Lin_yr2 - the value of the linear model at the start and end of the time series  
- Nonlin_yr1 and Nonlin_yr2 - the value of the non-linear model at the start and end of the time series   
- Over_LOQ_yr2 - whether Lin_yr2/Nonlin_yr2 is above LOQ   
- Model_used:  
    - Mean - if Nplus = 2,3 or 4 and N >= 3   
    - Nonlinear - if Nplus >= 7 and AICc_nonlin < AICc_lin  
    - Linear - otherwise  
- P_change: p_linear and p_nonlinear, depending on Model_used   
```{r}

model_from_medians("TBT", "Nucella lapillus", "Whole soft body", "227G1", "DW", 1980:2018, data_med)$statistics

# Some other examples:  
if (FALSE){
  model_from_medians("HG", "Gadus morhua", "Muskel", "30B", "DW", 1980:2018, data_med)$statistics
  model_from_medians("HG", "Gadus morhua", "Muskel", "30B", "WW", 2009:2018, data_med)$statistics
  model_from_medians("CB_S7", "Gadus morhua", "Lever", "30B", "WW", 2009:2018, data_med)$statistics
  model_from_medians("TBT", "N. lapillus / L. littorea", "Whole soft body", "71G", "WW", 2009:2018, data_med)$statistics
  model_from_medians("VDSI/Intersex", "N. lapillus / L. littorea", "Whole soft body", "71G", "WW", 1980:2018, data_med)$statistics
}

```

## 4. Prepare analysis  
  
### a. Prepare **df_series**  
df_series contains one line for each series we want to analyse with time series analysis  
```{r}

df <- data_med %>%
  filter(!is.na(Median) & PARAM %in% pars)

# xtabs(~Basis, df)

# filter(!is.na(Median) & PARAM %in% pars & Basis %in% c("WW"))

## Make df_series ----
#  Based on df

lastyear <- 2017   # The series must last at least until this year    
                   # Series without data in any of the three last years will be excluded

df_series <- df %>%
  filter(Basis %in% c("WW","WWa","DW","DWa","FB","FBa")) %>%
  group_by(STATION_CODE, LATIN_NAME, TISSUE_NAME, PARAM, UNIT, Basis) %>%
  summarise(No_of_years = n(), Last_year = max(MYEAR)) %>%
  filter(No_of_years >= 4 & Last_year >= lastyear) %>%
  ungroup()

cat("Number of series:", nrow(df_series), "\n")

```

### b. Test the entire procedure  
For 20 random series   
```{r}

# Pick 20 random series
df_series_random <- df_series %>% 
  sample_n(20)        # 20 random series
  
# Turn into list
args <- df_series_random[1:100,] %>% 
  as.list()
# names(args) 

# Change names of the list objects, so they fit with input names of 'model_from_medians'
names(args) <- sub("STATION_CODE", "station", names(args))
names(args) <- sub("PARAM", "param", names(args))
names(args) <- sub("LATIN_NAME", "species", names(args))
names(args) <- sub("TISSUE_NAME", "tissue", names(args))
names(args) <- sub("Basis", "basis", names(args))

# Pick the list objects we need
args <- args[c("station", "tissue", "species", "param", "basis")]

# FOR DEBUGGING ONLY:
# debugonce(model_from_medians)  
# debugonce(calc_models_one_station2)
# debugonce(calc_models_gam)
# debugonce(GAM_trend_analysis)
# debugonce(statistics_for_excel)

# Turn off error messages if you want
# old_options <- options(show.error.messages = FALSE, warn = -1)

# Run models
result_list_10yr <- args %>% pmap(model_from_medians_stat, 
                                  yrs = 2010:2019, data_medians = data_med)
result_list_long <- args %>% pmap(model_from_medians_stat, 
                                  yrs = 1980:2019, data_medians = data_med)

# Turn error messages on again
# options(old_options)

# Combine lists to data frames
result_10yr <- bind_rows(result_list_10yr)
result_long <- bind_rows(result_list_long)

```

### c. SPECIAL: add or updatetrends for one/a few parameters/stations   
Calculate trends for just a few selected series, and add them to the existing trend data sets (result_10yr and result_long)   
In order to do this:  
- set 'add_extra_series' in this chunk to TRUE    
- then modify the code so df_series contains only the series you want to add   -
- the rest of the code won't have to be changed - the latest trend data sets will be updated with the new data  
- remember to change add_extra_series back to `FALSE` afterwards    
For the ordinary case (where you want to analyse all time series), i.e., when add_extra_series = FALSE, just run the chunk below   

```{r}
# Set 'add_extra_series' to TRUE if you want to add just add a few trends to existing trends
#   or if you want to replace a few trends
# (Will also be used futher below, in the 'save' part)

add_extra_series <- FALSE


#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o
#
# Note: if 'add_extra_series' is (correctly) set to TRUE, the 'save results' part
#   will automatically read the existing (last saved) trends, add new ones, 
#   and re-save the trends. If the new series made her overlap with old ones, 
#   the old ones will be deleted before the new ones are added, avoiding duplication
#
#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o#o


# Change the filter below in order to calculate trends for just selected series
# I.e., we shorten df_series drastically
#
# FILTERING EXAMPLES - insert where it says "Filter df_series" (repce everything between "start" and "end")

# 
if (add_extra_series){
  
  cat("Original number of time series:\n")
  cat("  ", nrow(df_series), "\n")
  
  #
  # Filter df_series START
  # 
  
  # Example: we want to add 'TPTIN' to existing trends  
  # We filter df_series to get 'TPTIN' only:
  df_series <- df_series %>% 
    filter(PARAM %in% "TPTIN") 

  #
  # Filter df_series END
  # 

  cat("Number of time series after filtering df_series:\n")
  cat("  ", nrow(df_series), "\n")
} 



```

## 5. Analyse all time series    
  
### Prepare 'args' list    
```{r}

args <- df_series %>% 
  as.list()
# names(args) 

# Change names of the list objects, so they fit with input names of 'model_from_medians'
names(args) <- sub("STATION_CODE", "station", names(args))
names(args) <- sub("PARAM", "param", names(args))
names(args) <- sub("LATIN_NAME", "species", names(args))
names(args) <- sub("TISSUE_NAME", "tissue", names(args))
names(args) <- sub("Basis", "basis", names(args))
args <- args[c("station", "tissue", "species", "param", "basis")]

```


### Calculation procedure   
  
**NOTE: This takes ca. 35 minutes**    
  
```{r}

# Turn 'model_from_medians_stat' into a 'safe' function
#   The new function 'model_from_medians_stat_s' returns a list with two elements,
#     "result" and "error"
#   If the function works, "result" contains the normal output and "error" is NULL
#   If the function fails, "result" is NULL and "error" contains the error message
model_from_medians_stat_s <- safely(model_from_medians_stat)

# Example
# X <- model_from_medians_stat_s("TBT", "Nucella lapillus", "Whole soft body", "227G1", "DW", 1980:2018, data_med)
# X$result
# X$error

#
#o#o#o#o#o#o Calculation procedure starts #o#o#o#o#o#o
#

t0 <- Sys.time()                                                            # Start time for procedure
zz <- file("Messages from script 120 (can be deleted).txt", open = "wt")    # File for error messages

sink(zz, type = "message")             # Redirect error/warning messages 
                                       # - error messages  will be sent to the temp.txt file 

result_list_10yr <- args %>% pmap(model_from_medians_stat_s, 
                                  yrs = 2010:2019, data_medians = data_med)  # ca 15-20 minutes
result_list_long <- args %>% pmap(model_from_medians_stat_s, 
                                  yrs = 1980:2019, data_medians = data_med)  # ca 15-20 minutes

sink()                                 # Turn off redirection of messages   

Sys.time() - t0  # Print time used - 36.55274 minutes last time  

```

### Change output into data frames   

```{r}

# Transpose lists
# 'result_list_10yr' is a list of some 1000 elements, where each element
#    is a list with $result and $error
# We turn this to a list 2 elements: $result and $error, each with some 1000 elements  
result_list_10yr_t <- purrr::transpose(result_list_10yr)
result_list_long_t <- purrr::transpose(result_list_long)

# Combine list 1 to data frame

no_error <- result_list_10yr_t$error %>% map_lgl(is.null)
result_10yr <- bind_rows(result_list_10yr_t$result[no_error])

# Combine list 2 to data frame
no_error <- result_list_long_t$error %>% map_lgl(is.null)
result_long <- bind_rows(result_list_long_t$result[no_error])

```


## 6. Save or update the result file    

```{r}

if (!add_extra_series){   # this is the normal case - we have calculated trends for all series

  fn1 <- paste0("120_result_10yr_", file_date, ".rds")
  fn2 <- paste0("120_result_long_", file_date, ".rds")
  
  saveRDS(result_10yr, paste0("Data/", fn1))
  saveRDS(result_long, paste0("Data/", fn2))
  
  cat("Results saved as \n")
  cat(" ", fn1, "\n")
  cat(" ", fn2, "\n")
  cat("in folder 'Data'")
                  
} else if (add_extra_series){  # the case where we will update case - we have calculated trends for all series

  #
  # Will be run only if we are adding series to existing (saved) series 
  #   ('original' below), or replacing existing series 
  #
  # Regarding file names, there are two scenarios:
  #
  # 1) The existing file was made with data from e.g. January 1st ("120_result_10yr_2020-01-01.rds")
  #    The extra series were made  with data from e.g. January 5st 
  #    -> The updated file of time trends will be named "120_result_10yr_2020-01-05.rds"
  #
  # 2) The existing file was made with data from e.g. January 1st ("120_result_10yr_2020-01-01.rds")
  #    The extra series were made with data from the same date (original data updated the same day, or more parameters added) 
  #    -> The old file of time trends will be renamed "120_result_10yr_2020-01-01_OLD.rds"
  #    -> The updated file of time trends will be named "120_result_10yr_2020-01-01.rds"
  #

  # Find newest existing
  fn_existing_1 <- dir("Data", pattern = "120_result_10yr_") %>% tail(1)
  fn_existing_2 <- dir("Data", pattern = "120_result_long_") %>% tail(1)
  
  # Date
  date_existing_1 <- substr(fn_existing_1, 17, 26)
  date_existing_2 <- substr(fn_existing_2, 17, 26)
  
  # Read saved 10 year series...
  result_10yr_original <- readRDS(paste0("Data/", fn_existing_1)) %>%
    # Remove all series already present in result_10yr:
    safe_anti_join(result_10yr, 
                   by = c("STATION_CODE", "PARAM", "LATIN_NAME", "TISSUE_NAME", "Basis"),
                   check = "BCUV")

  # Read saved 'long' series...
  result_long_original <- readRDS(paste0("Data/", fn_existing_2)) %>%
    # Remove all series already present in result_long:
    safe_anti_join(flag_replace_long, 
                 by = c("STATION_CODE", "PARAM", "LATIN_NAME", "TISSUE_NAME", "Basis"),
                 check = "BCV")
  
  # Add the newly made series
  result_10yr <- bind_rows(result_10yr_original, result_10yr)
  result_long <- bind_rows(result_long_original, result_long)
  
  # Check that series are unique
  check1 <- result_long_original %>%
    count(STATION_CODE, PARAM, LATIN_NAME, TISSUE_NAME, Basis) %>%
    filter(n > 1) %>%
    nrow()

  check2 <- result_10yr_original %>%
    count(STATION_CODE, PARAM, LATIN_NAME, TISSUE_NAME, Basis) %>%
    filter(n > 1) %>%
    nrow()

  if (check1 == 0 & check2 == 0){
    cat("Series are unique\n")
  } else {
    cat("WARNING: Series are not unique!\n")
  }
  
  # Filenames that will be used for saving data
  fn1 <- paste0("120_result_10yr_", file_date, ".rds")
  fn2 <- paste0("120_result_long_", file_date, ".rds")
  
  # If the saved data already exists, we will make a backup named "_OLD"
  #   before overwriting the file (case 2 above)
  if (date_existing_1 == file_date){
    fn1_old <- paste0("120_result_10yr_", file_date, "_OLD.rds")
    file.copy(paste0("Data/", fn1), paste0("Data/", fn1_old))
  }
  if (date_existing_2 == file_date){
    fn2_old <- paste0("120_result_long_", file_date, "_OLD.rds")
    file.copy(paste0("Data/", fn2), paste0("Data/", fn2_old))
  }
  
  saveRDS(result_10yr, paste0("Data/", fn1, ".rds"))
  saveRDS(result_long, paste0("Data/", fn2, ".rds"))

}

```




```{r}

fn <- get_newest_filenames("120_result_long.+back.+rda", "back_", ".rda")
  result_long <- readRDS(paste0("Data/", fn))

  fn <- get_newest_filenames("120_result_10yr.+back.+rda", "back_", ".rda")
  result_10yr <- readRDS(paste0("Data/", fn))

```


```{r}

```


```{r}

```


```{r}

```


```{r}

```



