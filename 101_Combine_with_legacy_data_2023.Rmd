---
title: "101 Combine with legacy data"
output: 
  html_document:
    toc: true
    toc_float: true
editor_options: 
  chunk_output_type: inline
---

**Combine legacy data (data until the year before last year) with new data (downloaded in script 100)**   

**NOTE:** Before running this script, you must  
* run script 802 on your own PC (downloads latest data from Nivabasen)  
* this will create a file in the folder 'Files_to_Jupyterhub_2021' (if 2021 was the last year) named something like 
    - '01_df_2021_notstandard_2022-06-02.rds' (the last part is the date of creation)    
* copy the resulting file to Jupyterhub, folder 'Input_data'  
   
   
**NOTE: Check the results of '12 Data changes since last year'**  
  
**Overview of this script**   
1. Load libraries and functions which will be used   
2. Data
    - Last year's data (produced by script 80)      
    - 'Legacy data', i.e. the data we used last year  
3. Reformat last year's data so they conform with the legacy data  
    - Includes changing parameter names *  
4. Pick last year's data  
    - If year needs to be fixed, do it here     
    - Also add data read from Excel sheets: NILU data and cod biol. effects  
5. Fix units  
6. Add parameter sums for PCBs, BDEs etc.  
7. Add columns for dry weight and fat percentage (drawn from the data itself)   
  
* NOTE: When changing parameter names, remember that parameter names are found different places:   
    - data_legacy - see part 3-d2 in this script (Triphenyl -> TPhT)   
    - PROREF values - found in "Proref_report_2017.xlsx" and "Proref_paper.xlsx" (both in Input_data)   
    - Possibly EQS - found in "Input_data/EQS_limits.xlsx"   
    - Code in a few places (only script 210?)  
    
* The data is checked for duplicates repeatedly, in the following sections: 
2a7, 3b3, 3g, 7, 8c, 10d, 11a   
    - Errors often shows in these checks  
    - These checks can be sped up using data.table (https://stackoverflow.com/a/7450633), 
    or possibly dtplyr::lazy_dt 

## 1. Load libraries and functions   
```{r, results='hide', message=FALSE, warning=FALSE}

library(dplyr)
library(purrr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(readxl)
library(readr)

# Load self-made functions
source("002_Utility_functions.R")
source("101_Combine_with_legacy_data_functions.R")

```

### Set year  
Note: there are still some hard-coded "2019" given in the code  
```{r}

lastyear <- 2023

```


## 2. Data  

### a1a. Recently downloaded data  
- Read data downloaded from Nivabasen usoing script 080 (by default, the most recent dataset made is downloaded)   
- Reformat data         
- The file named '01_df_2019_notstandard_<date>' were made on DHJs PC using script 01 in project 'Milkys2_pc'  
```{r, results='hold'}

filepattern <- paste0("80_df_", lastyear, "_notstandard_")    # file name except date and extension #ELU endrer fra 80_df til 01_df
filepattern_with_extension <- paste0(filepattern, ".+.csv")
                  
filenumber <- 1                                 # filenumber = 1 means "read the newest file"

# Get available files, sorted from newest to oldest
files <- dir("Input_data", pattern = filepattern_with_extension) %>% rev()

if (length(files) == 0){
  
  stop("No files found for year ", lastyear)

} else {
  
  column_types <- cols(
    PROJECT_NAME = col_character(),
    STATION_CODE = col_character(),
    STATION_NAME = col_character(),
    LATIN_NAME = col_character(),
    MYEAR = col_double(),
    TISSUE_NAME = col_character(),
    SAMPLE_NO = col_double(),
    REPNO = col_double(),
    NAME = col_character(),
    VALUE = col_double(),
    FLAG1 = col_character(),
    UNIT = col_character(),
    REMARK_sample = col_character(),
    LABORATORY = col_character(),
    METHOD_REF = col_character(),
    DETECTION_LIMIT = col_double(),
    UNCERTAINTY = col_double(),
    QUANTIFICATION_LIMIT = col_double(),
    PROJECT_ID = col_double(),
    STATION_ID = col_double(),
    TAXONOMY_CODE_ID = col_double(),
    MATRIX_ID = col_double(),
    SAMPLE_ID = col_double(),
    TISSUE_ID = col_double(),
    METHOD_ID = col_double(),
    VALUE_ID = col_double(),
    Pooled_n = col_double(),
    LABWARE_TEXT_ID = col_character(),
    SPECIMEN_ID = col_character(),
    SPECIMEN_NO = col_character()
  )
  
         
  
  # Info for user
  cat("Reading file number ",  filenumber, ", sorted from newest to oldest files:", sep = "")
  cat("\n", files[filenumber])
  cat("\n\n")
  cat("If you want to read a different file, replace 'filenumber <- 1' or 'filename' with the file you want")
  cat("\n")
  cat("For instance, set 'filenumber <- 2' to read the second newest file")
  cat("\n")
  
  # Get filename and its date part 
  filename <- files[filenumber]
  file_date <- substr(filename, nchar(filepattern) + 1, nchar(filepattern) + 10) # pick date part
  
  # The date part of 'filename' (e.g., '2020-04-23')
  # will be used in part 10, when we save the resulting file
  
  dat_new1 <- read_csv(paste0("Input_data/", filename), col_types = column_types) %>%
    mutate(MYEAR = lastyear)
  message(nrow(dat_new1), " rows of data read from file")
  
}

cat("\n")

# If you want to remove VALUE = NA, change FALSE to TRUE in the next line 

dat_new1_missing_value <- dat_new1 %>% 
  filter(is.na(VALUE))

if (TRUE){
  
  n1 <- nrow(dat_new1)
  dat_new1 <- dat_new1 %>%
    filter(!is.na(VALUE))
  n2 <- nrow(dat_new1)
  
  warning("\n", n1-n2, " rows with no value of VALUE were removed\n")
  message("You must check the reason for missing rows - check 'dat_new1_missing_value'")
  
} else {
  
  warning("There are ", nrow(dat_new1_missing_value), " rows with VALUE = NA. These have NOT been removed (see a1")
  
}


```

### a1b. Add eider duck data (19N) for the year before (2022)   

* This is special for 2023!  

```{r}

### HARD-CODED - 2023 script only! ###

dat_eider_2022 <- read_csv(
  "Input_data/80_df_2022_notstandard_2024-09-12_12h16m.csv", 
  col_types = column_types) %>% 
  filter(STATION_CODE == "19N") %>%
  mutate(MYEAR = 2022)
message(nrow(dat_eider_2022), " rows of data will be added to the dataset")

check <- dat_new1$MYEAR == 2022 & dat_new1$STATION_CODE == "19N"
if (sum(check) == 0){
  dat_new1 <- bind_rows(dat_new1, dat_eider_2022) 
}

message("'dat_new1' now contains ", nrow(dat_new1), " rows")

```


### a1c. Remove industry stations   

* I965 Moholmen and I969 Bjørnebærviken  

```{r}

n1 <- nrow(dat_new1)
dat_new1 <- dat_new1 %>%
  filter(!STATION_CODE %in% c("I965", "I969")) 
n2 <- nrow(dat_new1)

message("'dat_new1' now contains ", nrow(dat_new1), " rows")

```


### a2. Check Fat and dry weight                    # ELU ok
Should be ca. 100-200 values for both liver and whole soft body    
```{r}

dat_new1 %>%
  filter(NAME %in% c("Fettinnhold", "Tørrstoff %")) %>%
  xtabs(~TISSUE_NAME + NAME, .)

```

### a3. Check of TBT    
* TBT given as 'Tributyltinn (TBT)' (ion weight) and 'Tributyltinn (TBT)-Sn' (tin weight)    

**Explanation**  
TBT is given by two measurements:  
- ion weight of TBT, called:    
    - 'TBT' in Access, 'Tributyltinn (TBT)' in Nivabasen, 'TBSN+' in ICES (current standard code)   
- atom weight of tin in TBT, called:   
    - 'TBTIN' in Access, 'Tributyltinn (TBT)-Sn' in Nivabasen, 'TBTIN' in ICES (marked as 'legacy code')   
- [ion weight] should be 2.44*[atom weight]   
  
As reference to the ICES codes, see    
- https://vocab.ices.dk/?CodeID=33697  
- http://vocab.ices.dk/?CodeID=78150   
- See http://vocab.ices.dk/?ref=37 for vocabulary for DOME (version 3.2 Biota), record 10,parameter 'PARAM' 
```{r}

dat_new1 %>%
  filter(grepl("Tributyltinn", NAME)) %>%
  group_by(NAME, UNIT, TISSUE_NAME) %>%
  summarise(Mean_value = mean(VALUE), N = n(), .groups = "drop")

```

### a4. Check whether adjusted metabolites have been mislabeled  

- Could rename them, for 2020 data we just remove them

```{r}

#
# SPECIAL CASE FOR 2020 (hopefully): adjusted metabolites have been mislabeled
#

sel <- dat_new1$NAME %in% c("PA1OH", "PYR1OH", "BAP3OH")

if (sum(sel) == 0){
  message("No mislabeled adjusted metabolites")
} else {
  stop("Seems to be some mislabeled adjusted metabolites. Consider to delete them.")
}


if (lastyear == 2020){
  
  dat_new1 <- dat_new1[!sel,]
  cat("dat_new1:", sum(sel), "records with mislabeled adjusted PAHs removed \n")   
  
}

```


### a5. Check PAH metabolites in cod bile      
- Unadjusted metabolites: "1-OH-fenantren", "1-OH-pyren", "3-OH-benzo[a]pyren" (used in 2020) are the same as PA1OH, PYR1OH, BAP3OH  
- Adjusted metabolites (unadjusted divided by ABS 380): PA1O, PYR1O, BAP3O  
```{r} 

params <- c("PA1OH", "PYR1OH", "BAP3OH", 
          "PA1O", "PYR1O", "BAP3O",
          "1-OH-fenantren", "1-OH-pyren", "3-OH-benzo[a]pyren")

#
# Check whether we have synonymous parameters for the same station
#
dat_check <- dat_new1 %>%
  filter(NAME %in% params) %>%
  mutate(NAME = factor(NAME, levels = params))
# View(dat_check)

tab <- xtabs(~NAME + STATION_CODE, dat_check)

# Function for testing whether the same staion contains both versions of
# synonymous names  
name_pair_in_station <- function(table, names){
  table_a <- table[rownames(table) %in% names,]
  # if there is only one station, table_a is not a matrix and apply doesn't work
  # so we must turn it into a matrix of one column 
  if (is.null(dim(table_a)))
    table_a <- matrix(table_a, ncol = 1)
  table_b <- apply(table_a > 0, 2, sum)  
  if (any(table_b > 1)){
    names_for_message <- paste(sQuote(names), collapse = ", ")
    message("The parameters ", names_for_message, " occur in station(s) given as TRUE below:")
    print(table_b > 1)
    stop("No stations must contain both of these two names")
  }
}
# test function:
# dat_test <- data.frame(
#   STATION_CODE = c("15B", "15B", "23B", "23B"),
#   NAME = c("PYR1OH", "1-OH-pyren", "PYR1OH", "PYR1OH"))
# tab <- xtabs(~NAME + STATION_CODE, dat_test)
# debugonce(name_pair_in_station)
# name_pair_in_station(tab, c("PYR1OH", "1-OH-pyren"))

# Check whether the same station contains both versions of
# synonymous names  
name_pair_in_station(tab, c("PYR1OH", "1-OH-pyren"))
name_pair_in_station(tab, c("PA1OH", "1-OH-fenantren"))
name_pair_in_station(tab, c("BAP3OH", "3-OH-benzo[a]pyren"))


dat_plot <- dat_new1 %>%
  filter(NAME %in% params & !is.na(VALUE)) 
# table(dat_plot$NAME)

if (nrow(dat_plot) > 0){
  
  # Plot values (all parameters in one plot)
  gg <- ggplot(dat_plot, aes(x = VALUE)) +
    geom_histogram() +
    facet_wrap(vars(NAME), scales = "free_x")
  print(gg)
  
  # separate for "3-OH-benzo[a]pyren"
  param_pick <- "1-OH-pyren"
  param_pick <- "1-OH-fenantren"
  param_pick <- "3-OH-benzo[a]pyren"
  gg <- ggplot(dat_plot %>% filter(NAME == param_pick), # %>% View(), 
         aes(x = VALUE)) +
    geom_histogram(bins = 30) +
    facet_wrap(vars(FLAG1), nrow = 1) +
    ggtitle(param_pick)
  # print(gg)

}

  
```


### a6. Remove adjusted PAH metabolites (PYR1O, PA1O, BAP3O)  

```{r}

sel <- dat_new1$NAME %in% c("PA1O", "PYR1O", "BAP3O")

dat_new1 <- dat_new1[!sel,]
cat("dat_new1:", sum(sel), "records with adjusted PAHs removed\n")   

```

### a7. Check for duplicates  
```{r}

# Note NAME instead of PARAM (on contrast with checks further down)
df_duplicates <- dat_new1 %>%
  add_count(STATION_CODE, LATIN_NAME, TISSUE_NAME, SAMPLE_ID, NAME) %>%           #fjernet MYEAR,
  filter(n > 1)

if (nrow(df_duplicates) > 0){
  xtabs(~NAME, df_duplicates) %>% print()
  xtabs(~TISSUE_NAME, df_duplicates) %>% print()
  xtabs(~STATION_CODE, df_duplicates) %>% print()
  stop("Duplicates in the data! Check 'df_duplicates'. (section 2-a7) \n")
} else {
  cat("No duplicates found in the data. \n")
}

```

### a8. For eider duck, change names of CCP  

* NO EIDER DUCK DATA YET (2.7.2024)  
* Use "eksl. LOQ, that is most similar to cod/blue mussel usage 

```{r}

sel <- with(dat_new1, STATION_CODE %in% "19N" & grepl("SCCP", NAME))
# View(dat_new1[sel,])
dat_new1$NAME[sel] <- "SCCP eksl. LOQ"
cat("Parameter name changed for", sum(sel), "values\n")

sel <- with(dat_new1, STATION_CODE %in% "19N" & grepl("MCCP", NAME))
# View(dat_new1[sel,])
dat_new1$NAME[sel] <- "MCCP eksl. LOQ"
cat("Parameter name changed for", sum(sel), "values\n")

```


### a9. Change SCCP and MCCP values  

- Have already added missing rows in Milkys2_pc script 802  
- Change 'SCCP eksl. LOQ' by setting VALUE = 0 and FLAG = NA for data < LOQ  
    - This is best for getting medians  
- Add new parameter 'SCCP' which is just the same as the old 'SCCP eksl. LOQ' 
    - I.e.: For less-than data, LOQ in VALUE column and FLAG1 = '<'    
    - This is intended to be used for trends mainly  
- Same for MCCP  

```{r}
#
# SCCPs
#

cat("SCCP: \n\n")

# Check

#### ELU: forstår ikke denne sjekken...

check <- dat_new1 %>%
  filter(NAME %in% c("SCCP eksl. LOQ", "SCCP inkl. LOQ"),
         STATION_CODE != "19N") %>% # View("SCCP")          # 19N doesn't have 'inkl LOQ'
  xtabs(~NAME + STATION_CODE, .)
check                                                         #ELU
if (!identical(check[1,], check[2,])){   
  message("Row 1 and row 2 are not identical! There should be equally many 'eksl. LOQ' and 'inkl. LOQ' values for all stations")           
  stop("This should be fixed in Nivabasen before proceeding. This can be done using script '817_Fix_SCCP_MCCP.R' in project 'Milkys2_pc'")
} else {
  message("There are equally many 'eksl. LOQ' and 'inkl. LOQ' values for all stations")
}                                              

#
# MCCPs
#

cat("\n\n\nMCCP: \n\n")


check <- dat_new1 %>%
  filter(NAME %in% c("MCCP eksl. LOQ", "MCCP inkl. LOQ"),
         STATION_CODE != "19N") %>%                         # 19N doesn't have 'inkl LOQ'
  xtabs(~NAME + STATION_CODE, .)
check

if (!identical(check[1,], check[2,])){   
  message("Row 1 and row 2 are not identical! There should be equally many 'eksl. LOQ' and 'inkl. LOQ' values for all stations")           
  stop("This should be fixed in Nivabasen before proceeding. This can be done using script '817_Fix_SCCP_MCCP.R' in project 'Milkys2_pc'")
} else {
  message("There are equally many 'eksl. LOQ' and 'inkl. LOQ' values for all stations")
}                                              



```


### b1. Read legacy data  
The data go up to 2017 and combines data from the Access database (up to 2015) and NIVAbasen (2016-17). 
```{r}

# Files 
files <- list_files("Data", pattern = "101_data_updated") %>% sort(decreasing = TRUE)
data.frame(filename = head(files, 5), remark = c("newest file", rep("", 4)))

# HARD_CODED: pick most recent data from last year
data_legacy <- readRDS("Data/101_data_updated_2023-09-12.rds") %>%
  mutate(PARAM = case_when(
    PARAM %in% "TTBTIN" ~ "TTBT",
    TRUE ~ PARAM)
  )

cat("\n")
cat("Lecacy data covers the years", min(data_legacy$MYEAR), "-", max(data_legacy$MYEAR), "\n")

check <- lastyear - max(data_legacy$MYEAR)
if (check <= 0){
  stop("Some of the legacy data are from 'lastyear' and thus overlaps the new data! Pick an older file?")
} else if (check >= 2){
  stop("There are missing years between legacy data and 'lastyear'! Pick a newer file?")
} else {
  message("Legacy data years checked and found ok")
}


```

### b2. Check MCCP/SCCP in legacy data   

* Fixed in Nivabase for years 2015-2022 (and 2023, see above)  
    - We do nothing about data up to 2014  

#### SCCP  

*  Through 2014: Only 'SCCP' given  
*  In 2015-2017, equal amount of 'SCCP' and 'SCCP eksl. LOQ', only lacking 'eksl. LOQ' for eider    
    - See script 870 on Milkys2_pc: there was actually no lacking/zero data for 'SCCP eksl. LOQ' those years  
*  In 2018-2020, zero data for 'SCCP eksl. LOQ' probably have not entered the database      


```{r}

df_SCCP_tall <- data_legacy %>%
  filter(grepl("SCCP", PARAM)) %>%
  select(STATION_CODE, LATIN_NAME, TISSUE_NAME, MYEAR, SAMPLE_NO2, PARAM, VALUE_WW, FLAG1) 

cat("Parameters used:\n\n")
xtabs(~PARAM + MYEAR, df_SCCP_tall)  

```

```{r}

cat("Stations:\n\n")
xtabs(~STATION_CODE + MYEAR, df_SCCP_tall)  

```


```{r}

df_SCCP_tall %>%
  filter(STATION_CODE == "23B") %>%
  ggplot(aes(MYEAR, VALUE_WW)) +
  geom_jitter(height = 0, width = 0.3) +
  facet_grid(vars(PARAM)) + 
  labs(title = "Parameter values")
 
```

```{r}

df_SCCP <- data_legacy %>%
  filter(grepl("SCCP", PARAM)) %>%
  select(STATION_CODE, LATIN_NAME, TISSUE_NAME, MYEAR, SAMPLE_NO2, PARAM, VALUE_WW) %>%
  tidyr::pivot_wider(names_from = PARAM, values_from = VALUE_WW)

ggplot(df_SCCP, aes(MYEAR, 100*(`SCCP inkl. LOQ` - `SCCP eksl. LOQ`)/`SCCP inkl. LOQ`)) +   #
  geom_jitter(height = 0, width = 0.3) +
  labs(title = "SCCP, difference between incl. LOQ and excl. LOQ values", 
       subtitle = "Note relavively small difference in 2015-2016",
       y = "incl. LOQ - excl. LOQ (as % incl. LOQ)")

```



#### MCCP  

*  Same concusions as for SCCP, see above        

```{r}

df_MCCP_tall <- data_legacy %>%
  filter(grepl("MCCP", PARAM)) %>%
  select(STATION_CODE, LATIN_NAME, TISSUE_NAME, MYEAR, SAMPLE_NO2, PARAM, VALUE_WW, FLAG1) 

df_MCCP <- data_legacy %>%
  filter(grepl("MCCP", PARAM)) %>%
  select(STATION_CODE, LATIN_NAME, TISSUE_NAME, MYEAR, SAMPLE_NO2, PARAM, VALUE_WW) %>%
  tidyr::pivot_wider(names_from = PARAM, values_from = VALUE_WW)

ggplot(df_MCCP, aes(MYEAR, 100*(`MCCP inkl. LOQ` - `MCCP eksl. LOQ`)/`MCCP inkl. LOQ`)) +
  geom_jitter(height = 0, width = 0.3) +
  labs(title = "MCCP, difference between incl. LOQ and excl. LOQ values", 
       subtitle = "Note much larger difference in 2015-2016",
       y = "incl. LOQ - excl. LOQ (as % incl. LOQ)")

```



### b3. Check legacy data for duplicates   
(11-12 seconds)
```{r}

df_duplicates <- data_legacy %>%
  add_count(STATION_CODE, LATIN_NAME, TISSUE_NAME, MYEAR, SAMPLE_NO2, PARAM) %>%
  filter(n > 1)

if (nrow(df_duplicates) > 0){
  xtabs(~PARAM, df_duplicates) %>% print()
  xtabs(~MYEAR, df_duplicates) %>% print()
  xtabs(~MYEAR + PARAM, df_duplicates) %>% print()
  stop("Duplicates in the data! Check 'df_duplicates'. (Section 2.b3)\n")
} else {
  cat("No duplicates found in the data. \n")
}
  

```

## 3. Reformat recent data to conform with legacy data  

### a. Create 'dat_new2'  
```{r}

dat_new2 <- dat_new1 %>%
  mutate(SAMPLE_NO2 = SAMPLE_NO,
         BASIS = "W")             # hard-coded

```



### b1. Fix parameter names     

PAH metabolites in bile:  
- "1-OH-fenantren", "1-OH-pyren", "3-OH-benzo[a]pyren" (used in 2020) are the same as PA1OH, PYR1OH, BAP3OH    

```{r}

# df_nivabase: Set standard parameter names (PARAM) based on NAME  
cat("dat_new2: Set standard parameter names (PARAM) \n")  
dat_new2$PARAM <- get_standard_parametername(
  dat_new2$NAME, 
  "Input_data/Lookup table - standard parameter names.csv"
  )
# Note: this lookup table had up to 2022 the following transformations:
#   Trifenyltinn (TPhT) -> TPTIN  
#   Monobutyltinn (MBT) -> MBTIN
#   Dibutyltinn (DBT)   -> DBTIN
# These were for 2023 data corrected to TPhT, MBT and DBT, resp.


# dat_new2 %>% filter(STATION_CODE == "227G2") %>% select(NAME, PARAM, VALUE, FLAG1)


# Fix PBDE and PCB substances  
dat_new2$PARAM <- sub("BDE-", "BDE", dat_new2$PARAM, fixed = TRUE)
dat_new2$PARAM <- sub("PCB-", "CB", dat_new2$PARAM, fixed = TRUE)

# Some new parameters in 2023
# Endosulfan, alfa-       insecticide, not found in data_legacy
# Lindan (gamma-HCH)      HCHG, exists 
# Oktaklorstyren (OCS)    OCS, exists  
# epsilon-HCH             an exotic form of HCH (hexachlorocyclohexane), not found in data_legacy  
# PFDoDS                  perfluoro-1-dodecansulfonate(PFDoS), exists (alternatives: PFDS, PFDoDA)
# PFHpS                   Perfluorheptansulfonat (PFHpS), exists
# PFNS                    correct (to be added to preferred units)
# PFPS                    what to add? PFPrS [perfluoro-1-propanesulfonate] or PFPeS [perfluoro-1-pentanesulfonate]?
# PFTriDS                 PFTrDS, probably to be added to preferred units (alternatives: PFTeDS, PFTrDA, PFTeDS)
# PFUnDS                  correct (to be added to preferred units)

# Extra changes
dat_new2 <- dat_new2 %>%
  mutate(
    PARAM = case_when(
      PARAM %in% c("Ag", "As", "Cd", "Co", "Cr", "Cu", "Hg", "Ni", "Pb", "Sn", "Zn") ~ toupper(PARAM),
      substr(PARAM,1,3) %in% "PCB" ~ sub("PCB ", "CB", PARAM, fixed = TRUE),
      PARAM %in% "Sølv" ~ "AG",
      PARAM %in% "Kvikksølv" ~ "HG",
      PARAM %in% "Selen" ~ "SE",
      PARAM %in% "Pentaklorbenzen (QCB)" ~ "QCB",	
      # the following names are not logical - but need to be like this in order to be conistent with old data.
      # Will be changed in 10.
      PARAM %in% "Monobutyltinn (MBT)" ~ "MBT",
      PARAM %in% "Monobutyltinn (MBT)-Sn" ~ "MBT-Sn",
      PARAM %in% "Monooktyltinn (MOT)" ~ "MOT",
      PARAM %in% "Monooktyltinn (MOT)-Sn" ~ "MOT-Sn",
      PARAM %in% "Dibutyltinn (DBT)" ~ "DBT",        
      PARAM %in% "Dibutyltinn-Sn (DBT-Sn)" ~ "DBT-Sn",        
      PARAM %in% "Dioktyltinn (DOT)" ~ "DOT",        
      PARAM %in% "Dioktyltinn-Sn (DOT-Sn)" ~ "DOT-Sn",   
      PARAM %in% "Tributyltinn (TBT)" ~ "TBT",
      PARAM %in% "Tributyltinn (TBT)-Sn" ~ "TBTIN",    # the logical would be TBT-Sn, but there is a tradition for TBTIN
      PARAM %in% "Trifenyltinn (TPhT)" ~ "TPhT",
      PARAM %in% "Trifenyltinn (TPhT)-Sn" ~ "TPhT-Sn",
      PARAM %in% "Trisykloheksyltinn (TCHT)" ~ "TCHT",
      PARAM %in% "Trisykloheksyltinn (TCHT)-Sn" ~ "TCHT-Sn",
      PARAM %in% "Tetrabutyltinn (TetraBT)" ~ "TTBT",
      PARAM %in% "Tetrabutyltinn (TTBT)-Sn" ~ "TTBT-Sn",
      PARAM %in% "1-OH-pyren" ~ "PYR1OH",
      PARAM %in% "1-OH-fenantren" ~ "PA1OH",
      PARAM %in% "3-OH-benzo[a]pyren" ~ "BAP3OH",
      PARAM %in% 'PFUdA' ~ 'PFUnDA',
      PARAM %in% 'PFTriDS' ~ 'PFTrDS',
      PARAM %in% '6:2 FTS' ~ '6:2 Fluortelomersulfonat (FTS, H4PFOS)',
      PARAM %in% 'PFDoDS' ~ 'perfluoro-1-dodecansulfonate(PFDoS)',
      PARAM %in% 'PFHpS' ~ 'Perfluorheptansulfonat (PFHpS)',
      
      PARAM %in% 'Lindan (gamma-HCH)' ~ 'HCHG',
      PARAM %in% 'Oktaklorstyren (OCS)' ~ 'OCS',
      grepl("oktametylsyklotetrasiloksan", PARAM) ~ "D4",
      grepl("dekametylsyklopentasiloksan", PARAM) ~ "D5",
      grepl("dodekametylsykloheksasiloksan", PARAM) ~ "D6",
      grepl("Kortkjedede (SCCP)", PARAM, fixed = TRUE) ~ "SCCP inkl. LOQ",
      grepl("Mellomkjedede (MCCP)", PARAM, fixed = TRUE) ~ "MCCP inkl. LOQ",
      TRUE ~ PARAM)
  )

sel <- dat_new2$NAME %in% "Tørrstoff %"  
dat_new2$PARAM[sel] <- "DRYWT%"
cat("dat_new2: PARAM = DRYWT% set for", sum(sel), "records \n")  

sel <- dat_new2$NAME %in% "Fettinnhold"  
dat_new2$PARAM[sel] <- "Fett"
cat("dat_new2: PARAM = Fett set for", sum(sel), "records \n")  

```

### b2. Check 'new' PARAM values         # ELU: finner 2 nye klor.pest,ok

* I.e., with legacy data  

```{r}

df_param_legacy <- data_legacy %>% distinct(PARAM)
df_param_new <- dat_new2 %>% count(PARAM)
df_param_new_notfound <- df_param_new %>% anti_join(df_param_legacy, by = join_by(PARAM))

df_param_new_notfound <- df_param_new_notfound %>%
  fuzzyjoin::stringdist_left_join(
    df_param_legacy, by = c("PARAM")
  ) %>%
  rename(PARAM = PARAM.x) %>%
  group_by(PARAM) %>%
  summarise(
    n = first(n),
    Suggestions = paste(PARAM.y, collapse = "; ")
  ) %>%
  mutate(
    Remark = case_when(
      grepl("-Sn", PARAM, fixed = TRUE) ~ "Tin weight of an organotin - can be ignored",
      grepl("^Sum", PARAM) ~ "Sum parameter - can be ignored",
      grepl("^sum", PARAM) ~ "Sum parameter - can be ignored",
      grepl("^Total", PARAM) ~ "Sum parameter - can be ignored",
      grepl("^PF", PARAM) ~ "PFAS - check spelling, including lower-case/upper-case letters/",
    )
  )

# df_param_new_notfound$PARAM %>% paste(collapse = "       ")

n <- nrow(df_param_new_notfound)
n_ignore <- sum(grepl("ignore", df_param_new_notfound$Remark))


if (n > 0){
  message(n, " parameters in 'dat_new2' are not found in the legacy data.\n\n")
  if (n_ignore == n){
    message("All 'new' parameters not found are tin weights (of organotins) or sums, which can be ignored (run View('df_param_new_notfound') for more info")
  } else {
    cat(
      n_ignore, " of these can be ignored, while ", n - n_ignore, " must be checked.\n",
      "Run\n", 
      "    View('df_param_new_notfound')\n", 
      "to see parameters in the 'new' data that are not found in the 'legacy' data.\n\n", 
      "You must identify if 'new' parameters are actually new, or just new names for 'old' substances.\n",
      "You can do this by checking existing names (in 'data_legacy').\n",
      "Example:\n", 
      "     You find that 'df_param_new_notfound' contains the substance '6:2 FTS'.\n", 
      "     Search for 'FTS' substance names in the legacy data by running the following:\n",
      "       tab <- table(data_legacy$PARAM)\n",
      "       tab[grepl('FTS', names(tab))]\n",
      "     This reveals that this is an existing substance, but the name used before is '6:2 Fluortelomersulfonat (FTS, H4PFOS)'\n\n",
      "For PFAS compounds, you can also check spelling in the standard OECDlist by running\n",
      "    View(read_tsv('Input_data/Lookup_tables/Lookup_PFAS_standard_names_OECD.txt'))\n\n",
      "To change the substance name in 'dat_new2', go back to part 3.b1 and add this inside the 'case_when':\n",
      "    PARAM %in% '6:2 FTS' ~ '6:2 Fluortelomersulfonat (FTS, H4PFOS)',\n",
      "Then run part a and b1 again.\n\n", 
      sep = ""
    )
    warning("If you don't correct parameter names, this will break existing time series.")
  }
}


```


### b3. Check for duplicates  

```{r}

df_duplicates <- dat_new2 %>%
  add_count(STATION_CODE, LATIN_NAME, TISSUE_NAME, MYEAR, SAMPLE_NO2, PARAM) %>%
  filter(n > 1)

if (nrow(df_duplicates) > 0){
  xtabs(~PARAM, df_duplicates) %>% print()
  xtabs(~STATION_CODE, df_duplicates) %>% print()
  stop("Duplicates in the data! Check 'df_duplicates'. (section 3-b2) \n")
} else {
  cat("No duplicates found in the data. \n")
}


```
### b4. Save data so far  
```{r}



```


### c. Remove sums  
```{r}

# 1. Some specific names
sel1 <- dat_new2$PARAM %in% c("Sum PCB(7) inkl. LOQ", 
                             "Total 6 Ikke dioksinlike PCB inkl. LOQ", 
                             "Sum PCB(7) eksl. LOQ", 
                             "Total 6 Ikke dioksinlike PCB eksl. LOQ")

# 2. All starting with "Sum " or "sum ":
sel2 <- tolower(substr(dat_new2$PARAM, 1, 4)) == "sum "

sel <- sel1 | sel2

dat_new2 <- dat_new2[!sel,]
cat("dat_new2:", sum(sel), "records with sums deleted (will be recalculated) \n")  

```

### d1. Check tins   

**NOTE: see part 10 below**  

By comparing with original report, we find that all tins in AqM, except TBT, are given as **tin (Sn) weight**. TBT is given as ion weight.  
* See "K:\Prosjekter\Sjøvann\JAMP\2019\analyser\Analyserapporter\snegler\Analyserapport 925-7518 snegler.PDF"  
- Exception: for the industry stations I965 and I969, it seems that tins are given as **ion weight** 
(Original report for Milkys 2019 can be found at   
`K:\Prosjekter\Sjøvann\JAMP\2019\analyser\Analyserapporter\snegler\Analyserapport 925-7518 snegler.PDF`)  
  
Previous years - overview of names used     

Substance            | ION WEIGHT                        | TIN WEIGHT  
---------------------|-----------------------------------|----------------------------------
BUTYLTINS            |                                   |                              
monobutyltin         | MBTIN, "monobutyltin (MBT)"       | Monobutyltinn (MBT)-Sn
dibutyltin           | DBTIN                             | Dibutyltinn-Sn (DBT-Sn)
tributyltin          | TBT                               | Tributyltinn (TBT)-Sn
tetrabutyltin        | TTBT, "Tetrabutyltinn (TetraBT)"  | Tetrabutyltinn (TTBT)-Sn
OCTYLTINS            |                                   |                              
monooctyltin         | MOT                               | Monooktyltinn (MOT)-Sn
dioctyltin           | DOT                               | Dioktyltinn-Sn (DOT-Sn)
CYCLOHEXYLTINS       |                                   |                                   
tricyclohexyltin     | TCHT                              |               
PHENYLTINS           |                                   |                               
Triphenyltin (TPhT)  | TPTIN - changed to TPhT in 2021 * | Trifenyltinn (TPhT)-Sn   

* Not for legacy data in Nivadatabase, but in this procedure   
  
Some of these (e.g. DBTIN and TPTIN for ion weight) are illogical but need to be like this in 
order to conform with legacy data (data_legacy)   
  
Examples from 11G in 2019:   
* Tributyltinn   
    - Report says Tributyltinn (TBT) = <1.9, Tributyltinn (TBT)-Sn = <0.77     
    - Aquamonitor says TBT = <0.77   
    - Nivabase says Tributyltinn (TBT) = <1.9, Tributyltinn (TBT)-Sn = <0.77   
* Triphenyltin C18-H15-Sn, ion weight 350.0, Sn weight 118.71 = [ion weight]*0.339   
    - Report says Trifenyltinn (TPhT) = <1.9, Trifenyltinn (TPhT)-Sn = <0.64    
    - Aquamonitor says TPhT = <0.64   
    - Nivabase says Trifenyltinn (TPhT) = <1.9, Trifenyltinn (TPhT)-Sn = <0.64
    - For new data, 'Trifenyltinn (TPhT)' is translated to TPTIN (but see part 10)
    
```{r}

# Check one station 
dat_new2 %>%
  filter(LATIN_NAME %in% c("Nucella lapillus", "Littorina littorea")) %>%
  filter(STATION_CODE == "227G2") %>%
  select(STATION_CODE, MYEAR, NAME, PARAM, UNIT, VALUE, FLAG1) %>%
  arrange(NAME)

if (FALSE){

  # Check tetrabutyltin or triphenyltin in legacy daya
  data_legacy %>% 
    # filter(PARAM %in% c("TTBT", "TTBTIN")) %>%
    filter(grepl("TPhT", PARAM, ignore.case = TRUE) | 
             grepl("Trifenyltinn", PARAM, ignore.case = TRUE) |
             grepl("TPTIN", PARAM, ignore.case = TRUE)) %>%
    xtabs(~MYEAR + PARAM, .)
 
}

```
### d2. Fix Triphenyltin in legacy data  # ELU kjører ikke
```{r}

# ONLY NEEDED TO DO ONCE
# sel <- data_legacy$PARAM %in% "TPTIN"  
# data_legacy$PARAM[sel] <- "TPhT"  
# message("data_legacy - ",sum(sel), " records: TPhT changed to TPTIN")
# saveRDS(data_legacy, "Data/101_data_updated_2020-08-05.rds")  

```


### e1. Check species names   
```{r}

table(addNA(dat_new2$LATIN_NAME))

```

### e2. Remove "unwanted species"   

* Fucus vesiculosus = rockweed (measured on a Milkys station, but for a different project)  

```{r}

n1 <- nrow(dat_new2)
dat_new2 <- dat_new2 %>%
  filter(!LATIN_NAME %in% "Fucus vesiculosus")
n2 <- nrow(dat_new2)

cat("Number of rows before:", n1, "\n")
cat("Number of rows after:", n2, "\n")
cat("Difference:", n1-n2, "\n")

```


### f. Check units    
- Will be fixed in section 4  
```{r}

table(addNA(dat_new2$UNIT))

```

### g. Check and fix uniqueness of samples   

* If duplicated data, see code for 2022 data  

```{r}

# Check uniqueness of fat and dry weight
check1 <- dat_new2 %>%
  filter(PARAM %in% c("DRYWT%", "Fett")) %>% # View()
  group_by(MYEAR, STATION_CODE, LATIN_NAME, TISSUE_NAME, SAMPLE_NO2, PARAM) %>%
  mutate(n = n()) %>%
  filter(n > 1) %>%
  arrange(SAMPLE_NO2, PARAM) %>%
  ungroup() %>%
  select(LATIN_NAME, SAMPLE_NO2, SAMPLE_ID, PARAM, VALUE,  FLAG1, QUANTIFICATION_LIMIT) 

if (nrow(check1) > 0){
  
  message("Duplicated data, fat and dry weight")
  table(check1$STATION_CODE)
  
  # USed below
  tab <- xtabs(~SAMPLE_NO2 + SAMPLE_ID + STATION_CODE, check1)

} else {
  
  message("No duplicated data for fat and dry weight")
  
}


# Check uniqueness of all variables
check2 <- dat_new2 %>%
  group_by(MYEAR, STATION_CODE, LATIN_NAME, TISSUE_NAME, SAMPLE_NO2, PARAM) %>%
  mutate(n = n()) %>%
  filter(n > 1) %>%
  arrange(SAMPLE_NO2, PARAM)

if (nrow(check2) > 0){
  
  message("Duplicated data for some parameters, fat and dry weight")
  table(check2$STATION_CODE)
  
} else {
  
  message("No duplicated data for other parameters")
  
}


```


### h. List variables in data sets  
Just for help with writing the next section  
```{r}

if (TRUE){
  
  data_legacy %>% 
    names() %>% paste(collapse = ", ") 

  dat_new2 %>% 
    names() %>% paste(collapse = ", ")
  
}

```


### i. Keep only rows with PARAM and remove the 'Substance' column (after possible check)    

```{r}

if (TRUE){
  dat_new2 %>%
    count(NAME, PARAM)
  }

n1 <- nrow(dat_new2)
dat_new3 <- dat_new2 %>% 
  filter(!is.na(PARAM)) %>%
  select(-NAME)
n2 <- nrow(dat_new3)

cat("Number of rows before:", n1, "\n")
cat("Number of rows after:", n2, "\n")
cat("Difference:", n1-n2, "\n")

```



### j. Tables of last year's data  

```{r}

# Tissues
cat("TISSUES \n")
for (tissue in unique(dat_new3$TISSUE_NAME)){
  cat(tissue, ": ")
  stations <- dat_new3 %>% 
    filter(TISSUE_NAME %in% tissue) %>%
    pull(STATION_CODE) %>% unique()
  cat(length(stations), "stations \n   ")
  cat(paste(stations, collapse = ", "), "\n")
}

# Species
cat("\n")
cat("SPECIES \n")
for (species in unique(dat_new3$LATIN_NAME)){
  cat(species, ": ")
  species_list <- dat_new3 %>% 
    filter(LATIN_NAME %in% species) %>%
    pull(STATION_CODE) %>% unique()
  cat(length(species_list), "stations \n   ")
  cat(paste(species_list, collapse = ", "), "\n")
}

```


## 4. Check and fix units  

### a. Fix Delta13C, Delta15N "unit"
```{r}

dat_new3 <- dat_new3 %>%
  mutate(
    UNIT = case_when(
      PARAM %in% c("VDSI", "Intersex") ~ "Index",
      is.na(UNIT) ~ "None",
      UNIT == "NONE" ~ "None",
      TRUE ~ UNIT
    )
  )

# Check:
if (TRUE){
  table(addNA(dat_new3$UNIT))
}

```

### b. Add preferred unit to data   
* Creates data 'dat_new4'  
```{r}

preferred_units <- readr::read_csv("Input_data/Lookup table - preferred parameter units.csv", col_types = "cc")[1:2] %>%
  filter(!is.na(PARAM))
unit_conversion <- readr::read_csv("Input_data/Lookup table - unit conversions.csv", col_types = "ccn") %>%
  filter(!is.na(UNIT))

# Fix the spaces in 'UNIT' in unit_conversion:
# find 'space_16bit' (non-breaking space) and replace with 'space_8bit' (ordinary space)    
# see here: https://programmer.group/c2-a0-no-break-space-with-special-spaces-in-utf-8-encoding.html
space_16bit <- charToRaw("\xc2\xa0") %>% rawToChar()
space_8bit <- charToRaw("\x20") %>% rawToChar()   

unit_conversion$UNIT <- gsub(space_16bit, space_8bit, unit_conversion$UNIT)

units_with_several_preferred <- preferred_units %>%
  count(PARAM) %>%
  filter(n > 1)

if (nrow(units_with_several_preferred) == 0){
  # Creates dat_new4 which has Preferred_unit and Conversion_factor added  
  dat_new4 <- dat_new3 %>%
    left_join(preferred_units, by = "PARAM") %>% 
    left_join(unit_conversion, by = c("UNIT", "Preferred_unit")) %>%
    mutate(Conversion_factor = ifelse(UNIT == "PERCENT", 1, Conversion_factor))
  cat("Preferred_unit and Conversion_factor added to data using 'Lookup table - unit conversions.csv' \n")
  cat("Name of data set for last year: 'dat_new3' -> 'dat_new4' \n")
} else {
  cat("'Lookup table - preferred parameter units.csv' contains some PARAM with more than one preferred unit\n")
  cat("  - check 'units_with_several_preferred'\n")
  cat("  - then fix 'Lookup table - preferred parameter units.csv' and run this chunk again.\n")
  warning("'Lookup table - preferred parameter units.csv' must contain exactly one row (one preferred unit) for each PARAM!")
}  


# For checking:
if (FALSE){
  dat_new4 %>%
    filter(LATIN_NAME == "Somateria mollissima") %>%
    select(PARAM, UNIT, Preferred_unit, Conversion_factor) 
}


```

### c. Checks (if needed) - see code in 'Appendix'   

### d. Check units that are different from preferred units   
```{r}

allowed_units <- table(preferred_units$Preferred_unit)

check_unit <- dat_new4 %>%
  filter(is.na(UNIT) | is.na(Preferred_unit) | UNIT != Preferred_unit) %>%
  count(PARAM, UNIT, Preferred_unit, Conversion_factor)

# Check manually:
# View(check_unit2)

check_unit2 <- check_unit %>%
  filter(!UNIT %in% allowed_units & is.na(Preferred_unit))

if (nrow(check_unit2) > 0){
  stop(nrow(check_unit2), 
       " param/units have forbidden units and no preferred unit!\n",
       "Check the 'check_unit2' dataset\n",
       "One of two this may be wrong (1 is more likely):\n",
       "  1) the new data has an 'old' substance, but it has been given a new name.\n", 
       "     Example: you find that 'check_unit2' contains the substance '6:2 FTS'.\n", 
       "     Search for 'FTS' ubstance names in the legacy data using.\n",
       "       tab <- table(data_legacy$PARAM)\n",
       "       tab[grepl('FTS', names(tab))]\n",
       "     This reveals that the name we have used before is '6:2 Fluortelomersulfonat (FTS, H4PFOS)'",
       "     Then, go back to part 3.b1 and add this inside the 'case_when':\n",
       "        NAME %in% '6:2 FTS' ~ '6:2 Fluortelomersulfonat (FTS, H4PFOS)',\n",
       "Fix the csv table 'Lookup table - preferred parameter units.csv' (folder Input_data).\n",
       "Note: this is also where you will notice if some parameter names ('PARAM') should change name,\n",
       "  so you might go back to section 3.b1 to recode parameter names.\n",
       "(This error happened in Section 4d)")
} else {
  message("Test 1 ok (no param/units have have forbidden units combined with no preferred unit)")
}


# the following code (wrapped in a 'FALSE' to avoid it's run by accident) 
# can be used to add new parameters to 'Lookup table - preferred parameter units' 
#   (in this case, Preferred_unit is set 'UG_P_KG' for all 'new' parameters)

if (FALSE){
  preferred_units_new <- bind_rows(
    preferred_units,
    check_unit2 %>% 
      select(PARAM) %>%
      mutate(Preferred_unit = "UG_P_KG")
  )
  dir("Input_data", pattern = "Lookup table - preferred parameter units.*csv")
  # takes backup of the lookup file and and overwrites it
  write_csv_with_backup(preferred_units_new, 
                        folder = "Input_data",
                        filename_without_extension =  "Lookup table - preferred parameter units")
  
}

#
# Code such as the following may be useful to run in R on your own computer, after running script 802
#   to help updating 'preferred parameter units'. Can then copy/paste lots of new parameters to excel. 
#   Example below copies the names of all PAH metabolites (which all have 'OH' in the name):
#
# df_data %>% filter(grepl("OH", NAME)) %>% count(NAME) %>% write.table("clipboard", sep = "\t") 
#

check_unit3 <- check_unit %>%
  filter(is.na(Preferred_unit))

if (nrow(check_unit3) > 0){
  warning("Some param/units have no preferred unit, check that given UNIT in 'check_unit3' is OK.")
} else {
  message("Test 2 ok (All param/units have preferred unit)")
}

check_unit4a <- dat_new4 %>%
  filter(UNIT != Preferred_unit & is.na(Conversion_factor)) %>% # View()
  count(PARAM, UNIT, Preferred_unit, Conversion_factor)

check_unit4b <- check_unit4a %>%
  count(UNIT, Preferred_unit)

if (nrow(check_unit4b) > 0){
  stop(nrow(check_unit4b), 
       " UNIT - preferred unit pairs lack conversion factor! Fix excel table 'preferred_units'.\n",
       "Find the file 'Input_data/Lookup table - preferred parameter units.xlsx', download it to your pc,\n",
       "add the conversion factors lacking (see check_unit4b), and upload it to Jupyterhub again.\n\n",
       "(This is an error that occured in section 4d)")
} else {
  message("Test 3 ok (All pairs of UNIT - preferred unit have conversion factor)")
}

```

### e. If OK, we convert units  
```{r}

cat("No preferred unit:", sum(is.na(dat_new4$Preferred_unit)), "cases \n")
cat("UNIT == Preferred_unit:", sum(dat_new4$UNIT == dat_new4$Preferred_unit), "cases \n")
cat("UNIT != Preferred_unit:", sum(dat_new4$UNIT != dat_new4$Preferred_unit), "cases \n")
cat("UNIT != Preferred_unit and Conversion_factor = NA:", 
    sum(dat_new4$UNIT != dat_new4$Preferred_unit & is.na(dat_new4$Conversion_factor)), "cases \n")

dat_new5 <- dat_new4 %>%
  mutate(
    VALUE = case_when(
      is.na(Preferred_unit) ~ VALUE,
      UNIT == Preferred_unit ~ VALUE,
      UNIT != Preferred_unit ~ VALUE*Conversion_factor),
    UNIT = case_when(
      is.na(Preferred_unit) ~ UNIT,
      UNIT == Preferred_unit ~ UNIT,
      UNIT != Preferred_unit ~ Preferred_unit)
  ) %>%
  filter(!is.na(VALUE))

cat("Units converted. Parameters with no 'preferred unit' have just kept their original unit \n\n")
cat("Original data (dat_new4):", nrow(dat_new4), "\n")
cat("New data (dat_new5):", nrow(dat_new5), "\n")
cat("Difference:", nrow(dat_new4) - nrow(dat_new5), "\n\n")
cat("Name of data set for last year: 'dat_new4' -> 'dat_new5' \n")

#
# For checking result
#
if (FALSE){
  xtabs(~ UNIT + is.na(Preferred_unit), dat_new5)
  
  sel <- with(dat_new4, is.na(Preferred_unit))
  dat_new5[sel,] %>% select(PARAM, UNIT, VALUE)
  dat_new5[sel,] %>% xtabs(~PARAM, .)
  
  sel <- with(dat_new4, UNIT != Preferred_unit)
  dat_new4[sel,] %>% select(PARAM, UNIT, VALUE)
  dat_new5[sel,] %>% select(PARAM, UNIT, VALUE)
}

```


## 6. Add sums  

### Add sum parameters (as extra rows)  
Note that this also deletes some 'index' variables and reshuffles data  
```{r}

for (i in seq_along(sum_parameters)){     # go through numbers 1 to 9
  # We add new rows every time we go through the loop
  dat_new5 <- add_sumparameter(i, sum_parameters, dat_new5)
  }

```



### Check 
```{r}

# Check all sum parameters - how many values have we got for each?  
dat_new5 %>%
  filter(PARAM %in% names(sum_parameters)) %>%
  xtabs(~PARAM + is.na(VALUE), .)

# Same, for ex. LOQ parameters  
dat_new5 %>%
  filter(PARAM %in% paste0(names(sum_parameters), "_exloq")) %>%
  xtabs(~PARAM + is.na(VALUE), .)


#
# PLot one group parameter 
#
# Set i, e.g. 1 for sum parameter number 1 (i.e. CB_S7)

names(sum_parameters)

tissue <- "Whole soft body"
i <- 3
pars <- c(sum_parameters[[i]], 
          names(sum_parameters)[i], 
          paste0(names(sum_parameters)[i], "_exloq"))

  
dat_new5 %>%
  filter(PARAM %in% pars) %>%
  # filter(TISSUE_NAME %in% "Lever" & BASIS %in% "W") %>%
  filter(TISSUE_NAME %in% tissue & BASIS %in% "W") %>%
  group_by(STATION_CODE, MYEAR, PARAM) %>%
  mutate(PARAM = factor(PARAM, levels = pars)) %>%
  summarise(median = median(VALUE), .groups = "drop") %>%
  ggplot(aes(PARAM, median, fill = PARAM)) +
  geom_col() +
  facet_wrap(vars(STATION_CODE)) +
  theme(axis.text.x = element_text(angle = -45, hjust = 0))
  

if (FALSE){
  
  # Plot all sum parameters
  
  for (i in seq_along(sum_parameters)){
    
    
    pars <- c(sum_parameters[[i]], names(sum_parameters)[i])
    
    data_sel <- dat_new5 %>%
      filter(PARAM %in% pars) %>%
      filter(TISSUE_NAME %in% "Lever" & BASIS %in% "W") %>%
      group_by(STATION_CODE, MYEAR, PARAM) %>%
      summarise(median = median(VALUE), .groups = "drop") %>%
      mutate(PARAM = factor(PARAM, levels = pars))
    
    if (nrow(data_sel) > 0){
      gg <- data_sel %>%
        ggplot(aes(PARAM, median, fill = PARAM)) +
        geom_col() +
        facet_wrap(vars(STATION_CODE)) +
        theme(axis.text.x = element_text(angle = -45, hjust = 0))
      
      print(gg)
    }
    
  }
  
}  

```



## 7. Add columns for dry weight and fat (dat_new6)  
DRYWT and FAT_PERC (dat_new6)   
```{r}

check1 <- dat_new5 %>%
  filter(PARAM %in% c("DRYWT%", "Fett")) %>%
  count(MYEAR, STATION_CODE, LATIN_NAME, TISSUE_NAME, SAMPLE_NO2, PARAM)
check2 <- sum(check1$n > 1)

if (check2 == 0){
  
  dat_columns_to_add <- dat_new5 %>%
    filter(PARAM %in% c("DRYWT%", "Fett")) %>%
    mutate(PARAM = case_when(
      PARAM == "DRYWT%" ~ "DRYWT",
      PARAM == "Fett"  ~ "FAT_PERC")
    ) %>%
    select(MYEAR, STATION_CODE, LATIN_NAME, TISSUE_NAME, SAMPLE_NO2, PARAM, VALUE) %>%
    pivot_wider(names_from = PARAM, values_from = VALUE)
  
  dat_new6 <- dat_new5 %>%
    left_join(dat_columns_to_add, by = c("MYEAR", "STATION_CODE", "LATIN_NAME", "SAMPLE_NO2", "TISSUE_NAME"))
  
  cat("dat_new6 created by adding DRYWT% + Fett to dat_new5. Number of rows should be the same. \n\n")

  cat("Original data (dat_new5):", nrow(dat_new5), "\n")
  cat("New data (dat_new6):", nrow(dat_new6), "\n")
  cat("Difference:", nrow(dat_new5) - nrow(dat_new6), "\n")
  
} else {
  
  cat("Each line of data must have unique combination of MYEAR, STATION_CODE, LATIN_NAME, TISSUE_NAME, SAMPLE_NO2.")
  cat("\n")
  cat("Please check up the 'check1' data set to see where there are duplicates.")
  cat("\n")
  
}

```





## 8. Calculate VALUE_WW, VALUE_DW and VALUE_FB   

### a. Calculation
```{r}

dat_new6 <- dat_new6 %>%
  mutate(
    VALUE_WW = case_when(
      BASIS == "W" ~ VALUE,
      BASIS == "D" ~ VALUE*(DRYWT/100),
      BASIS == "F" ~ VALUE*(FAT_PERC/100)),
    VALUE_DW = case_when(
      BASIS == "W" ~ VALUE/(DRYWT/100),
      BASIS == "D" ~ VALUE,
      BASIS == "F" ~ VALUE*(FAT_PERC/100)/(DRYWT/100)),
    VALUE_FB = case_when(
      BASIS == "W" ~ VALUE/(FAT_PERC/100),
      BASIS == "D" ~ VALUE*(DRYWT/100)/(FAT_PERC/100),
      BASIS == "F" ~ VALUE)
    ) %>%
  select(-c(BASIS, VALUE, Preferred_unit, Conversion_factor, N_par))
    
# Example
# value_ww = 8, drywt = 50, fatperc = 10
# value_dw = 16
# value_fb = 80

```

### b. Tables dry-weight and fat basis, last year    
Note: the Somateria mollissima (eider duck) data (19N) are only 
```{r}

#
# Tabulate by tissue
#
print_station_summary <- function(table, name_of_variable){
  stations_all_ok <- rownames(table)[table[,2] == 0]
  stations_none_ok <- rownames(table)[table[,1] == 0]
  stations_some_ok <- rownames(table)[table[,1] > 0 & table[,2] > 0]
  stations_some_ok_table <- table[table[,1] > 0 & table[,2] > 0,]
  if (length(stations_all_ok) > 0){
    cat(name_of_variable, "existing for _all_ samples of the following stations: \n")
    cat("  ")
    cat(stations_all_ok, sep = ", ")
    cat("\n")
  }
  if (length(stations_none_ok) > 0){
    cat(name_of_variable, "existing for _no_ samples of the following stations: \n")
    cat("  ")
    cat(stations_none_ok, sep = ", ")
    cat("\n")
  }
  if (length(stations_some_ok) > 0){ 
    cat(name_of_variable, "lacking for lacking for some samples of the following stations: \n")
    print(stations_some_ok)
    print(stations_some_ok_table)
    cat("\n")
  }
  cat("\n")
}

#
# Tabulate by tissue
#

cat("DRY WEIGHT BASIS \n==================\n")
for (tissue in unique(dat_new6$TISSUE_NAME)){
  # tissue <- "Lever"
  cat(toupper(tissue), ": \n")
  df <- dat_new6 %>% 
    filter(TISSUE_NAME %in% tissue & MYEAR == lastyear) %>%
    mutate(Missing = factor(is.na(VALUE_DW), levels = c(FALSE, TRUE)))
  tab <- xtabs(~STATION_CODE + Missing, df)
  print_station_summary(tab, name_of_variable = "Dry weight")
}


cat("FAT BASIS \n==================\n")
for (tissue in unique(subset(dat_new6, MYEAR == lastyear)$TISSUE_NAME)){
  # tissue <- "Lever"
  # tissue <- "Blod"
  cat(toupper(tissue), ": \n")
  df <- dat_new6 %>% 
    filter(TISSUE_NAME %in% tissue & MYEAR == lastyear) %>%
    mutate(Missing = factor(is.na(VALUE_FB), levels = c(FALSE, TRUE)))
  tab <- xtabs(~STATION_CODE + Missing, df)
  # debugonce(print_station_summary)
  print_station_summary(tab, name_of_variable = "Fat percentage")
}


if (FALSE){
  
  # Check 30B liver
  dat_new6 %>% 
    filter(TISSUE_NAME %in% "Lever" & MYEAR == lastyear & STATION_CODE == "30B") %>%
    summarize_samples_print()

  # Check 30B muscle
  df <- dat_new6 %>% 
    filter(TISSUE_NAME %in% "Muskel" & MYEAR == lastyear & STATION_CODE == "30B")
  summarize_samples_print(df)

  }

```

###  c. Check duplicates again  
```{r}

df_duplicates <- dat_new6 %>%
  add_count(STATION_CODE, LATIN_NAME, TISSUE_NAME, MYEAR, SAMPLE_NO2, PARAM) %>%
  filter(n > 1)

if (nrow(df_duplicates) > 0){
  stop("Duplicates in the data! Check 'df_duplicates'. (Section 8) \n")
  xtabs(~PARAM, df_duplicates) %>% print()
  xtabs(~MYEAR, df_duplicates) %>% print()
} else {
  cat("No duplicates found in the data. \n")
}
  

```
## 9. Add the new data to the old data  

The variables lacking in dat_new6 (length-adjusted data) are just added with NA values  

```{r}

# Check overlap of column names
n1 <- names(data_legacy)
n2 <- names(dat_new6)
cat("Columns in data_legacy that are not in last year's data: \n")
n1[!n1 %in% n2]
cat("\n")

cat("Columns in last year's data (dat_new6) that are not in data_legacy: \n")
n2[!n2 %in% n1]
# n2[!n2 %in% n1] %>% dput() 
# n2[!n2 %in% n1] %>% paste(collapse = ", ")

data_updated <- bind_rows(
  data_legacy, 
  dat_new6 %>% select(-c(SAMPLE_NO, REPNO, FLAG1, REMARK_sample, 
                      STATION_ID, SAMPLE_ID, METHOD_ID, VALUE_ID,  
                      TISSUE_ID, TAXONOMY_CODE_ID))
  )

cat("Data combined. \n\n")
cat("Legacy data:", nrow(data_legacy), "rows \n")
cat("Updated data:", nrow(data_updated), "rows \n")
cat("That is", nrow(data_updated)-nrow(data_legacy), "rows more \n")


```


### Check sum data  
```{r}

data_updated %>%
  filter(PARAM %in% "CB_S7" & TISSUE_NAME %in% "Lever" & !is.na(VALUE_WW) & MYEAR >= 2010) %>%
  group_by(STATION_CODE) %>%
  mutate(n_year = length(unique(MYEAR))) %>%
  filter(n_year > 5 ) %>%
  group_by(STATION_CODE, TISSUE_NAME, MYEAR) %>%
  summarise(median = median(VALUE_WW), .groups = "drop") %>%
  ggplot(aes(MYEAR, median, color = STATION_CODE)) +
  geom_line() +
  geom_point() + 
  facet_wrap(vars(STATION_CODE))
    
```

### Check C/N data  
- C/N is in all data since 2012  
- '% C' and '% N' is in all data since 2015  
- Also checked just before saving  
```{r}

df <- data_updated %>%
  filter(MYEAR >= 2008) %>% # xtabs(~PARAM, .)
  filter(PARAM %in% c("C/N", "% C", "% N"))

df %>% xtabs(~MYEAR + PARAM + is.na(VALUE_WW), .)

```


### Check LATIN_NAME  
```{r}

cat("Table of LATIN_NAME \n-------------------------------------------\n")
xtabs(~addNA(LATIN_NAME), data_updated)

cat("\n\nTable of LATIN_NAME by year \n-------------------------------------------\n")
df <- data_updated %>%
  filter(MYEAR >= 2008) # %>% # xtabs(~PARAM, .)
xtabs(~MYEAR + addNA(LATIN_NAME), df)
  
if (FALSE){
  df <- data_updated %>%
    filter(MYEAR >= 2008) # %>% # xtabs(~PARAM, .)
  xtabs(~MYEAR + addNA(LATIN_NAME), df)
}

```

## 10. Corrections  

### a. Check and change/remove duplicates with different PARAM values  

#### PAH metabolites in bile  

"1-OH-fenantren", "1-OH-pyren", "3-OH-benzo[a]pyren" are the same as PA1OH, PYR1OH, BAP3OH  
- Example of "3-OH-benzo[a]pyren" vs BAP3OH shown below   
```{r}

# for testing (30B 2016 only)
df <- data_updated %>%
  filter(PARAM %in% c("3-OH-benzo[a]pyren", "BAP3O", "BAP3OH") & MYEAR == 2016 & STATION_CODE == "30B") %>% 
  arrange(STATION_CODE, SAMPLE_NO2, PARAM) %>%
  select(STATION_CODE, SAMPLE_NO2, PARAM, VALUE_WW) %>%
  pivot_wider(names_from = PARAM, values_from = VALUE_WW)

# head(df)

check1 <- data_updated %>%
  filter(PARAM %in% c("3-OH-benzo[a]pyren", "BAP3O", "BAP3OH")) %>% 
  arrange(STATION_CODE, SAMPLE_NO2, PARAM, MYEAR) %>%
  select(STATION_CODE, SAMPLE_NO2, PARAM, MYEAR, VALUE_WW) %>%
  pivot_wider(names_from = PARAM, values_from = VALUE_WW)

# Manual check (can also check values)
# View(check1 %>% filter(!is.na(`1-OH-pyren`)))

# Check if all records with 3-OH-benzo[a]pyren also have BAP3OH (i.e.,
#   the former can be deleted)   

if ("3-OH-benzo[a]pyren" %in% names(check1)){
  
  check2 <- check1 %>%
    filter(!is.na(`3-OH-benzo[a]pyren`)) %>%
    filter(is.na(BAP3OH))
  
  if (nrow(check2) > 0){
    stop("NOTE: Some records have 3-OH-benzo[a]pyren but not BAP3OH. Do not delete all. (Section 10a) \n")
  }
  
  
  
  # Check difference between duplicate values   
  check3 <- check1 %>%
    filter(!is.na(`3-OH-benzo[a]pyren`)) %>%
    mutate(Difference_percent = (BAP3OH - `3-OH-benzo[a]pyren`)/BAP3OH*100)
  
  if (sum(abs(check3$Difference_percent) > 5) > 0){
    stop("NOTE: The difference between 3-OH-benzo[a]pyren and BAP3OH exceeds 5%. Check before deletion. (Section 10a) \n")
  }
  
} else {
  
  cat("No '3-OH-benzo[a]pyren' in the data\n")
  
}

```

#### Delete 3-OH-benzo[a]pyren  
```{r}

n1 <- nrow(data_updated)
data_updated <- data_updated %>%
  filter(!PARAM %in% "3-OH-benzo[a]pyren")
n2 <- nrow(data_updated)

cat(n1-n2, "rows deleted\n")
                      
```

#### Same check for "1-OH-pyren" = PYR1OH
```{r}

# Only 30B 2016
data_updated %>%
  filter(PARAM %in% "1-OH-pyren") %>% 
  xtabs(~STATION_CODE + MYEAR, .)

# for testing (30B 2016 only)
df <- data_updated %>%
  filter(PARAM %in% c("1-OH-pyren", "PYR1O", "PYR1OH") & MYEAR == 2016 & STATION_CODE == "30B") %>% 
  arrange(STATION_CODE, SAMPLE_NO2, PARAM) %>%
  select(STATION_CODE, SAMPLE_NO2, PARAM, VALUE_WW) %>%
  pivot_wider(names_from = PARAM, values_from = VALUE_WW)

# head(df)

check1 <- data_updated %>%
  filter(PARAM %in% c("1-OH-pyren", "PYR1O", "PYR1OH")) %>% 
  arrange(STATION_CODE, SAMPLE_NO2, PARAM, MYEAR) %>%
  select(STATION_CODE, SAMPLE_NO2, PARAM, MYEAR, VALUE_WW) %>%
  pivot_wider(names_from = PARAM, values_from = VALUE_WW, values_fn = length)

# View(check1 %>% filter(!is.na(`1-OH-pyren`)))

if ("1-OH-pyren" %in% names(check1)){
  
  # Check if all records with 3-OH-benzo[a]pyren also have BAP3OH (i.e.,
  #   the former can be deleted)   
  check2 <- check1 %>%
    filter(!is.na(`1-OH-pyren`)) %>%
    filter(is.na(PYR1OH))
  
  if (nrow(check2) > 0){
    stop("NOTE: Some records have 1-OH-pyren but not PYR1OH. Do not delete all. (Section 10a) \n")
  }
  
  # Check difference between duplicate values   
  check3 <- check1 %>%
    filter(!is.na(`1-OH-pyren`)) %>%
    mutate(Difference_percent = (PYR1OH - `1-OH-pyren`)/PYR1OH*100)
  
  if (sum(abs(check3$Difference_percent) > 5) > 0){
    stop("NOTE: The difference between 1-OH-pyren and PYR1OH exceeds 5%. Check before deletion. (Section 10a) \n")
  }
  
} else {
  
  cat("No '1-OH-pyren' in the data\n")
  
}

```

#### Delete '1-OH-pyren'    
```{r}

n1 <- nrow(data_updated)
data_updated <- data_updated %>%
  filter(!PARAM %in% "1-OH-pyren")
n2 <- nrow(data_updated)

cat(n1-n2, "rows deleted\n")
  
                      
```

### b. Tins [data_updated2] 

* this whole part deleted for the moment as it should be rewritten somewhat, see 2022 version of this script if you are curious    

```{r}

data_updated2 <- data_updated

```

### c. Change some other parameter names  

#### QCB
```{r}

cat("Parameter names used: \n")
data_updated2$PARAM %>% unique() %>% grep("QCB", ., value = TRUE)
cat("\n")

sel <- grepl("QCB", data_updated2$PARAM)

# For checking:
df_duplicates <- data_updated2[sel,] %>%
  group_by(STATION_CODE, LATIN_NAME, TISSUE_NAME, MYEAR, SAMPLE_NO2) %>%
  mutate(n = n()) %>%
  filter(n > 1)

if (nrow(df_duplicates) > 0){
  cat("WARNING! Change of parameter names will create duplicates. Check 'df_duplicates' (code below) \n")
  cat("Parameter names not changed. \n")
  df_duplicates %>%
    select(STATION_CODE, LATIN_NAME, TISSUE_NAME, MYEAR, SAMPLE_NO2, VALUE_WW)
} else {
  data_updated2$PARAM[sel] <- "QCB"
  cat("Parameter names changed to 'QCB' for", sum(sel), "records. \n")
}

```

#### OCS
```{r}

cat("Parameter names used: \n")
data_updated2$PARAM %>% unique() %>% grep("OCS", ., value = TRUE)
cat("\n")

sel <- grepl("OCS", data_updated2$PARAM)

# For checking:
df_duplicates <- data_updated2[sel,] %>%
  group_by(STATION_CODE, LATIN_NAME, TISSUE_NAME, MYEAR, SAMPLE_NO2) %>%
  mutate(n = n()) %>%
  filter(n > 1)

if (nrow(df_duplicates) > 0){
  cat("WARNING! Change of parameter names will create duplicates. Check 'df_duplicates' (code below) \n")
  cat("Parameter names not changed. \n")
  df_duplicates %>%
    select(STATION_CODE, LATIN_NAME, TISSUE_NAME, MYEAR, SAMPLE_NO2, VALUE_WW)
} else {
  data_updated2$PARAM[sel] <- "OCS"
  cat("Parameter names changed to 'OCS' for", sum(sel), "records. \n")
}

```

#### Tables of TISSUE_NAME  
```{r}

cat("Table of TISSUE_NAME \n-------------------------------------------\n")
xtabs(~TISSUE_NAME, data_updated)

cat("\n\nTable of TISSUE_NAME by year \n-------------------------------------------\n")
df <- data_updated %>%
  filter(MYEAR >= 2008) # %>% # xtabs(~PARAM, .)
xtabs(~MYEAR + TISSUE_NAME, df)
  
if (FALSE){
  df <- data_updated %>%
    filter(MYEAR >= 2008) # %>% # xtabs(~PARAM, .)
  xtabs(~MYEAR + TISSUE_NAME, df)
}

```

### d. Final checks

#### Check all data for duplicates   
(11-12 seconds)
```{r}

# if (!exists("df_duplicates_all")){    # recalculate only if it doesn't exist (for testing)

df_duplicates_all <- data_updated2 %>%
  add_count(STATION_CODE, LATIN_NAME, TISSUE_NAME, MYEAR, SAMPLE_NO2, PARAM) %>%
  filter(n > 1)

#}

if (nrow(df_duplicates_all) > 0){
  xtabs(~PARAM, df_duplicates_all) %>% print()
  xtabs(~MYEAR, df_duplicates_all) %>% print()
  xtabs(~MYEAR + PARAM, df_duplicates_all) %>% print()
  stop("Duplicates in the data! Check 'df_duplicates_all'. (Section 10d)\n")
} else {
  cat("No duplicates found in the data. \n")
}
  

```


### e. Adding data for VDSI in 36G in 2019 
```{r}

message("Number of rows: ", nrow(data_updated2))

check <- data_updated2 %>%
  filter(STATION_CODE == "36G" & PARAM == "VDSI")
# View(check)


if (!2019 %in% check$MYEAR){
  
  # Pick 2020 data
  data_to_add <- check %>% filter(MYEAR == 2020) %>% as.data.frame()
  # Manipulate them to 2019 data (NOTE: VALUE is 0 also in 2019)
  data_to_add$DRYWT <- NA
  data_to_add$VALUE_ID <- NA
  data_to_add$MYEAR <- 2019
  
  data_updated2 <- bind_rows(data_updated2, data_to_add)
  
  message("VDSI for 36G 2019 added to data")
  
}
  
message("Number of rows: ", nrow(data_updated2))


```

### f. Fix EROD and PROTV tissue   
- Change 2021 to "Lever" - not strictly correct but follows previous years  
- Something strange in 2020, seem to be duplicates for the data ("Lever" + "Liver - microsome")  
```{r}

if (TRUE){
  check <- data_updated2 %>%
    filter(PARAM %in% c("EROD","PROTV"))
  
  xtabs(~MYEAR + TISSUE_NAME, check)
}

# BACKUP <- data_updated2

sel <- with(data_updated2, PARAM %in% c("EROD", "PROTV") & !TISSUE_NAME %in% "Lever" & MYEAR == 2021)
data_updated2$TISSUE_NAME[sel] <- "Lever"
message("TISSUE_NAME set to 'Lever' for ", sum(sel), " EROD + PROTV records in 2021")

```

### g. Fix "liver" for the snail station!
```{r}

sel <- with(data_updated2, 
            LATIN_NAME %in% c("Nucella lapillus", "Littorina littorea") & !TISSUE_NAME %in% c("Whole soft body", "SH", "WO"))

if (sum(sel) > 0){
  
  xtabs(~TISSUE_NAME + STATION_CODE, data_updated2[sel,])
  
  data_updated2$TISSUE_NAME[sel] <- "Whole soft body"
  
  cat(sum(sel), "TISSUE_NAME changed for snails")
  
}



```


### h. Add sum excl. LOQ for entire time series    

* DELETING THIS FOR NOW  


### i. Fix tin in Eider duck   

* not needed 


### j. Fix HG value in Eider duck (instead of fixing theunit)   

```{r}

sel <- with(data_updated2, MYEAR >= 2021 & STATION_CODE == "19N" & PARAM %in% "HG")
# sum(sel)

if (mean(data_updated2$VALUE_WW[sel]) > 10){
  
  # Check
  df_before <- data_updated2 %>%
    filter(MYEAR >= 2010,
           STATION_CODE == "19N",
           PARAM == "HG") %>%
    group_by(MYEAR, TISSUE_NAME) %>%
    summarise(across(c(VALUE_WW, VALUE_DW, VALUE_FB), ~round(median(.x),3)))
  # View(df_before)
  
  data_updated2$VALUE_WW[sel] <- data_updated2$VALUE_WW[sel]/1000
  data_updated2$VALUE_FB[sel] <- data_updated2$VALUE_FB[sel]/1000
  message(sum(sel), " rows updated")
  
  # Check again
  df_after <- data_updated2 %>%
    filter(MYEAR >= 2010,
           STATION_CODE == "19N",
           PARAM == "HG") %>%
    group_by(MYEAR, TISSUE_NAME) %>%
    summarise(across(c(VALUE_WW, VALUE_DW, VALUE_FB), ~round(median(.x),3)))
  # View(after)
  
} else {
    cat("no data needed to be updated")
}


```


### l. Add SCCP and MCCP without LOQ for eider duck (S. mollissima)  #ELU kjører ikke denne


```{r}
# 
# data_updated2_backup <- data_updated2
# 
# data_updated2 %>%
#   filter(grepl("SCCP", PARAM),
#          LATIN_NAME %in% "Somateria mollissima") %>%
#   xtabs(~MYEAR + PARAM, .)
# 
# # Get existing rows for eider duck
# sel1 <- grepl("SCCP", data_updated2$PARAM) & data_updated2$LATIN_NAME %in% "Somateria mollissima"
# sel2 <- grepl("MCCP", data_updated2$PARAM) & data_updated2$LATIN_NAME %in% "Somateria mollissima"
# sel <- sel1 | sel2
# cat(sum(sel), "eider duck rows selected")
# 
# dat_to_add <- dat_orig <- data_updated2[sel,]
# 
# # Pick LOQ rows
# sel_loq <- dat_orig$FLAG1 %in% "<"
# cat(sum(sel_loq), "rows <LOQ selected")
# 
# # For the new data with <LOQ, set value to 0 and set FLAG1 to NA
# dat_to_add$VALUE_WW[sel_loq] <- 0
# dat_to_add$VALUE_DW[sel_loq] <- 0
# dat_to_add$VALUE_FB[sel_loq] <- 0
# dat_to_add$FLAG1[sel_loq] <- as.character(NA)
# # For ALL the new data (regardless of <LOQ), change PARAM to "SCCP eksl. LOQ" / "MCCP eksl. LOQ"
# dat_to_add$PARAM <- sub("inkl", "eksl", dat_to_add$PARAM)
# 
# # Check
# if (FALSE){
#   bind_cols(
#     dat_orig %>% select(LATIN_NAME, PARAM, VALUE_WW, FLAG1),
#     dat_to_add %>% select(LATIN_NAME, PARAM, VALUE_WW, FLAG1)
#   ) %>% View()
# }
# 
# # Add to data  
# n1 <- nrow(data_updated2)
# 
# # Check if it already has been added
# check <- grepl("SCCP eksl", data_updated2$PARAM) & data_updated2$LATIN_NAME %in% "Somateria mollissima"
# 
# 
# # Add only if the "eksl. LOQ" data are NOT there
# if (sum(check) == 0){
#   data_updated2 <- bind_rows(data_updated2, dat_to_add)
# }
# n2 <- nrow(data_updated2)
# 
# cat(n2-n1, "rows of 'eksl. LOQ' data for eider duck added to data set \n")

```

#### . - check again
```{r}

data_updated2 %>%
  filter((grepl("SCCP", PARAM) | grepl("MCCP", PARAM)),
         LATIN_NAME %in% "Somateria mollissima") %>%
  xtabs(~MYEAR + PARAM, .)  

```


## 11. Save the data for later use    
- We use the date the data was downloaded (in script 101) in the filename   
- Used in script 109 (and downstream in 110, 111, 120, 201)  
- Also downloaded to `C:\Data\seksjon 212\Milkys2_pc\Files_from_Jupyterhub_2020\Raw_data` and used for ICES submission  
```{r}

# We make a file name using 'file_date' extracted from the original file (see part 2a)
filename <- paste0("Data/101_data_updated_", file_date, ".rds")

# Save in R format
saveRDS(data_updated2, filename)

# To read this data, we use a sentence such as 
#   data_updated2 <- readRDS(filename)    


cat("Updated and standardized data saved as:")
cat("\n", filename)


# Note: There is an alternative way of saving in R format, which you may be more familiar with:
#   save(data_updated2, file = filename)
# For data saved using save(), you read the data using the sentence
#   load(filename)
# In these scripts we instead use 
#   saveRDS()   (for saving data)
#   readRDS()   (for reading data)
# A main difference between the two methods is that save() also stores the name given to the data set,
# in this case 'data_updated2'. When the file is read, the data are automatically given the name 'data_updated2'. 
# If a data set with that name already exists, it will be overwritten (with no notice/warning). 
# Therefore, using save() + load() is a bit dangerous, so we instead use saveRDS() + readRDS(),
#   where you have to explicitly give a name to the data when you read it.

```

### a. Final check for duplicates   

(11-12 seconds)

```{r}

# if (!exists("df_duplicates_all")){    # recalculate only if it doesn't exist (for testing)

df_duplicates <- data_updated2 %>%
  add_count(STATION_CODE, LATIN_NAME, TISSUE_NAME, MYEAR, SAMPLE_NO2, PARAM) %>%
  filter(n > 1)

#}

if (nrow(df_duplicates) > 0){
  xtabs(~PARAM, df_duplicates) %>% print()
  xtabs(~MYEAR, df_duplicates) %>% print()
  xtabs(~MYEAR + PARAM, df_duplicates) %>% print()
  stop("Duplicates in the data! Check 'df_duplicates'. (Section 11a)\n")
} else {
  cat("No duplicates found in the data. \n")
}
  

```


### b. Save data from 2015 until now in Excel format
Change TISSUE_NAME before output:   
- Muskel til Muscle,  
- Lever til Liver,   
- Blod til Blood,   
- Galle til Bile  
```{r}

# Save data since 2015 in Excel format
filename_xl <- paste0("Data/101_data_2015-", lastyear, ".xlsx")

data_updated2_for_excel <- data_updated2 %>%
  filter(MYEAR %in% 2015:lastyear) %>%
  mutate(TISSUE_NAME = case_when(
    TISSUE_NAME %in% "Muskel" ~ "Muscle",  
    TISSUE_NAME %in% "Lever" ~ "Liver",   
    TISSUE_NAME %in% "Blod" ~ "Blood",
    TISSUE_NAME %in% "Galle" ~ "Bile",
    TRUE ~ TISSUE_NAME)
  )

writexl::write_xlsx(data_updated2_for_excel, filename_xl)
cat("Raw data since 2015 written to", sQuote(filename_xl), "\n\n")

cat("Table of TISSUE_NAME by year \n-------------------------------------------\n")
xtabs(~MYEAR + TISSUE_NAME, data_updated2_for_excel)


```


### c. Check TISSUE_NAME  
```{r}

cat("Table of TISSUE_NAME \n-------------------------------------------\n")
xtabs(~TISSUE_NAME, data_updated)

  
if (FALSE){
  df <- data_updated %>%
    filter(MYEAR >= 2008) # %>% # xtabs(~PARAM, .)
  xtabs(~MYEAR + TISSUE_NAME, df)
}

```

### d. Also save ´dat_new6´   
Contains date, for instance  
```{r}

# Make file name
filename <- paste0("Data/101_dat_new_", file_date, ".rds")

# Save in R format
saveRDS(dat_new6, filename)

```

## 12. Data changes since last year  

### Stations 'gained' and 'lost' during last year  
```{r}

# If you want to check older data:
# data_updated2 <- readRDS("Data/101_data_updated_2021-09-30.rds")

# Define names of variables (if 2020 is last year, 'n2019' and 'n2020')
var1 <- paste0("n", lastyear-1)
var2 <- paste0("n", lastyear)
  
check1 <- data_updated2 %>% 
  filter(MYEAR >= (lastyear-1)) %>%
  count(STATION_CODE, LATIN_NAME, MYEAR) %>%
  pivot_wider(names_from = "MYEAR", values_from = "n", 
              names_prefix = "n", values_fill = 0) 

stations_lost <- check1[check1[[var1]] > 0 & check1[[var2]] == 0,]
stations_gain <- check1[check1[[var1]] == 0 & check1[[var2]] > 0,]

cat(nrow(stations_lost), "stations lost \n")
cat("  ", paste(stations_lost$STATION_CODE, collapse = ", "), "\n")

cat(nrow(stations_gain), "stations gained \n")
cat("  ", paste(stations_gain$STATION_CODE, collapse = ", "), "\n")

```

### Tissues 'gained' and 'lost' during last year  
```{r}

check2 <- data_updated2 %>% 
  filter(MYEAR >= (lastyear-1)) %>%
  filter(!STATION_CODE %in% c(stations_lost$STATION_CODE, stations_gain$STATION_CODE)) %>%
  count(STATION_CODE, LATIN_NAME, TISSUE_NAME, MYEAR) %>%
  pivot_wider(names_from = "MYEAR", values_from = "n", 
              names_prefix = "n", values_fill = 0) %>%
  mutate(Station_tissue = paste(STATION_CODE, TISSUE_NAME)) 

data_updated2 %>% 
  filter(PARAM == "EROD" & MYEAR > 2010) %>%
  count(PARAM, TISSUE_NAME)

data_updated2 %>% 
  filter(TISSUE_NAME == "Liver - microsome" & MYEAR > 2010) %>%
  count(MYEAR, PARAM, TISSUE_NAME)

tissues_lost <- check2[check2[[var1]] > 0 & check2[[var2]] == 0,]
tissues_gain <- check2[check2[[var1]] == 0 & check2[[var2]] > 0,]

cat(nrow(tissues_lost), "tissues lost (when station was not lost) \n")
cat(nrow(tissues_gain), "tissues gained (when station was not gained) \n")


```


### Parameters 'gained' and 'lost' during last year   
```{r}

check3 <- data_updated2 %>% 
  filter(MYEAR >= (lastyear-1)) %>%
  filter(!STATION_CODE %in% c(stations_lost$STATION_CODE, stations_gain$STATION_CODE)) %>%
  mutate(Station_tissue = paste(STATION_CODE, TISSUE_NAME)) %>%
  filter(!Station_tissue %in% c(tissues_lost$Station_tissue, tissues_gain$Station_tissue)) %>%
  count(STATION_CODE, LATIN_NAME, TISSUE_NAME, PARAM, MYEAR) %>%
  pivot_wider(names_from = "MYEAR", values_from = "n", 
              names_prefix = "n", values_fill = 0) 

params_lost <- check3[check3[[var1]] > 0 & check3[[var2]] == 0,]
params_gain <- check3[check3[[var1]] == 0 & check3[[var2]] > 0,]

cat(nrow(params_lost), "parameters lost (when station/tissue was not lost) \n")
cat(nrow(params_gain), "parameters gained (when station/tissue was not gained) \n")


```

## 13. Other checks  

```{r}
data_updated <- data_updated2
```

### Stations used at least once last three years
```{r}

df <- data_updated %>%
  group_by(STATION_CODE) %>%
  mutate(Last_year = max(MYEAR)) %>%
  filter(Last_year >= 2017 & MYEAR >= 2010) %>%
  mutate(Group = case_when(
    grepl("B", STATION_CODE) ~ "Cod",
    grepl("A", STATION_CODE) ~ "Blue mussel",
    grepl("I", STATION_CODE) ~ "Blue mussel",
    grepl("X", STATION_CODE) ~ "Blue mussel",
    grepl("F", STATION_CODE) ~ "Flatfish",
    grepl("G", STATION_CODE) ~ "Snail",
    TRUE ~ "Others")
  )
for (gr in c("Cod", "Blue mussel", "Flatfish", "Snail", "Others")){
  cat("=======================================================================\n", gr, "\n")
  cat("-----------------------------------------------------------------------\n")
  xtabs(~STATION_CODE + MYEAR, df %>% filter(Group == gr)) %>% print()
  cat("\n")
}

```


### Quick visual check of times series  
All time series for a station/tissue  
```{r, fig.width=9, fig.height=6.5}

# Set 'station' to one of the stations with new data (see table in part 4 above)
station <- "15B"
tissue <- "Lever"

if (FALSE){
  station <- "19N"
  tissue <- "Blod"
  tissue <- c("Egg", "Egg homogenate of yolk and albumin")

  station <- "53B"
  tissue <- "Galle"
}

# Get all parameters for the given tissue with 2019 data from this station  
pars <- data_updated2 %>%
  filter(STATION_CODE %in% station & TISSUE_NAME %in% tissue & MYEAR == 2019) %>%
  xtabs(~PARAM, .) %>% names()

# For those parameters, we filter the data set for the data we want...
gg <- data_updated2 %>%
  filter(STATION_CODE %in% station & TISSUE_NAME %in% tissue & MYEAR >= 2000 & PARAM %in% pars) %>%
  # ...extract the median value for every PARAM and MYEAR...
  group_by(MYEAR, PARAM) %>%
  summarise(Median_concentration = median(VALUE_WW), .groups = "drop") %>%
  # ...and we feed the result into ggplot for plotting time series:
  ggplot(aes(MYEAR, Median_concentration)) + 
  geom_point() + geom_line() +
  scale_y_log10() +
  facet_wrap(vars(PARAM), scales = "free_y") +    # 'facet_wrap' means 'make one graph for each PARAM'
                                                # 'free_y' means 'let the y scale differ between plots'
  labs(title = paste0(station, ", ", tissue))

gg


```

## Appendix  

### Checks used in 'Units part' (section 4) before  
```{r}
#
# OLD CHECKS
#

if (FALSE){
  
  test1 <- dat_new4 %>%
    filter(is.na(Preferred_unit))
  
  test2 <- dat_new4 %>%
    filter(UNIT != Preferred_unit & is.na(Conversion_factor))
  
  cat("\n")
  if (nrow(test1) > 0){
    cat("WARNING! Preferred_unit not found for", 
        nrow(test1), "records of the following parameters: \n")
    test1 %>%
      pull(PARAM) %>%
      unique() %>%
      print()
  } else {
    cat("Preferred_unit found for all parameters. \n")
  }
  
  cat("\n")
  if (nrow(test2) > 0){
    cat("WARNING! Conversion_factor not found for", 
        nrow(test2), "records of the following parameters: \n")
    test2 %>%
      pull(PARAM) %>%
      unique() %>%
      print()
    cat("\n")
    cat("You must either change the preferred unit or add the lacking conversion factors. \n")
    test3 <- test2 %>%
      distinct(PARAM, UNIT, Preferred_unit) %>%
      count(UNIT, Preferred_unit)
    for (i in nrow(test3))
      cat("Cannot convert from", test3$UNIT[i], "to", test3$Preferred_unit[i], "for", test3$n[i], "parameters \n")
    
    cat("\n")
    cat("Table of existing units ('UNIT' in table below) and preferred units: \n")
    xtabs(~PARAM + Preferred_unit + UNIT,  test2)  
    
  } else {
    cat(" Conversion_factor found for all parameters. \n")
  }
  
  if (nrow(test1) > 0 | nrow(test2) > 0){
    cat("\n")
    cat("------------------------------------------------------------ \n")
    cat("Please edit 'Lookup table - preferred parameter units.xlsx'  \n")
    cat("(Folder 'Input_data') \n")
    cat("Download the file to your PC, edit it, and   \n")
    cat("   upload it back to the 'Input_data' folder.  \n")
    cat("------------------------------------------------------------ \n")
  }
  
}


```
