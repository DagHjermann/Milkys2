---
title: "201 Make csv for big excel file"
output: 
  html_document:
    keep_md: true
    toc: true
    toc_float: true
---

## 0. Check this first  


### a. Which kind of csv file do you want to make?     
  
The resulting file will be imported into Excel, so set set   
* decimal_comma = TRUE of you use European-style Excel (`,` for decimal numbers, columns separated by semicolon)   
* decimal_comma = FALSE of you use American-style Excel (`.` for decimal numbers, columns separated by comma)   
```{r}

decimal_comma <- TRUE
# used in part 7

```


### b. Last year  
Last year with observations  
```{r}

last_year <- 2021

if (as.numeric(substr(Sys.Date(), 1, 4)) - last_year != 1){
  warning("'last_year' should usually be last year. Is it set correctly?")
} else {
  message("OK ('last_year' is one year ago)")
}

```
### Set name of second last year's table
```{r}

# "Big_excel_table/Data_xl_2022-01-05_ver01.rds"

fn_secondlastyear <- "Data_xl_2022-01-05_ver01.rds"

```



## 1. Libraries + functions



```{r, message=FALSE, warning=FALSE, results='hide'}

# update.packages("rlang")

# install safejoin, if that has not already been done
if (!"safejoin" %in% installed.packages()){
  devtools::install_github(repo = "moodymudskipper/safejoin")
}

library(readxl)
library(dplyr)        
library(tidyr)        # gather()
library(purrr)        # map_ functions
# library(stringr)
library(lubridate)
# library(openxlsx)
library(mgcv)
library(AICcmodavg)   # AICc()
library(safejoin)     # safe_left_join() - from https://github.com/moodymudskipper/safejoin   

source("002_Utility_functions.R")
source("201_Make_big_excel_file_functions.R")
source("201_Time_series_write_to_Excel_functions.R", encoding = "UTF-8")

```



## 2. Data  



### a1. Annual medians  
```{r, results='hold'}

files <- list_files("Data", 
                    pattern = "110_mediandata_updated_[:date:]", 
                    extension = "rds")

cat("\n")
data_list <- read_rds_file(folder = "Data", 
                          files, 
                          filenumber = 1, 
                          get_date = TRUE,
                          time_since_modified = TRUE)

data_med2 <- data_list$data
file_date <- data_list$file_date

#
# FOR 2021 DATA!  DATA WITHOUT STATION CODE!
#

warning("NOTE!!!! FOR 2021 DATA!  DATA WITHOUT STATION CODE!")
nrow(data_med2)
data_med2 <- data_med2 %>%
  filter(!(is.na(STATION_CODE) & PARAM %in% c("% C", "% N", "C/N", "Delta13C", "Delta15N")))
nrow(data_med2)

```
### a2. Check of data_med2    
```{r}

check <- data_med2 %>%
  filter(is.na(STATION_CODE))

if (nrow(check) > 0){
  stop("There are data without 'STATION_CODE'! Check data 'check'.")
}

```

Function for reading the last (by default) file made, of files with name following 'pattern'  
```{r}

list_and_read_rds_file <- function(folder, pattern,  
                                   filenumber = 1, check_date = NULL){
  
  date_pattern <- "[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]"
  pattern_mod <- sub("[:date:]", date_pattern, pattern, fixed = TRUE)

  files <- dir(path = folder, 
               pattern = pattern_mod) %>% sort(decreasing = TRUE)
  cat("\n")
  data_list <- read_rds_file(folder = folder, 
                             files, 
                             filenumber = filenumber, 
                             get_date = TRUE,
                             time_since_modified = TRUE)
  result <- data_list$data
  if (!is.null(check_date)){
    if (data_list$file_date != check_date){
    stop("Date of this data =", data_list$file_date, "\n",
         "Date of file in check_date =", check_date, "\n",
         "They are different!")
    }
  }
  
  result
}


```


### b1. Time trends for last year  

```{r}

warning("Make sure you have selected the latest trend results (although we will try to do it for you).\n\n")

# All trend folders
folders <- dir("Data", pattern = "125_results_2021_*", include.dirs = TRUE, full.names = TRUE)

# Find folder with the latest results
sel_type <- substr(folders, 26, 31) == "output"
sel_year <- as.numeric(substr(folders, 18, 21)) %in% last_year
folders_last_year <- folders[sel_type & sel_year]
versions <- as.numeric(substr(folders_last_year, 23, 24)) 

folders_last_year_latest <- folders_last_year[which.max(versions)]

cat("\nSelected folder: \n   ", folders_last_year_latest, "\n")

# Get data
trends_last_year <- readRDS(paste0(folders_last_year_latest, "/126_df_trend_wide_2021.rds"))  

cat("\n", nrow(trends_last_year), "trends read")

```

### b2. Time trends for second last year  

```{r}

cat("======================================\n")
cat(" Trends for second last year \n")
cat("======================================\n")

date_pattern <- "[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]"
version_pattern <- "run[0-9][0-9]"

pattern_10yr_seclast <- paste0("^120_result_10yr_", last_year - 1, "_", 
                            date_pattern, "_", version_pattern, ".rds$")
pattern_long_seclast <- paste0("^120_result_long_", last_year - 1, "_", 
                            date_pattern, "_", version_pattern, ".rds$")


# Checking date
if (FALSE){
  
  result_10yr_seclast <- list_and_read_rds_file(
    folder = "Data", 
    pattern = pattern_10yr_seclast, 
    check_date = data_list$file_date
  )
  result_long_seclast <- list_and_read_rds_file(
    folder = "Data", 
    pattern = pattern_long_seclast, 
    check_date = data_list$file_date
  )
  
  result_10yr_seclast <- list_and_read_rds_file(
    folder = "Data", 
    pattern = pattern_10yr_seclast, 
    check_date = data_list$file_date
  )
  result_long_seclast <- list_and_read_rds_file(
    folder = "Data", 
    pattern = pattern_long_seclast, 
    check_date = data_list$file_date
  )
  
}

# NOT Checking date
result_10yr_seclast <- list_and_read_rds_file(
  folder = "Data", 
  pattern = pattern_10yr_seclast)

result_long_seclast <- list_and_read_rds_file(
  folder = "Data", 
  pattern = pattern_long_seclast 
)

result_10yr_seclast <- list_and_read_rds_file(
  folder = "Data", 
  pattern = pattern_10yr_seclast 
)

result_long_seclast <- list_and_read_rds_file(
  folder = "Data", 
  pattern = pattern_long_seclast, 
)

```

### c. Labware data  
Data of samples   
   
NOTE: These data are downloaded from Nivabasen using the script   
105_Download_Labware_sample_data.Rmd  
This must be done using a PC - cannot be done from Jupyterhub   
```{r}

# Read and reformat the most recent data (by default)  
files <- dir("Input_data", "Labware_samples_") %>% rev()
filename <- files[1] 

df_samples_labware_raw <- readRDS(paste0("Input_data/", filename))  

cat("Read file", sQuote(filename), "\n")


```

```{r}
# For test
data_med2 %>%
  filter(STATION_CODE == "36A" & PARAM == "% C" & Basis == "WW")

```

### d. N-string, SD and DDI
```{r, results='hold'}

cat("======================================\n")
cat("N string (sample size) \n")
cat("======================================\n")

dat_nstring <- list_and_read_rds_file(
  folder = "Data", 
  pattern = "^111_Nstring_updated_[:date:].rds$", 
  check_date = data_list$file_date
)

cat("======================================\n")
cat("SD (standard deviation) \n")
cat("======================================\n")

dat_sd <- list_and_read_rds_file(
  folder = "Data", 
  pattern = "^111_SD_updated_[:date:].rds$", 
  check_date = data_list$file_date
)


cat("======================================\n")
cat("D.d.i. (detectable data information) \n")
cat("======================================\n")

dat_ddi <- list_and_read_rds_file(
  folder = "Data", 
  pattern = "^111_DDI_updated_[:date:].rds$", 
  check_date = data_list$file_date
)

```


### e1. Other data   
1. Trends for second last year   
2. Individual data for this year (for SD)   
3. Second last year's table   
4. List of station names     
5. Data for the extra columns for parameters and stations   


```{r}

#
# 1. Trends for second last year (2018)
#

# NOT USED, repaced by 'result_10yr_seclast' etc. above
# result_10yr_prev <- readRDS("Input_data/120_result_10yr_2018.RData")
# result_long_prev <- readRDS("Input_data/120_result_long_2018.RData")
# cat("1. Trends for second last year - data read \n")
message("1. Trends for second last year - not used")

#
# 2. Individual data for this year (for "D.d.i.")
#

if (TRUE){
data_lastyear_ind <- readRDS(paste0("Data/101_data_updated_", file_date, ".rds"))   
cat("\n")
message("2. Individual data for this year - data read")

# Fixing station 227G1 and 227G2 (shall count as 227G) 
sel <- data_lastyear_ind$STATION_CODE %in% c("227G1","227G2")
data_lastyear_ind$STATION_CODE[sel] <- "227G"
cat(sum(sel), "lines with 227G1 and 227G2 changed to 227G \n")

# Fixing station 36A and 36A1 (36A1 shall count as 36A) 
sel <- data_lastyear_ind$STATION_CODE %in% "36A1"
data_lastyear_ind$STATION_CODE[sel] <- "36A"
cat(sum(sel), "lines with 36A1 changed to 36A \n")

#
# Check uniqueness (for last year only)
#
df <- data_lastyear_ind %>%
  filter(MYEAR %in% seq(last_year - 1, last_year)) %>%
  group_by(STATION_CODE, LATIN_NAME, TISSUE_NAME, MYEAR, SAMPLE_NO2, UNIT, PARAM) %>%
  mutate(n = n()) %>%
  filter(n > 1)
if (nrow(df) > 0)  # should result in zero
  stop("ERROR: There seems to be duplicates in 'data_lastyear_ind' \n")
} else {
  message("No duplicates found")
}


#
# 3. Second last year's table
#
# results_seclast_year <- read.csv2("Input_data/Data_xl_lessthans_ver12.csv", encoding = "UTF-8")
results_seclast_year <- readRDS(paste0("Big_excel_table/", fn_secondlastyear)) %>%
  mutate(TISSUE_NAME = case_when(
    TISSUE_NAME %in% "Liver" ~ "Lever",
    TISSUE_NAME %in% "Muscle" ~ "Muskel",
    TISSUE_NAME %in% "Bile" ~ "Galle",
    TISSUE_NAME %in% "Blood" ~ "Blod",
    TRUE ~ TISSUE_NAME)
    ) %>%
  filter(!STATION_CODE %in% c("227G1", "36A"))  # HARD-CODED - these dont have data in 2018 
cat("\n")
message("3. Second last year's table - data read")
# table(results_seclast_year$TISSUE_NAME)

# Fixing station 36A and 36A1 (36A1 shall count as 36A) 
sel <- results_seclast_year$STATION_CODE %in% "36A1"
results_seclast_year$STATION_CODE[sel] <- "36A"
cat(sum(sel), "lines with 36A1 changed to 36A \n")

#
# Check uniqueness (for last year only)
#
df <- results_seclast_year %>%
  group_by(STATION_CODE, LATIN_NAME, TISSUE_NAME, PARAM, Basis) %>%
  mutate(n = n()) %>%
  filter(n > 1)
if (nrow(df) > 0)  # should result in zero
  stop("ERROR: There seems to be duplicates in 'data_lastyear_ind' \n")

if (FALSE){
  results_seclast_year %>%
    select(PARAM, LATIN_NAME, TISSUE_NAME, STATION_CODE, Basis, 
         Yr_2018, N_string, SD_last) %>%
    View()
}

# names(df)
# PARAM", "LATIN_NAME", "TISSUE_NAME", "STATION_CODE", "Basis

#
# 4. List of station names and coordinates     
#
data_stations <- readxl::read_excel("Input_data/Kartbase_edit.xlsx")
cat("\n")
message("4. List of station names - data read")

# Change 227G2 to 227G (also see script 110)
sel <- data_stations$STATION_CODE %in% "227G2"
data_stations$STATION_CODE[sel] <- "227G"
cat(sum(sel), "cases of STATION_CODE = 227G2 changed to 227G \n")

# Check all stations in 'data_med2'  
check_stations1 <- data_med2 %>%
  filter(MYEAR >= (last_year - 10)) %>%
  count(STATION_CODE) %>%
  anti_join(data_stations, by = "STATION_CODE")

# Check stations in 'data_med2' last 5 years  
check_stations2 <- data_med2 %>%
  filter(MYEAR >= (last_year - 5)) %>%
  count(STATION_CODE) %>%
  anti_join(data_stations, by = "STATION_CODE")

if (nrow(check_stations2) > 0){
  warning("Coordinates not found for STATION_CODE(s) ", 
      paste(unique(check_stations2$STATION_CODE), collapse = ", "))
  cat("These stations have been used the last 5 years \n")
}

#
# 5a. Data for the extra columns for parameters 
#

#This filewas updated using the code in Appendix 2  
df_par <- read.csv("Input_data/Lookup for big excel - param.csv", stringsAsFactors = FALSE, row.names = 1)

# More checking
if (FALSE){
  a <- table(df_par_old$Substance.Group) %>% names() %>% sort() %>% dput()
  b <- table(df_par_original$Substance.Group) %>% names() %>% sort() %>% dput()
  setdiff(a, b)
  setdiff(b, a)
}
#
# 5b. Data for the extra columns for stations
#
df_stationinfo <- readxl::read_excel("Input_data/Lookup for big excel - stations.xlsx")


cat("\n")
message("5. Data for the extra columns for parameters and stations - data read")


```

### e2. Station coordinates   
Makes 'data_coordinates', added after less-than columns (section 6)
```{r}

#
# Read coordinates used in ICES
# Will be used for all stations that are *not* in 'data_stations' 
#

data_ices_coordinates <- read.csv2("Input_data/StationDictionary_20191104_utf8_Norway.csv",
                                   stringsAsFactors = FALSE)

# Skipping extracting Station_name (due to encoding problems), which any way isn't used 
#   (in "Add coordinates", line 2002)
data_ices_coordinates <- data_ices_coordinates %>%
  mutate(Station_name_orig = Station_Name,
         first_space = regexpr("[[[:blank:]]", Station_Name),
         STATION_CODE = substr(Station_Name, 1, first_space-1)) %>%
  group_by(STATION_CODE) %>%
  mutate(StartYear_max = max(StartYear, na.rm = TRUE)) %>%
  filter(StartYear == StartYear_max)

check <- data_ices_coordinates %>%
  count(STATION_CODE) %>%
  filter(n > 1) %>%
  nrow()

if (check > 0){
  warning("Duplicate STATION_CODE in the station file! \n")
}

check_stations3 <- check_stations2 %>%
  anti_join(data_ices_coordinates, by = "STATION_CODE")

if (nrow(check_stations3) > 0){
  warning("Coordinates not found for STATION_CODE(s) ", 
      paste(unique(check_stations3$STATION_CODE), collapse = ", "))
  cat("These stations have been used the last 5 years \n")
} else {
  message("All stations used the last 5 years are either in 'data_stations' or 'data_ices_coordinates'.")
}

#
# Combine coordinates from ICES with coordinates from data_stations (kartbase.xlsx)
#
data_coordinates <- bind_rows(
  # coordinates from ICES:
  data_ices_coordinates %>%
    filter(!STATION_CODE %in% data_stations$STATION_CODE) %>%
    rename(Long = Lon) %>%
    select(STATION_CODE, Long, Lat),
  # coordinates from kartbase.xlsx:
  data_stations
)

writexl::write_xlsx(data_coordinates, "Data/201_data_coordinates.xlsx")

```


### f. Some data fixing  
```{r}

### 1. Delete VDSI that are not Basis WW    
sel <- with(data_med2, PARAM %in% c("VDSI","VDSI/Intersex") & !Basis %in% "WW")
data_med2 <- data_med2[!sel,]
cat(sum(sel), "records of VDSI/Intersex deleted \n")

# Check
# data_med2 %>% filter(PARAM %in% "VDSI" & MYEAR %in% 2015:2017 & STATION_CODE %in% c("227G","227G2"))

### 2. BAP unit
sel <- with(data_med2, PARAM %in% "BAP")
# data_med2[sel,] %>% count(UNIT)
data_med2$UNIT[sel] <- "ug/kg/ABS 380 nm"
cat(sum(sel), "units of BAP changed \n")

# 3. Units of isotopes  
sel1 <- data_med2$PARAM %in% c("Delta13C", "Delta15N")
# xtabs(~UNIT, data_med2[sel1,])
sel2 <- sel1 & !data_med2$UNIT %in% "‰"
data_med2$UNIT[sel2] <- "‰"
cat(sum(sel2), "units of Delta13C and Delta15N changed \n")

# 4. Set all Tissues containing "Egg" to exactly "Egg"
sel <- grepl("Egg", data_med2$TISSUE_NAME)
data_med2$TISSUE_NAME[sel] <- "Egg"
cat(sum(sel), "tissue names containing 'Egg' changed to the exact word 'Egg' \n")

```



## 3. Some checking   



### a. One problematic species, one problematic station, one problematic parameter
```{r, results='hold'}
cat("==================================\n")
cat("Eider duck\n")
cat("----------------------------------\n")
check <- data_med2 %>% filter(LATIN_NAME %in% "Somateria mollissima" & MYEAR %in% last_year & Basis %in% "WW") %>%
  group_by(TISSUE_NAME, PARAM) %>%
  summarise(N = n(), .groups = "drop") %>%
  group_by(TISSUE_NAME, N) %>%
  summarise(PARAM = paste(PARAM, collapse = ", "), .groups = "drop") %>%
  as.data.frame()
# check
for (i in 1:nrow(check)){
  cat(check[i,"TISSUE_NAME"], "\nNumber of medians: N =", check[i,"N"], ":\n")
  cat(check[i,"PARAM"], "\n\n")
}

cat("==================================\n")
cat("71G\n")
cat("----------------------------------\n")
check <- data_med2 %>% filter(STATION_CODE %in% "71G" & Basis %in% "WW") %>%
  group_by(LATIN_NAME, PARAM, MYEAR) %>%
  summarise(N = n(), .groups = "drop") %>%
  group_by(LATIN_NAME, PARAM, N) %>%
  summarise(MYEAR = paste(MYEAR, collapse = ", "), .groups = "drop") %>%
  group_by(LATIN_NAME, N, MYEAR) %>%
  summarise(PARAM = paste(PARAM, collapse = ", "), .groups = "drop") %>%
  as.data.frame()
# check
for (i in 1:nrow(check)){
  cat(check[i,"LATIN_NAME"], ", ", check[i,"PARAM"], "\nNumber of medians: N =", check[i,"N"], ":\n")
  cat(check[i,"MYEAR"], "\n\n")
}


cat("==================================\n")
cat("PYR1O\n")
cat("----------------------------------\n")
check <- data_med2 %>% filter(PARAM %in% "PYR1O" & MYEAR >= 2008 & Basis %in% "WW") %>%
  group_by(STATION_CODE, MYEAR) %>%
  summarise(N = n(), .groups = "drop") %>%
  group_by(STATION_CODE, N) %>%
  summarise(MYEAR = paste(MYEAR, collapse = ", "), .groups = "drop") %>%
  group_by(MYEAR, N) %>%
  summarise(STATION_CODE = paste(STATION_CODE, collapse = ", "), .groups = "drop") %>%
  as.data.frame()
# check
for (i in 1:nrow(check)){
  cat(check[i,"STATION_CODE"], "\nNumber of medians since 2008: N =", check[i,"N"], ":\n")
  cat(check[i,"MYEAR"], "\n\n")
}
```




## 4. Prepare for building excel data



### a. Make 'data_xlvalues'  

```{r, results='hold'}

# This data set is used only for making select_data
data_for_select_data <- data_med2 %>%
  select(STATION_CODE, LATIN_NAME, PARAM, Basis, UNIT, MYEAR, Value) %>%
  group_by(STATION_CODE, LATIN_NAME, PARAM, Basis, UNIT) %>%
  mutate(Present_last7year = max(MYEAR) >= (last_year-7)) %>% 
  ungroup()

data_for_select_data %>%
  count(!is.na(Value), Present_last7year, !is.na(UNIT))

select_data <- with(data_for_select_data, MYEAR >= 1980 & !is.na(Value) & Present_last7year & !is.na(UNIT))
cat("Number of medians, originally:", nrow(data_med2), "\n")
cat("Number of medians, selected:", sum(select_data), "\n")

data_xlvalues1 <- data_med2[select_data,]
data_xlvalues <- data_xlvalues1 %>%
  select(MYEAR:UNIT, Basis, Value) %>%
  tidyr::pivot_wider(names_from = "MYEAR", values_from = "Value") %>%
  as.data.frame()

cat("Number of medians, selected, in wide format:", nrow(data_xlvalues), "\n")

```

### b. Make less-than columns (as TRUE/FALSE)  

```{r, results='hold'}

data_lessthans <- data_med2[select_data,] %>%
  mutate(Lessthan = Over_LOQ/N_median < 0.5) %>%
  select(MYEAR:UNIT, Basis, Lessthan) %>%
  # select(-STATION_NAME) %>%     # Some station names varies, e.g. 02B (Kirkøy nord or 'Kirkøy (north)')
  tidyr::pivot_wider(names_from = "MYEAR", values_from = "Lessthan") %>%
  as.data.frame()

# Change column names 
# We now use the names Yr_ and EQS_ for medians and EQS columns, because they are easier to search for
# Note: before writing to Excel we will change these to V.. and Q..
cn <- colnames(data_lessthans)
isnum <- !is.na(as.numeric(cn))
colnames(data_lessthans)[isnum] <- paste0("Lt_", cn[isnum])

# colnames(data_lessthans)
# str(data_lessthans)

if (nrow(data_xlvalues) != nrow(data_lessthans)){
  cat("\n\n\n")
  stop("ERROR! 'data_xlvalues' and 'data_lessthans' has different number of lines!")
} else {
  cat("\n\n")
  cat("'data_lessthans' created and appears to be ok \n")
}

# Check (all must be equal, ie all numbers below should be zero!)

ch <- rep(NA, 5)
ch[1] <- sum(data_xlvalues$PARAM != data_lessthans$PARAM)
ch[2] <- sum(data_xlvalues$STATION_CODE != data_lessthans$STATION_CODE)
ch[3] <- sum(data_xlvalues$LATIN_NAME != data_lessthans$LATIN_NAME)
ch[4] <- sum(data_xlvalues$TISSUE_NAME != data_lessthans$TISSUE_NAME)
ch[5] <- sum(data_xlvalues$Basis != data_lessthans$Basis)

for (i in 1:5){
  if (ch[i] > 0)
    stop("ERROR! The rows of 'data_xlvalues' and 'data_lessthans' must be ordered in the same way")
}

cat("\n")
cat("Index columns of 'data_xlvalues' and 'data_lessthans' has been checked and is OK \n")  

# head(data_lessthans,1)


```

### c. Check that we don't have any duplicates  
```{r}

checkdata <- data_xlvalues %>%
  group_by(STATION_CODE, LATIN_NAME, TISSUE_NAME, PARAM, Basis) %>%
  summarise(N = n(), .groups = "drop_last") %>%
  filter(N > 1) 
cat("Number of data with duplicates:", nrow(checkdata), "\n")

# The stuff below is run only if we have duplicates:
if (nrow(checkdata) > 0){
  i <- 1  # check duplicate number i
  df1 <- checkdata[i,] %>% 
    mutate(Key = paste(STATION_CODE, LATIN_NAME, TISSUE_NAME, PARAM, Basis, sep = "_"))
  df2 <- data_xlvalues %>% 
    mutate(Key = paste(STATION_CODE, LATIN_NAME, TISSUE_NAME, PARAM, Basis, sep = "_"))
  sel <- df2$Key %in% df1$Key; sum(sel)
  data_xlvalues[sel,]
  
  # 02B    Kirkøy nord 
  # 02B Kirkøy (north)
  
  # Check stations last year
  results_seclast_year %>%
    filter(STATION_CODE %in% "02B") %>%
    count(STATION_CODE, Station.Name)
}

```

### d. Change column names
```{r}

# We now use the names Yr_ and EQS_ for medians and EQS columns, because they are easier to search for
# Note: before writing to Excel we will change these to V.. and Q..
cn <- colnames(data_xlvalues)
isnum <- !is.na(as.numeric(cn))
# colnames(data_xlvalues)[isnum] <- paste0("Yr_", substr(cn[isnum], 3, 4))
colnames(data_xlvalues)[isnum] <- paste0("Yr_", cn[isnum])

cat("\n")
cat("Column names: \n")
colnames(data_xlvalues)

```

### e1. Add EQS limits - prepare  
```{r}

# Make table based on 'data_xlvalues'
data_EQS1 <- data_xlvalues
colnames(data_EQS1) <- sub("Yr_", "EQS_", colnames(data_EQS1), fixed = TRUE)
# head(data_EQS1, 2)

# Delete all data values to make table to fill in 
sel_cols <- grepl("EQS_", colnames(data_EQS1))
data_EQS1[,sel_cols] <- NA
colno_values <- which(sel_cols)

# Read EQS limits  
EQS_limits <- read.csv("Input_data/EQS_limits.csv")

# Check which combinations of PARAM, LATIN_NAME and Basis that are given  
# E.g., how many are species-unspecific (LATIN_NAME = NA)
EQS_limits %>%
  count(!is.na(PARAM), !is.na(LATIN_NAME), !is.na(Basis))
  

```

### e2. Add EQS limits - add 'Limit'  
```{r}

df_eqslimits1 <- EQS_limits %>% 
      filter(!is.na(PARAM) & is.na(LATIN_NAME) & !is.na(Basis)) %>% 
      select(PARAM, Basis, Limit) %>% 
      rename(Limit1 = Limit)
df_eqslimits2 <- EQS_limits %>% 
      filter(!is.na(PARAM) & !is.na(LATIN_NAME) & !is.na(Basis)) %>%   # add LATIN_NAME
      select(PARAM, LATIN_NAME, Basis, Limit) %>%                      # add LATIN_NAME
      rename(Limit2 = Limit)

# Add Limit1 (species-independent) and Limit2 (depends on species) 
data_EQS2 <- data_EQS1 %>%
  # Add limit for EQS given only by PARAM and Basis
  safe_left_join(
   df_eqslimits1, 
    by = c("PARAM", "Basis"),
    na_matches = "never",
    check = "BCV") %>% # View("Lim1")
  # Add limit for EQS given by PARAM, LATIN_NAME and Basis
  safe_left_join(
    df_eqslimits2, 
    by = c("PARAM", "LATIN_NAME", "Basis"),                            # add LATIN_NAME
    na_matches = "never",
    check = "BCV")

check <- with(data_EQS2, !is.na(Limit1) & !is.na(Limit2))
if (sum(check)> 0){
  stop("Some rows have both Limit1 and Limit2!")
}

if (FALSE){
  # For checking / pedagogic crutches
  data_EQS2 %>%
    filter(PARAM %in% unique(EQS_limits$PARAM) & Basis == "WW" |
             PARAM %in% "CB118" & Basis == "FB") %>%
    select(PARAM, LATIN_NAME, Basis, Limit1, Limit2) %>%
    View("species-independent limits")
  data_EQS2 %>%
    filter(PARAM %in% "CB_S6" & Basis == "WW") %>%
    select(PARAM, LATIN_NAME, Basis, Limit1, Limit2) %>%
    View("species-dependent limits")
  
}

# Add Limit
data_EQS <- data_EQS2 %>%
  mutate(
    Limit = case_when(
      !is.na(Limit1) ~ Limit1,
      !is.na(Limit2) ~ Limit2)
  ) %>%
  select(-Limit1, -Limit2)

if (FALSE){
  # For checking / pedagogic crutches
  data_EQS %>% filter(PARAM %in% unique(EQS_limits$PARAM) & Basis == "WW" | PARAM %in% "CB118" & Basis == "FB") %>% select(PARAM, LATIN_NAME, Basis, Limit) %>%
    View("species-independent limits")
}

# Preliminary check:
# cat("Number of data with/without and EQS limit (with = TRUE): \n ")
# table(!is.na(data_EQS$Limit))

cat("Number of data with/without and EQS limit (with = TRUE): \n ")
table(!is.na(data_EQS$Limit))

```

### e3. Add "n" in rows with EQS    

```{r}

# Add "n" in rows with EQS and in the columns where 'data_xlvalues' has values
# Why 'n'? Because it can be changed into a circle in Excel (by changing font to WIngdigs/Webdings)

# Select rows with Limit
sel_rows <- which(!is.na(data_EQS$Limit))
# length(sel_rows)

# Pick the columns with values only ('data_xlvalues_vals')
data_EQS_vals <- data_EQS[,colno_values]
data_xlvalues_vals <- data_xlvalues[,colno_values]
for (i in sel_rows){
  data_EQS_vals[i, !is.na(data_xlvalues_vals[i,])] <- "n"
}
# Put the columns with values only back into data_EQS
data_EQS[,colno_values] <- data_EQS_vals

# Check that the columns fit together
cat("\n\n")
cat("Check that the columns fit together (row one = data_xlvalues, row two = data_EQS): \n")
i <- with(data_xlvalues, PARAM %in% "HG" & STATION_CODE %in% "10A2" & Basis == "WW")
i <- with(data_xlvalues, PARAM %in% "HG" & STATION_CODE %in% "30B" & Basis == "WW")
a <- data_xlvalues[i, ] %>% as.matrix(ncol = 1)
b <- data_EQS[i, 1:ncol(a)] %>% as.matrix(ncol = 1)
rbind(a, b)


```




## 5. Build data set 'data_xl', which will become the big excel file   


### Start making data_xl  

```{r}

data_xl <- data_xlvalues %>% 
  rename(Unit = UNIT) %>% select(STATION_CODE, TISSUE_NAME, LATIN_NAME, PARAM, Basis, Unit)

cat("Number of columns in data_xl:",  ncol(data_xl), "\n")
# should be 6

```

### Prepare 'df_stationinfo' (station information)  

```{r}

# Assure STATION_CODE has no empty values
data_stations <- data_stations %>%
  filter(!is.na(STATION_CODE))

# Add new names
df_stationinfo$Station.Name <- NULL
df_stationinfo <- safe_left_join(
  df_stationinfo, 
  data_stations %>% select("STATION_CODE","Station_name"), 
  by = "STATION_CODE",
  na_matches = "never",
  check = "BCV"
  )

# Correct column order
# dput(colnames(df_stationinfo))
cols <- c("STATION_CODE", "Station_name", "Area", "County", "Water.Region", "VannforekomstID", "VAnnforekomstNavn")
df_stationinfo <- df_stationinfo[,cols]
colnames(df_stationinfo)[2] <- "Station.Name"

```

### Prepare parameter columns

```{r, results='hold'}

colnames(df_par)[1] <- "PARAM"

# Some IUPAC values contain semicolon, which makes a mess in Excel (as we use a semicolon-separated file)
# We replace the semicolon by a slash
# View(df_par)
sel <- grepl(";", df_par$IUPAC, fixed = TRUE)
cat("Change", sum(sel), "IPUAC values by replacing semicolon with slash \n")

cat("\n")
cat("Old names: \n")
df_par$IUPAC[sel]
df_par$IUPAC <- gsub(";", " / ", df_par$IUPAC, fixed = TRUE)
cat("\n")
cat("New names: \n")
df_par$IUPAC[sel]

# Change sum parameter names som they fit with the our "new" names
# Also see section 28
sel <- df_par$Parameter.Code %in% "PK_S"
if (sum(sel) > 0)
  df_par$Parameter.Code[sel] <- "KPAH"
cat(sum(sel), "cases: PK_S changed to KPAH \n")

sel <- df_par$Parameter.Code %in% "PAHSS"
if (sum(sel) > 0)
  df_par$Parameter.Code[sel] <- "PAH16"
cat(sum(sel), "cases: PAHSS changed to PAH16 \n")

```


### Add new columns to data_xl
```{r}

# Add extra columns
data_xl <- data_xl %>%
  safe_left_join(
  df_par  %>% filter(!is.na(PARAM)), 
  by = "PARAM",
  na_matches = "never",
  check = "BCV"
) %>%
  safe_left_join(
    df_stationinfo %>% filter(!is.na(STATION_CODE)), 
    by = "STATION_CODE",
    na_matches = "never",
    check = "BCV"
  )

cat("Number of columns in data_xl:", ncol(data_xl), "\n") # 17

```

### Put columns in correct sequence  
```{r}
cols_sequence <- c("PARAM", "Parameter.Name", "IUPAC", "CAS", "Component.Name", "Substance.Group", "Unit",
                   "STATION_CODE", "Station.Name", "Area", "County", 
                   "Water.Region", "VannforekomstID", "VAnnforekomstNavn",
                   "LATIN_NAME", "TISSUE_NAME",  "Basis")
data_xl <- data_xl[,cols_sequence]

# If error, try:
# cols_sequence[!cols_sequence %in% colnames(data_xl)]
```

### Add some station info manually
```{r}

cat("\nNumber of cases changed (se code for details): \n") # 17

sel <- data_xl$STATION_CODE %in% "19B"; sum(sel)
data_xl$Station.Name[sel] <- "Svalbard"
data_xl$County[sel] <- "Svalbard"

sel <- data_xl$STATION_CODE %in% "19N"; sum(sel)
data_xl$Station.Name[sel] <- "Breøyane"
data_xl$County[sel] <- "Svalbard"

sel <- data_xl$STATION_CODE %in% "I964"; sum(sel)
data_xl$Station.Name[sel] <- "Toraneskaien"
data_xl$County[sel] <- "Nordland"

sel <- data_xl$STATION_CODE %in% "227G2"; sum(sel)
data_xl$Station.Name[sel] <- "Flatskjær"
data_xl$County[sel] <- "Rogaland"

sel <- data_xl$STATION_CODE %in% "76A2"; sum(sel)
data_xl$Station.Name[sel] <- "Risøy"
data_xl$County[sel] <- "Aust-Agder"

sel <- data_xl$STATION_CODE %in% "97A3"; sum(sel)
data_xl$Station.Name[sel] <- "Bodø harbour"
data_xl$County[sel] <- "Nordland"

sel <- data_xl$STATION_CODE %in% "28A2"; sum(sel)
data_xl$Station.Name[sel] <- "Ålesund harbour"
data_xl$County[sel] <- "Møre og Romsdal"
data_xl$Water.Region[sel] <- "Møre og Romsdal"
data_xl$VAnnforekomstNavn[sel] <- "Borgundfjorden-vest"

sel <- data_xl$STATION_CODE %in% "I911"; sum(sel)
data_xl$Station.Name[sel] <- "Horvika"
data_xl$County[sel] <- "Møre og Romsdal"

sel <- data_xl$STATION_CODE %in% "I914"; sum(sel)
data_xl$Station.Name[sel] <- "Flåøya (southeast)"
data_xl$County[sel] <- "Møre og Romsdal"

sel <- data_xl$STATION_CODE %in% "I132"; sum(sel)
data_xl$Station.Name[sel] <- "Svensholmen"
data_xl$County[sel] <- "Vest-Agder"
data_xl$Water.Region[sel] <- "Agder"
data_xl$VAnnforekomstNavn[sel] <- "Kristiansandsfjorden-indre"

```

### Add PROREF (background values) and add median values    
Q95 = Proref  
```{r}

df_background <- data_med2 %>%
  group_by(PARAM, LATIN_NAME, TISSUE_NAME, Basis) %>%
  summarise_at(c("Stations", "N_stations", "Proref_N", "Median", "Q95"), first) %>%
  ungroup()

# Used in report - copy to Norman's K (K:\Avdeling\Mar\NOG\JMG\2018\Tabeller)
# openxlsx::write.xlsx(df_background, "Data/201_Proref.xlsx")

```

### Adding "Stations", "N_stations", "Proref_N", "Median", "Q95"  
```{r}
# head(df_background , 3)
# dput(colnames(df_background))

data_xl <- safe_left_join(
  data_xl, 
  df_background, 
  by = c("PARAM", "LATIN_NAME", "TISSUE_NAME", "Basis"),
  na_matches = "never",
  check = "BCV")

# Change some column names
colnames(data_xl)[colnames(data_xl) %in% "Stations"] <- "Backgr_stations"
colnames(data_xl)[colnames(data_xl) %in% "N_stations"] <- "Backgr_Nstat"
colnames(data_xl)[colnames(data_xl) %in% "Proref_N"] <- "Backgr_N"

cat("Number of rows in data_xl:", nrow(data_xl), "\n") # 24661
cat("Number of columns in data_xl:", ncol(data_xl), "\n") # 22

# head(data_xl, 2)
```

### Adding values from 'data_xlvalues' and EQS sign from 'data_EQS'  
```{r}
### Prepare for adding values from 'data_xlvalues' and EQS sign from 'data_EQS'  
ind_cols1 <- which(grepl("Yr_", colnames(data_xlvalues)))
ind_cols2 <- which(grepl("EQS_", colnames(data_EQS)))

if (length(ind_cols1) != length(ind_cols2)){  # should be TRUE
  stop("There number of 'Yr_' columns must be the same as the number of 'EQS_' columns'! ")
} 

# Pick every second column from 'data_xlvalues' and 'data_EQS'
for (i in 1:length(ind_cols1)){
  i1 <- ind_cols1[i]
  i2 <- ind_cols2[i]
  data_xl <- cbind(data_xl, data_xlvalues[,i1], data_EQS[,i2], stringsAsFactors = FALSE)
  colnames(data_xl)[ncol(data_xl) - 1] <- colnames(data_xlvalues)[i1]
  colnames(data_xl)[ncol(data_xl)] <- colnames(data_EQS)[i2]
}

# Add 1980 (no data but it is in the Excel file we mimic)
i <- which(colnames(data_xl) == "Yr_1981")
n <- ncol(data_xl)
data_xl <- data.frame(data_xl[,1:(i-1)], Yr_1980 = NA, EQS_1980 = NA, data_xl[,i:n])

# colnames(data_xl)
# str(data_xl)

cat("\nNumber of columns:", ncol(data_xl), "\n") # 102
```

### N string etc. for second last year    
5 columns:   
* Ant.prøver.2018 (N string)  
* SD_2018  
* Klasse.2018
* EQSclass_2018
* EQSthreshold_2018  

#### N string (sample size string) and SD     
```{r}
# data_xl_b <- data_xl  # backup
# data_xl <- data_xl_b  # restore

data_xl <- safe_left_join(
  data_xl, 
  dat_nstring %>% 
    filter(MYEAR == last_year - 1) %>% 
    select(-c(MYEAR, N, N_pooled, Max_ind)),
  by = c("PARAM", "LATIN_NAME", "TISSUE_NAME", "STATION_CODE"),
  na_matches = "never",
  check = "BCV")
# Change variable name
names(data_xl)[ncol(data_xl)] <- paste0("Ant.prøver.", last_year - 1)

# Check how many values are lacking
check <- 100*mean(!is.na(data_xl[[ncol(data_xl)]]))
message("N string (sample size string) for second last year: ", 
        round(check, 2), " % of records are ok")
if (check < 30)
  warning("Few records have N string for second last year!")

cat("\nNumber of columns:", ncol(data_xl), "\n") # 103

data_xl <- safe_left_join(
  data_xl, 
  dat_sd %>% 
    filter(MYEAR == last_year - 1) %>% 
    ungroup() %>%
    select(-MYEAR), 
  by = c("PARAM", "LATIN_NAME", "TISSUE_NAME", "STATION_CODE", "Basis"),
  na_matches = "never",
  check = "BCV")
# Change variable name
names(data_xl)[ncol(data_xl)] <- paste0("SD_", last_year - 1)

# Check how many values are lacking
check <- 100*mean(!is.na(data_xl[[ncol(data_xl)]]))
message("SD for second last year: ", 
        round(check, 2), " % of records are ok")
if (check < 30)
  warning("Few records have SD for second last year!")

cat("\nNumber of columns:", ncol(data_xl), "\n") # 104

```

#### Add Klasse (proref class) previous year  
```{r}

colnumber_value <- which(colnames(data_xl) == paste0("Yr_", last_year-1))  # Find column number for that year's median
value_prevyear <- data_xl[,colnumber_value]

colnumber_lessthan <- which(colnames(data_lessthans) == paste0("Lt_", last_year-1))  # Find column number for less-than
lessthan_prevyear <- data_xl[,colnumber_value]

# Less-thans are set a tad lower, to be put in the lower class
sel <- !is.na(lessthan_prevyear) & lessthan_prevyear
value_prevyear[sel] <- value_prevyear[sel] - 0.00001

# Just to check that we get the correct classes, i.e., if the conc. is on the limit, we get the upper class (using right = FALSE)
check_classes <- cut(value_prevyear/data_lessthans$Q95, breaks = c(-999999,1,2,5,10,20,999999), right = FALSE)

cat("Classes for Value / Proref : \n")
levels(check_classes)
cat("\n")

class_prevyear <- cut(value_prevyear/data_xl$Q95, breaks = c(-999999,1,2,5,10,20,999999), right = FALSE, labels = FALSE)
# str(class_prevyear)
# summary(class_prevyear)
# table(addNA(class_prevyear))

# Make variable
data_xl$Klasse.prevyear <- class_prevyear

# Tabulate
# table(addNA(data_xl$Klasse.lastyear))

# Set variable name
colnames(data_xl)[ncol(data_xl)] <- paste0("Klasse.", last_year - 1)

cat("\nNumber of rows:", nrow(data_xl), "\n\n") # 24346
cat("\nNumber of columns:", ncol(data_xl), "\n") # 105

```


#### Add EQSclass and EQS for second last year   
```{r}

cols <- c("PARAM", "LATIN_NAME", "TISSUE_NAME", "STATION_CODE", "Basis",
          paste0("EQSclass_", last_year - 1), 
          "EQS")

select_rows <- complete.cases(
  results_seclast_year[c("PARAM", "LATIN_NAME", "TISSUE_NAME", "STATION_CODE", "Basis")])

# cols %in% colnames(results_seclast_year)
data_xl <- safe_left_join(
  data_xl, 
  results_seclast_year[select_rows, cols],
  by = c("PARAM", "LATIN_NAME", "TISSUE_NAME", "STATION_CODE", "Basis"),
  na_matches = "never",
  check = "BCV"
  )

cat("\nNumber of columns:", ncol(data_xl), "\n") # 107

# Change column name
colnumber <- which(colnames(data_xl) == "EQS")
colnames(data_xl)[colnumber] <- paste0("EQSthreshold_", last_year - 1)
cat("Changed name for column number", colnumber, " \n")

```


### N string and SD for last year    

```{r}

data_xl <- safe_left_join(
  data_xl, 
  dat_nstring %>% 
    filter(MYEAR == last_year) %>% 
    select(-c(MYEAR, N, N_pooled, Max_ind)), 
  by = c("PARAM", "LATIN_NAME", "TISSUE_NAME", "STATION_CODE"),
  na_matches = "never",
  check = "BCV")

# Change variable name
names(data_xl)[ncol(data_xl)] <- "N_string"

cat(sum(!is.na(data_xl$N_string)), "values of 'N_string' added to data \n")

# Check how many values are lacking
check <- 100*mean(!is.na(data_xl[[ncol(data_xl)]]))
message("N string (sample size string) for last year: ", 
        round(check, 2), " % of records are ok")
if (check < 30)
  warning("Few records have N string for last year!")

cat("Number of columns:", ncol(data_xl), "\n") # 108

data_xl <- safe_left_join(
  data_xl, 
  dat_sd %>% 
    filter(MYEAR == last_year) %>% 
    ungroup() %>%
    select(-MYEAR), 
  by = c("PARAM", "LATIN_NAME", "TISSUE_NAME", "STATION_CODE", "Basis"),
  na_matches = "never",
  check = "BCV")

# Change variable name
names(data_xl)[ncol(data_xl)] <- "SD_last"

cat("\n")
cat(sum(!is.na(data_xl$SD_last)), "values of 'SD_last' added to data \n")  

# Check how many values are lacking
check <- 100*mean(!is.na(data_xl[[ncol(data_xl)]]))
message("SD for last year: ", 
        round(check, 2), " % of records are ok")
if (check < 30)
  warning("Few records have SD for last year!")

cat("Number of columns:", ncol(data_xl), "\n") # 109

```



### Add Class for last year   
Class for second last year added below (section 27b)

```{r}

colnumber_value <- which(colnames(data_xl) == paste0("Yr_", last_year))  # Find column number for last year's median
value_lastyear <- data_xl[,colnumber_value]

colnumber_lessthan <- which(colnames(data_lessthans) == paste0("Lt_", last_year))  # Find column number for last year's less-than
lessthan_lastyear <- data_xl[,colnumber_value]

# Less-thans are set a tad lower, to be put in the lower class
sel <- !is.na(lessthan_lastyear) & lessthan_lastyear
value_lastyear[sel] <- value_lastyear[sel] - 0.00001

# Just to check that we get the correct classes, i.e., if the conc. is on the limit, we get the upper class (using right = FALSE)
check_classes <- cut(value_lastyear/data_lessthans$Q95, breaks = c(-999999,1,2,5,10,20,999999), right = FALSE)

cat("Classes for Value / Proref : \n")
levels(check_classes)
cat("\n")

class_lastyear <- cut(value_lastyear/data_xl$Q95, breaks = c(-999999,1,2,5,10,20,999999), right = FALSE, labels = FALSE)
# str(class_lastyear)
# summary(class_lastyear)
# table(addNA(class_lastyear))

# Make variable
data_xl$Klasse.lastyear <- class_lastyear

# Tabulate
# table(addNA(data_xl$Klasse.lastyear))

# Set variable name
colnames(data_xl)[ncol(data_xl)] <- paste0("Klasse.", last_year)


cat("\nNumber of columns:", nrow(data_xl), "\n\n") # 110
cat("\nNumber of columns:", ncol(data_xl), "\n") # 110

```

### EQS class - put variable without data   

```{r}

# Now just give it a NA, then we set it after we have inserted the column for the EQS limit
# Then we will change the name, also 
data_xl$EQSclass_lastyear <- NA

cat("\nNumber of columns:", ncol(data_xl), "\n") # 115 (2021 data)

```

### EQS limit (not for WWa at this point)     

```{r}

# Variable 'EQS'
# head(EQS_limits, 2)

data_xl_back <- data_xl

data_xl <- data_xl %>%
  safe_left_join(
    df_eqslimits1, 
    by = c("PARAM", "Basis"), 
    na_matches = "never",
    check = "BCV") %>%
  safe_left_join(
    df_eqslimits2, 
    by = c("PARAM", "LATIN_NAME", "Basis"), 
    na_matches = "never",
    check = "BCV") %>%
  mutate(
    EQS = case_when(
      !is.na(Limit1) ~ Limit1,
      !is.na(Limit2) ~ Limit2)
  ) %>%
  select(-Limit1, -Limit2)

if (FALSE){
  # For checking
  data_xl %>% filter(Basis %in% c("WW","FB") & PARAM %in% EQS_limits$PARAM) %>% select(PARAM, LATIN_NAME, Basis, EQS) %>% View("eqs1") 
  data_xl %>% filter(Basis %in% c("WW") & PARAM %in% "CB_S6_exloq") %>% select(PARAM, LATIN_NAME, Basis, EQS) %>% View("eqs2") 
}

# colnames(data_xl)
cat("\nNumber of columns:", ncol(data_xl), "\n") # 116 (2021 data)

```

### Set values of EQS class

```{r}

value_lastyear <- data_xl[[paste0("Yr_", last_year)]]
lessthan_lastyear <- data_lessthans[[paste0("Lt_", last_year)]]

# Less-thans are set a tad lower, to be put in the lower class
sel <- !is.na(lessthan_lastyear) & lessthan_lastyear; sum(sel)
value_lastyear[sel] <- value_lastyear[sel] - 0.00001

# Fill variable with values
data_xl$EQSclass_lastyear <- cut(value_lastyear/data_xl$EQS, breaks = c(-999999,1,999999), right = FALSE, labels = FALSE)

# Change column name of last added variable
colnumber <- which(colnames(data_xl) %in% "EQSclass_lastyear")
colnames(data_xl)[colnumber] <- paste0("EQSclass_", last_year)

if (FALSE){
  # For checking
  data_xl %>% filter(Basis %in% c("WW","FB") & PARAM %in% EQS_limits$PARAM) %>% select(PARAM, LATIN_NAME, Basis, Yr_2021, EQSclass_2021, EQS) %>% View("eqs1") 
  data_xl %>% filter(Basis %in% c("WW") & PARAM %in% "CB_S6_exloq") %>% select(PARAM, LATIN_NAME, Basis, Yr_2021, EQSclass_2021, EQS) %>% View("eqs2") 
}

cat("\nNumber of columns:", ncol(data_xl), "\n") # still 116


```

### Add OC  
No data  
```{r}

data_xl$OC <- NA
cat("\nNumber of columns:", ncol(data_xl), "\n") # 113

```


### Trends for last year - make 'trends_for_excel' 

```{r}

# dir("Data", "126")

# Imitate to the last detail the previous version of 'trends_for_excel' data frame  
trends_for_excel <- trends_last_year %>%
  mutate(`Last Year(long)` = last_year,
         `Last Year(short)` = last_year-1) %>%
  select(PARAM, LATIN_NAME, TISSUE_NAME, STATION_CODE, Basis,
         p_long, Perc_change_long, First_year_long, `Last Year(long)`, N_years,
         p_short, Perc_change_short, First_year_short, `Last Year(short)`,  N_years_10yr,
         Trend_symbol) %>%
  rename(`Trend p(long)` = p_long, `Detectable % change(long)` = Perc_change_long, `First Year(long)`= First_year_long, 'No of Years(long)' = N_years,
         `Trend p(short)` = p_short, `Detectable % change(short)` = Perc_change_short, `First Year(short)`= First_year_short, 'No of Years(short)' = N_years_10yr)

names(trends_for_excel)[names(trends_for_excel) == "Trend_symbol"] <- paste0("Trends.", last_year)
  
```


### Trends for last year - add 'trends_for_excel' columns  
```{r}

# Key columns:
cols <- c("PARAM", "LATIN_NAME", "TISSUE_NAME", "STATION_CODE", "Basis")

data_xl_b <- data_xl  # backup data
# data_xl <- data_xl_b  # restore from backup, if needed

data_xl <- safe_left_join(
  data_xl, 
  trends_for_excel, 
  by = cols, 
  na_matches = "never",
  check = "BCV")

cat("\nNumber of columns:", ncol(data_xl), "\n") # 124
# colnames(data_xl) 

```

### Trends from second last year - preparations  
```{r, results='hold'}

# Key columns:
cols <- c("PARAM", "LATIN_NAME", "TISSUE_NAME", "STATION_CODE", "Basis")
# debugonce(set_symbol)

# Make data frames with trend symbols 
trend_long_for_excel_seclast <- make_trend_data_for_excel2(result_long_seclast, data_xl[,cols])
trend_10yr_for_excel_seclast <- make_trend_data_for_excel2(result_10yr_seclast, data_xl[,cols])

# head(trend_long_for_excel_seclast, 2)

# Combine log + 10yr and prepare even more for Excel
trends_for_excel_seclast <- combine_long_and_short_trends_for_excel2(trend_long_for_excel_seclast, 
                                                                     trend_10yr_for_excel_seclast)

cat("'trends_for_excel_seclast', number of lines:", nrow(trends_for_excel), "\n\n")  # 29582

cat("'trends_for_excel_seclast', values: \n")  # 29582
table(trends_for_excel_seclast$Trend.year)

# Existing names
var2 <- c("Trend p(long)", "Detectable % change(long)", "First Year(long)", "Last Year(long)",
          "No of Years(long)", "Trend p(short)", "Detectable % change(short)", "First Year(short)", "Last Year(short)",
          "No of Years(short)")
if (sum(colnames(trends_for_excel_seclast) %in% var2) != 10){
  message("Warning: one of the names doesn't fit (should be 10 names fitting)")
}

var2_new <- paste(var2, last_year-1)

# Set new names
for (i in 1:length(var2_new)){
  sel <- colnames(trends_for_excel_seclast) == var2[i]
  colnames(trends_for_excel_seclast)[sel] <- var2_new[i]
}

# Change last column name
colnumber <- which(colnames(trends_for_excel_seclast) %in% "Trend.year")
colnames(trends_for_excel_seclast)[colnumber] <- paste0("Trends.", last_year-1)
# colnames(trends_for_excel)


check <- trends_for_excel_seclast %>%
  group_by(STATION_CODE, LATIN_NAME, TISSUE_NAME, PARAM, Basis) %>%
  summarise(N = n())
cat("Number of duplicates in 'trends_for_excel_seclast' (should be zero):", sum(check$N > 1), "\n")   

# If there are duplicates, check data:
if ( sum(check$N > 1)){
  table(check$N)
  check %>% filter(N > 1) %>% head(10)
  df1 <- check %>% filter(N > 1) %>% head(1)
  check2 <- trends_for_excel_seclast %>% 
    filter(STATION_CODE %in% df1$STATION_CODE, LATIN_NAME %in% df1$LATIN_NAME, 
           TISSUE_NAME %in% df1$TISSUE_NAME, PARAM %in% df1$PARAM, Basis %in% df1$Basis)
  check2
}

```

### Remove duplicates for PAH metabolites  
* These were "artifially" added in script 110, part 3B  
* For some reason this causes duplicates in 'make_trend_data_for_excel2' function  
* We should check why this happens, but below is a quick fix  
* Also happens for 'last year', see above    
```{r}

if (FALSE){
  
  # For demonstrating the problem

  # This one is not OK - duplicates, with identical values:
  trends_for_excel_seclast %>%
    filter(PARAM == "PYR1OH" & Basis == "WW") %>%
    arrange(STATION_CODE) %>%
    View()
}

check_duplicates <- trends_for_excel_seclast %>%
  count(PARAM, LATIN_NAME, TISSUE_NAME, STATION_CODE, Basis) %>%
  filter(n > 1)

# Check that the problem is only for PAH metabolites  
check <- mean(unique(check_duplicates$PARAM) == c("BAP3OH", "PA1OH", "PYR1OH"))

cat("trends_for_excel_seclast - number of lines before fixing:", nrow(trends_for_excel_seclast), "\n")

if (nrow(check_duplicates) == 0){
  message("No duplicates to fix")
} else if (check == 1){
  trends_for_excel_seclast <- trends_for_excel_seclast %>%
    ungroup() %>%
    group_by(PARAM, LATIN_NAME, TISSUE_NAME, STATION_CODE, Basis) %>%
    summarise(across(.fns = first), .groups = "drop")
} else {
  stop("We seem to have a problem for something else than PAH metabolites!")
}

cat("\n")
cat("trends_for_excel_seclast - number of lines after fixing:", nrow(trends_for_excel_seclast), "\n")

```



### Trends from second last year - add columns to data

```{r}
data_xl_b <- data_xl    # backup
# data_xl <- data_xl_b  # revert to backup

data_xl <- safe_left_join(
  data_xl, 
  trends_for_excel_seclast, 
  by = cols,
  na_matches = "never",
  check = "BCV")

cat("\nNumber of columns:", ncol(data_xl), "\n") # 135

```

### Add "Last_two_years" +  "DETLIM_..." for second last year  

```{r}
#
# Last_two_years
#
data_xl$Last_two_years <- NA

#
# DETLIM for second last year
#
cols <- c("PARAM", "LATIN_NAME", "TISSUE_NAME", "STATION_CODE", "Basis", paste0("Det_limit_", last_year-1))

if ("Det_limit" %in% names(results_seclast_year)){
  sel <- names(results_seclast_year) == "Det_limit"
  names(results_seclast_year)[sel] <- paste0("Det_limit_", last_year-1)
}

# dput(colnames(results_seclast_year))
# results_seclast_year[1, cols[1:5]]

data_xl_b <- data_xl  # backup
# data_xl <- data_xl_b

data_xl <- safe_left_join(
  data_xl, 
  results_seclast_year[,cols], 
  by = c("PARAM", "LATIN_NAME", "TISSUE_NAME", "STATION_CODE", "Basis"),
  na_matches = "never",
  check = "BCV")

cat("\nNumber of columns:", ncol(data_xl), "\n") # 137

```

### Add "DETLIM_..." for last year  

```{r}

cols <- c("PARAM", "LATIN_NAME", "TISSUE_NAME", "STATION_CODE", "Basis", "Det_limit")

# dput(colnames(results_seclast_year))
# results_seclast_year[1, cols[1:5]]

# check <- data_med2 %>%
#   group_by(PARAM, LATIN_NAME, TISSUE_NAME, STATION_CODE, Basis) %>%
#   summarize(N = n())
# table(check$N)
# check2 <- check %>% filter(N > 1) %>% head(1)
# data_med2 %>% filter(PARAM %in% check2$PARAM &
#                      LATIN_NAME %in% check2$LATIN_NAME & 
#                      TISSUE_NAME %in% check2$TISSUE_NAME &
#                      STATION_CODE %in% check2$STATION_CODE &
#                      Basis %in% check2$Basis)


data_xl_b <- data_xl  # backup
# data_xl <- data_xl_b

sel <- data_med2$MYEAR %in% last_year
data_xl <- safe_left_join(
  data_xl, 
  data_med2[sel,cols], 
  by = c("PARAM", "LATIN_NAME", "TISSUE_NAME", "STATION_CODE", "Basis"),
  na_matches = "never",
  check = "BCV")

# Change name of last variable (add year)
sel <- length(names(data_xl))
names(data_xl)[sel] <- paste0("Det_limit_", last_year)

cat("\nNumber of columns:", ncol(data_xl), "\n") # 138


```

### Detection limit for BDESS_exloq (1) 

**WARNING: HARD_CODED FOR 2021!** 

- Sum BDE 6 (excl LOQ) 
- Get/estimate detection limit   


```{r}

if (FALSE){
  
  # Columns to check
  put(tail(names(data_xl), 30))
  nm <- c("PARAM", "LATIN_NAME", "TISSUE_NAME", "Yr_2021", "EQS_2021", "EQSclass_2021", "EQS", "Det_limit_2020", "Det_limit_2021")
  
  # all data
  data_xl[nm] %>% View("all")  
  
  # List parameters  
  data_xl %>% filter(grepl("BDE", PARAM) & Basis %in% "WW") %>% pull(PARAM) %>% unique()

  # BDE209 as example - Det_limit_2021 varies  
  data_xl %>%
    filter(!is.na(Det_limit_2021) & PARAM %in% "BDE209" & Basis %in% "WW") %>% .[nm] %>% View("bde")

  # BDE6S as example - only exists for eider duck blood  
  data_xl %>%
    filter(!is.na(Det_limit_2021) & PARAM %in% "BDE6S" & Basis %in% "WW") %>% .[nm] %>% View("bde")

}

params <- c("BDE28", "BDE47", "BDE99", "BDE100", "BDE153", "BDE154")    # from script "101...functions.R"  

df1 <- data_xl %>%
  filter(PARAM %in% params & !is.na(Det_limit_2021)) %>%
  group_by(PARAM, LATIN_NAME, TISSUE_NAME, Basis) %>%
  summarize(
    Det_limit_2021 = median(Det_limit_2021, na.rm  = TRUE), 
    Det_limit_2021_min = min(Det_limit_2021, na.rm  = TRUE),  
    Det_limit_2021_max = max(Det_limit_2021, na.rm  = TRUE),  
    Det_limit_2021_range = Det_limit_2021_max - Det_limit_2021_min,
    .groups = "drop") %>%
  arrange(Basis, LATIN_NAME, TISSUE_NAME)

table(df1$PARAM)

# Show existence of LOQ by parameter and species-tissue  
xtabs(~PARAM + paste(LATIN_NAME, TISSUE_NAME), df1)

# Show level of LOQ by parameter and species-tissue  
df1 %>%
  filter(Basis == "WW") %>%
  mutate(Species_tissue = paste(LATIN_NAME, TISSUE_NAME)) %>%
  select(Species_tissue, PARAM, Det_limit_2021) %>%
  pivot_wider(names_from = Species_tissue, values_from = Det_limit_2021)

df2 <- df1 %>%
  group_by(LATIN_NAME, TISSUE_NAME, Basis) %>%
  summarize(Det_limit_2021_sum = sum(Det_limit_2021), 
            Det_limit_2021_min = min(Det_limit_2021), 
            n = n(), .groups = "drop") %>%
  #       Estimate      = sum LOQ for 3-6       (number of lacking)*(minimum LOQ)
  mutate(Det_limit_2021_new = Det_limit_2021_sum + (6-n)*Det_limit_2021_min,
         PARAM = "BDESS_exloq")

```


### Detection limit for BDESS_exloq (2)  

**WARNING: HARD_CODED FOR 2021!** 

- Add to data

```{r}

# data_xl_back <- data_xl

n1 <- nrow(data_xl)

data_xl_new <- data_xl %>%
  # Add column 'Det_limit_2021_new'
  left_join(df2 %>% select(PARAM, LATIN_NAME, TISSUE_NAME, Basis, Det_limit_2021_new), 
            by = c("PARAM", "LATIN_NAME", "TISSUE_NAME", "Basis")) %>%
  # Set missing values in column 'Det_limit_2021'
  mutate(Det_limit_2021 = case_when(
    PARAM %in% "BDESS_exloq" & is.na(Det_limit_2021) ~ Det_limit_2021_new,
    TRUE ~ Det_limit_2021)
    )

n2 <- nrow(data_xl_new)

if (n1 != n2){
  stop("Left join - row numbers should not change!")
}

# Check
# data_xl_new %>% filter(PARAM %in% "BDESS_exloq" & Basis %in% "WW") %>% count(PARAM, LATIN_NAME, TISSUE_NAME, Basis, Det_limit_2021, Det_limit_2021_new)

# Remove column 'Det_limit_2021_new'
data_xl <- data_xl_new %>%
  select(-Det_limit_2021_new)

```


### Remove last year's EQS where it is lower than detection limit  

**WARNING: HARD_CODED FOR 2021!** 


```{r}

sel1 <- !is.na(data_xl$Det_limit_2021) & !is.na(data_xl$EQS); sum(sel1)
sel2 <- with(data_xl, sel1 & EQS < Det_limit_2021); sum(sel2)

# Check
# data_xl[sel2, nm] %>% View("EQS problem")  

data_xl[sel2, "EQS_2021"] <- ""
data_xl[sel2, "EQSclass_2021"] <- NA

cat(sum(sel2), "EQS values deleted becaus they were lower than detection limit \n\n")  

cat("Deleted: \n")
xtabs(~paste(LATIN_NAME, TISSUE_NAME) + PARAM, data_xl[sel2,])

if (FALSE){
  
  param <- "BDESS_exloq"
  param <- "BDE47"
  sel <- with(data_xl, PARAM %in% param & Basis %in% "WW")
  data_xl[sel, nm] %>% View(param)  
  
  data_med2 %>% 
    filter(PARAM %in% param & Basis %in% "WW" & MYEAR == 2021) %>%
    group_by(LATIN_NAME, TISSUE_NAME, Basis) %>%
    summarize(Over_LOQ, N_median)
    
}
```


### Add trend and EQS change  

4 columns: TREND_CHANGE	CLASS_CHANGE	EQS_CHANGE	EAC_CHANGE  

```{r}

# TREND_CHANGE
col_last <- paste0("Trends.", last_year)
col_seclast <- paste0("Trends.", last_year - 1)
sel <- !is.na(data_xl[,col_seclast]) & !is.na(data_xl[,col_last]) & data_xl[,col_seclast] != data_xl[,col_last]
data_xl$TREND_CHANGE <- NA
data_xl$TREND_CHANGE[sel] <- paste(data_xl[sel,col_seclast], "to", data_xl[sel,col_last])

cat("Number of changes in trend:", sum(sel), "\n")

# CLASS_CHANGE
col_last <- paste0("Klasse.", last_year)
col_seclast <- paste0("Klasse.", last_year - 1)
sel <- !is.na(data_xl[,col_seclast]) & !is.na(data_xl[,col_last]) & data_xl[,col_seclast] != data_xl[,col_last]
data_xl$CLASS_CHANGE <- NA
data_xl$CLASS_CHANGE[sel] <- paste(data_xl[sel,col_seclast], "to", data_xl[sel,col_last])

cat("Number of changes in class:", sum(sel), "\n")

# Check
# table(data_xl$CLASS_CHANGE)

# EQS classes second last year
value_seclast <- data_xl[,paste0("Yr_", last_year - 1)]
lessthan_seclast <- data_lessthans[,paste0("Lt_", last_year - 1)]
# Less-thans are set a tad lower, to be put in the lower class
sel <- !is.na(lessthan_seclast) & lessthan_seclast
value_seclast[sel] <- value_seclast[sel] - 0.00001
EQSclass_seclast <- cut(value_seclast/data_xl$EQS, breaks = c(-999999,1,999999), right = FALSE, labels = FALSE)

# EQS classes last year
EQSclass_last <- data_xl[,paste0("EQSclass_", last_year)]

# Set EQS_CHANGE
data_xl$EQS_CHANGE <- NA
sel <- !is.na(EQSclass_seclast) & !is.na(EQSclass_last) & 
        EQSclass_seclast != EQSclass_last  # pick all that are different
sum(sel)
data_xl$EQS_CHANGE[sel] <- paste(EQSclass_seclast[sel], "to", EQSclass_last[sel])

cat("Changes in EQS class: \n")
table(data_xl$EQS_CHANGE)

# 1 to 2 2 to 1 
#      4     11

# EAC_CHANGE is not used
data_xl$EAC_CHANGE <- NA

cat("\nNumber of columns:", ncol(data_xl), "\n") # 142

```


### D.d.i.- add to data
```{r}

cols <- c("PARAM", "LATIN_NAME", "TISSUE_NAME", "STATION_CODE", "Basis", "DDI")

data_xl_b <- data_xl    # backup
# data_xl <- data_xl_b  # restore from backup

data_xl <- safe_left_join(
  data_xl, 
  dat_ddi[,cols], 
  by = c("PARAM", "LATIN_NAME", "TISSUE_NAME", "STATION_CODE", "Basis"),
  na_matches = "never",
  check = "BCV")

cat("\nNumber of columns:", ncol(data_xl), "\n") # 143

```

#### Check D.d.i.  
```{r}

if (FALSE){
  
  # colnames(data_xl)[seq(91,101,2)] %>% dput()
  
  vars <- c("PARAM", "STATION_CODE", "Basis", "Yr_2018", "Yr_2019", "DDI")
  
  data_xl[vars] %>%
    filter(STATION_CODE == "30B" & Basis == "WW")
  
  data_xl[vars] %>%
    filter(STATION_CODE == "36A" & PARAM == "% C" & Basis == "WW")
  
  data_xl[vars] %>%
    filter(is.na(DDI))
  
}

```


### Add trends as given 2016   
*Not* second last year - fixed to 2016     
- Using the old OSPAR rules for less-thans   
```{r}

var1 <- c("PARAM", "LATIN_NAME", "TISSUE_NAME", "STATION_CODE", "Basis")

# Just for checking....
if (FALSE){
  var2 <- c("Trend.p.long.", "Detectable...change.long.", "First.Year.long.", "Last.Year.long.",
            "No.of.Years.long.", "Trend.p.short.", "Detectable...change.short.",
            "First.Year.short.", "Last.Year.short.", "No.of.Years.short.",
            "Trends.2016.old")
  
  var2 %in% colnames(results_seclast_year)
  which(colnames(results_seclast_year) %in% var2)
}

data_xl_b <- data_xl  # backup
# data_xl <- data_xl_b

data_xl <- safe_left_join(
  data_xl, 
  results_seclast_year[,c(var1, "Trends.2016.old")], 
  by = var1, 
  na_matches = "never",
  check = "BCV")

cat("\nNumber of columns:", ncol(data_xl), "\n") # 144

```

### Add D.d.i. code  
This is an index number, but we can't add it yet since we need to keep the original row order for making 'data_xl_lessthans', and then rows will be reordered   
```{r}

data_xl <- data_xl %>%
  mutate(`D.d.i. code` = as.numeric(NA))

cat("\nNumber of columns:", ncol(data_xl), "\n") # 144


if (FALSE){
  head(data_xl$`D.d.i. code`)
  tail(data_xl$`D.d.i. code`)
  names(data_xl )
}

```




## 6. Add less-than columns   


### Check number of rows  
```{r}
# Using 'data_lessthans' created further up (1b)

# Check again
n1 <- nrow(data_lessthans)  # 29539
n2 <- nrow(data_xl)  # 29539

n_equal <- n1 == n2
if (!n_equal){
  cat("\n\n\n\n################################\n No. of rows differ! \n\n\n\n################################")
} else {
  cat("\nNumber of rows equal\n")
}
```

### Sort them equally
```{r}
# Sort them equally
data_xl <- data_xl %>%
  arrange(PARAM, STATION_CODE, LATIN_NAME, TISSUE_NAME, Basis)

data_lessthans <- data_lessthans %>% 
  arrange(PARAM, STATION_CODE, LATIN_NAME, TISSUE_NAME, Basis)

# Must be only zeros
ch1 <- sum(data_xl$PARAM != data_lessthans$PARAM)
ch2 <- sum(data_xl$STATION_CODE != data_lessthans$STATION_CODE)
ch3 <- sum(data_xl$LATIN_NAME != data_lessthans$LATIN_NAME)
ch4 <- sum(data_xl$TISSUE_NAME != data_lessthans$TISSUE_NAME)
ch5 <- sum(data_xl$Basis != data_lessthans$Basis)

all_match <- ch1 == 0 & ch2 == 0 & ch3 == 0 & ch4 == 0 & ch5 == 0
if (!all_match){
  cat("\n\n\n\n")
  message("################################")
  message("Lack of match in key variables! Check ch1-ch5")
  message("################################")
} else {
  cat("\nAll key variables matches\n")
}

```

###  Intersperse empty columns  
```{r}
# Intersperse empty columns 
# colnames(data_lessthans)
extra_cols <- matrix(NA, nrow(data_lessthans), sum(isnum)) %>% as.data.frame()
colnames(extra_cols) <- paste0(colnames(data_lessthans)[isnum], "x")
# str(extra_cols)
data_lessthans2 <- cbind(data_lessthans, extra_cols)
# dput(sort(colnames(data_lessthans2)))
```

### Create data_xl_lessthans
```{r}

# Construct column names
# The ones with an "x" is just empty columns, they are tehre because there is an EQS column between each 
#   vakue column
txt1 <- rep(1981:last_year, each = 2)
txt2 <- rep(c("", "x"), length(txt1)/2)
cols <- paste0("Lt_", txt1, txt2)

# Select columns 
data_lessthans2 <- data_lessthans2[,cols]
# str(data_lessthans2)

if (n_equal & all_match){
  data_xl_lessthans <- cbind(data_xl, data_lessthans2)
  cat("\ndata_xl_lessthans created by adding less-than columns\n")
} else {
  cat("\nndata_xl_lessthans NOT created!\n")
}


```

### Reorder rows in the data a bit   
We do this in order to get some much-used parameters in the top of the file,
 so Excel more easily put the right data type
```{r}

data_xl_lessthans$Substance.Group <- factor(data_xl_lessthans$Substance.Group) %>%
  forcats::fct_relevel("Support parameters",
                       "Metals and metalloids", "Chlorobiphenyls",
                       "Polycyclic aromatic hydrocarbons (PAHs)")

data_xl_lessthans <- data_xl_lessthans %>%
  arrange(Substance.Group, PARAM, STATION_CODE)

```

### Add values in D.d.i. code  
Still just an index number    
Making 'data_xl_lessthans' involves putting togethe
We have to do this before we have made 'data_xl_lessthans'  
```{r}

data_xl_lessthans <- data_xl_lessthans %>%
  mutate(`D.d.i. code` = 1:nrow(data_xl_lessthans))

if (FALSE){
  head(data_xl$`D.d.i. code`)
  tail(data_xl$`D.d.i. code`)
}

```

### Change tissue names to English  
To be on the safe side, added as TISSUE_NAME_new, which later is copied to TISSUE_NAME and then deleted
```{r}

xtabs(~addNA(TISSUE_NAME), data_xl_lessthans)

data_xl_lessthans <- data_xl_lessthans %>%
  mutate(TISSUE_NAME_new = 
           case_when(TISSUE_NAME %in% "Blod" ~ "Blood",
                     grepl("Egg", TISSUE_NAME) ~ "Egg",
                     TISSUE_NAME %in% "Galle" ~ "Bile",
                     TISSUE_NAME %in% "Muskel" ~ "Muscle",
                     TISSUE_NAME %in% "Lever" ~ "Liver",
                     TISSUE_NAME %in% "WO" ~ "Whole organism",
                     TRUE ~ TISSUE_NAME)
  )

xtabs(~addNA(TISSUE_NAME_new), data_xl_lessthans)

# Replace the original TISSUE_NAME
data_xl_lessthans$TISSUE_NAME <- data_xl_lessthans$TISSUE_NAME_new

# Delete TISSUE_NAME_new
data_xl_lessthans$TISSUE_NAME_new <- NULL


cat("\nNumber of columns:", ncol(data_xl_lessthans), "\n") # 222

```

### Add Class for second last year (2017)  
```{r}

colnumber_value <- which(colnames(data_xl) == paste0("Yr_", last_year-1)); colnumber_value
value_secondlast <- data_xl[,colnumber_value]

colnumber_lessthan <- which(colnames(data_lessthans) == paste0("Lt_", last_year-1)); colnumber_lessthan
lessthan_lastyear <- data_xl[,colnumber_value]

# Less-thans are set a tad lower, to be put in the lower class
sel <- !is.na(lessthan_lastyear) & lessthan_lastyear
value_secondlast[sel] <- value_secondlast[sel] - 0.00001

# Just to check that we get the correct classes, i.e., if the conc. is on the limit, we get the upper class (using right = FALSE)
check_classes <- cut(value_secondlast/data_lessthans$Q95, breaks = c(-999999,1,2,5,10,20,999999), right = FALSE)
levels(check_classes)

class_secondlast <- cut(value_secondlast/data_xl$Q95, breaks = c(-999999,1,2,5,10,20,999999), right = FALSE, labels = FALSE)
# str(class_secondlast)
# summary(class_secondlast)
# table(addNA(class_secondlast))

# Make variable
data_xl_lessthans$Klasse.secondlast <- class_secondlast

# Tabulate
# table(addNA(data_xl$Klasse.lastyear))

# Set variable name
colnames(data_xl_lessthans)[ncol(data_xl_lessthans)] <- paste0("Klasse.", last_year-1, " NY")

nrow(data_xl_lessthans)  # 19304

cat("\nNumber of columns:", ncol(data_xl_lessthans), "\n") # 219


```

### Change a couple of sum PARAM names   
```{r}

sel <- data_xl_lessthans$PARAM %in% "KPAH"; sum(sel)
data_xl_lessthans$PARAM[sel] <- "PK_S"

sel <- data_xl_lessthans$PARAM %in% "PAH16"; sum(sel)
data_xl_lessthans$PARAM[sel] <- "PAHSS"

```

### Add coordinates  
```{r}

data_xl_lessthans <- data_xl_lessthans %>%
  safe_left_join(data_coordinates %>% select(STATION_CODE, Long, Lat),
                 by = "STATION_CODE",
                 check = "BCV",
                 na_matches = "never")
```




### Change column names  

```{r}

data_xl_lessthans_oldnames <- data_xl_lessthans
# This is a backup. For restoring data:
# data_xl_lessthans <- data_xl_lessthans_oldnames 

# Remove this column 
data_xl_lessthans <- data_xl_lessthans %>%
  select(-Trends.2016.old)

# lookup file
df_colnames_orig <- readxl::read_excel(
  "Input_data/Column headings v0409_2020_edit.xlsx") %>%
  mutate(
    New_name = case_when(
      is.na(Edited) ~ Norman,
      !is.na(Edited) ~ Edited),
    Current = ifelse(Current == "SD.2018", "SD_2018", Current)
  ) %>%
  arrange(Col_no)  # this defines the order of the columns

# Update column names of trends etc
i <- 103:nrow(df_colnames_orig)
df_colnames_orig$Current[i] <- sub("2019", last_year, df_colnames_orig$Current[i])
df_colnames_orig$Current[i] <- sub("2018", last_year-1, df_colnames_orig$Current[i])

# For adding new years after 2019 
df_colnames_add <- data.frame(
  Col_no = seq(102.01, by = 0.01, length = 2*(last_year-2020+1)),
  Current = paste0(
    rep(c("Yr_", "EQS_"), last_year-2020+1),
    rep(2020:last_year, each = 2)
  ),
  New_name = paste0(
    rep(c("V", "Q"), last_year-2020+1),
    rep(2020:last_year-2000, each = 2)
  )
)

# Add new years after 2019 
df_colnames <- bind_rows(df_colnames_orig, df_colnames_add) %>%
  arrange(Col_no)  # this defines the order of the columns
  
#
# For checking:
#
check_colnames <- data.frame(
  Current = names(data_xl_lessthans)
) %>%
  left_join(df_colnames, by = "Current")

# View(check_colnames)



# Columns that will change names (and order) are all in the left part 

# Left part of file: all columns until column before Lt_1981
n1 <- 1
n2 <- which(names(data_xl_lessthans) %in% "Lt_1981") - 1   # all columns until column before Lt_1981
# Right part of file
n3 <- which(names(data_xl_lessthans) %in% "Lt_1981")       # Lt_1981
n4 <- ncol(data_xl_lessthans)

# Original names
orig_names <- names(data_xl_lessthans)[n1:n2]   # Column names in left part of the file   

# Check that all original names are found in lookup file
check <- orig_names %in% as.data.frame(df_colnames)$Current
if (sum(!check) > 0){
  cat("\n\n****************************\ncolumn names are not found in the lookup file:")
  orig_names[!check]
  stop("Some column names are not found in the lookup file! ")
}

# Pick and sort 
old_names_ordered <- df_colnames %>% 
  filter(!is.na(Col_no)) %>% 
  pull(Current)
new_names <- df_colnames %>% 
  filter(!is.na(Col_no)) %>% 
  pull(New_name)

# Reorder and rename left part of table
df_left_part <- data_xl_lessthans[old_names_ordered]
names(df_left_part) <- new_names

# Get right part of table
df_right_part <- data_xl_lessthans[n3:n4]

# Put it all together
data_xl_lessthans <- bind_cols(df_left_part, df_right_part)

if (FALSE){
  names(data_xl_lessthans)
}

# Write out
x <- names(data_xl_lessthans)
cat("Names of first columns: \n")
new_names[1:22]
cat("\n")
cat("Names of columns of median values: \n")
cat("  ", x[23], "etc. +", x[24], "etc. \n")
cat("\n")
cat("Names of last columns: \n")
#  names(data_xl_lessthans)
i1 <- max(which(grepl("^Q[0-9][0-9]$", x))) + 1
i2 <- min(which(grepl("Lt_", x))) - 1
x[i1:i2]

```

### For checking
```{r}
if (FALSE){
  
  data_xl_lessthans[c("Parameter Code", "Parameter Group", "V81", "V19")] %>% View()
  
  data_xl_lessthans[c("Parameter Code", "V81", "V19")] %>%
    group_by(`Parameter Code`) %>%
    summarise_all(.funs = function(x) sum(is.na(x))) %>%
    mutate(Sum = V81 + V19) %>%
    arrange(desc(Sum))
  
  data_xl_lessthans[c("Parameter Code", "V81", "V19")] %>%
    group_by(`Parameter Code`) %>%
    summarise_all(.funs = function(x) sum(is.na(x))) %>%
    mutate(Sum = V81 + V19) %>%
    arrange(desc(Sum))
  
  names(data_xl_lessthans_oldnames)
  data_xl_lessthans_oldnames %>% 
    select(PARAM, LATIN_NAME, TISSUE_NAME, Basis, Yr_2019, N_string, SD_last) %>%
    View()

}


```




## 7. Save 'data_xl_lessthans' as text and RDS file  

```{r, results = 'hold'}

#
# Existing file names (dates and versions)
#
fns <- dir("Big_excel_table", pattern = "Data_xl_.+.csv") %>% rev()
fns_date <- substr(fns, 9, 18)
m <- regexpr("ver[0-9]+", fns)
fns_ver <- regmatches(fns, m) %>% substr(4,5) %>% as.numeric()
n <- length(fns_ver)
file_versions <- tibble(Filename = fns[1:n], Date = fns_date[1:n], Version = fns_ver) %>%
  arrange(desc(Date), desc(Version))
file_versions

#
# csv
#

# Version number to use
# - if file with same date exists in the folder, we increase the version by 1
# - if file with same date does not exist, we set version to 1
fn_version <- case_when(
  file_date == file_versions$Date[1] ~ file_versions$Version[1] + 1,
  file_date != file_versions$Date[1] ~ 1
)
fn_version_txt <- sprintf("%02i", fn_version)

# File name to use
fn <- paste0("Data_xl_", file_date, "_ver", fn_version_txt, ".csv")
fn_full <- paste0("Big_excel_table/", fn)


if (fn %in% dir("Big_excel_table")){
  cat("File", fn, "already exists! File will not be overwritten.")
} else {
  # Save CSV
  if (decimal_comma){
    write.csv2(data_xl_lessthans, file = fn_full, quote = FALSE, na = "", row.names = FALSE)
  } else {
    write.csv(data_xl_lessthans, file = fn_full, quote = FALSE, na = "", row.names = FALSE)
  }
  cat("Text file", sQuote(fn), "written to folder 'Big_Excel_table'\n")
  # Save RDS
  saveRDS(data_xl_lessthans_oldnames, sub("csv", "rds", fn_full))
  cat("R data file", sQuote(sub("csv", "rds", fn)), "written to folder 'Big_Excel_table'\n")
}

#
# For map-making
#
fn_stations <- paste0("201_Stations_", last_year, ".xlsx")
data_xlvalues1 %>%
  filter(MYEAR %in% last_year) %>%
  count(STATION_CODE, LATIN_NAME) %>%
  arrange(STATION_CODE) %>% 
  writexl::write_xlsx(paste0("Data/", fn_stations))
cat("\n")
cat("Excel file", sQuote(fn_stations), "(one line per station) written to folder 'Data'\n")

```
### For checking (old) files  
```{r}

#
# NOTE: don't run all of the stuff inside the brackets
# These are code snippets, so you are meant to pick and choose
# (for instance, it doesn't make sense to make 'check' first by reading the text file,
#   and then by reading the rds file. You only need to do one of them.)
#
if (FALSE){
  
  #
  # Existing file names (dates and versions)
  #
  fns <- dir("Big_excel_table", pattern = "Data_xl_.+.csv") %>% rev()
  # OR:
  # fns <- dir("Big_excel_table", pattern = "Data_xl_.+.rds") %>% rev()
  fns_date <- substr(fns, 9, 18)
  m <- regexpr("ver[0-9]+", fns)
  fns_ver <- regmatches(fns, m) %>% substr(4,5) %>% as.numeric()
  n <- length(fns_ver)
  file_versions <- tibble(Filename = fns[1:n], Date = fns_date[1:n], Version = fns_ver) %>%
    arrange(desc(Date), desc(Version))
  file_versions
  
  # Newest version = version 1 (Filename[1])
  fn <- paste0("Big_excel_table/", file_versions$Filename[1])
  fn


  # read R data (fast)
  check <- readRDS(file = sub(".csv", ".rds", fn, fixed = TRUE))

  # OR read csv (slow)
  # check <- read.csv2(file = fn)

  # Check header of csv:
  # readLines(fn, n = 1)

  # All column names
  names(check)
  
  # Check, selected columns
  check %>%
    select(PARAM, Substance.Group, LATIN_NAME, TISSUE_NAME, STATION_CODE, Basis, 
         Yr_2016, Yr_2017, Yr_2018, Yr_2019, EQS_2019, Yr_2020, EQS_2020, Yr_2021, EQS_2021, N_string, SD_last, EQS) %>%
    View("check")

  # Check, selected columns with trends
  check %>%
    filter(Basis == "WW") %>%
    select(PARAM, Substance.Group, LATIN_NAME, TISSUE_NAME, STATION_CODE, Basis, 
         Yr_2019, EQS_2019, Yr_2020, EQS_2020, Yr_2021, EQS_2021, N_string, SD_last, EQS, Trends.2020, Trends.2021) %>%
    View("check")

  # Check data for all TBT
  check %>%
    filter(PARAM == "TBT" & Basis == "WW") %>%
    select(PARAM, Substance.Group, LATIN_NAME, TISSUE_NAME, STATION_CODE, Basis, 
         Yr_2018, Yr_2019, Yr_2020, N_string, SD_last, EQS) %>%
    View()

  # Check data for all TBT
  check %>%
    filter(PARAM == "HG" & Basis == "WW" & STATION_CODE == "30B") %>%
    select(PARAM, Substance.Group, LATIN_NAME, TISSUE_NAME, STATION_CODE, Basis, 
         Yr_2018, Yr_2019, N_string, SD_last, EQS, Trends.2019) %>%
    View()

  # Check all data for one snail station
  check %>%
    filter(Basis == "WW" & STATION_CODE == "71G") %>%
    select(PARAM, Substance.Group, LATIN_NAME, TISSUE_NAME, STATION_CODE, Basis, 
         Yr_2003, Yr_2010, Yr_2014, Yr_2018, Yr_2019, N_string, SD_last, EQS) %>%
    View("11G")

  check %>%
    filter(Basis == "WW" & STATION_CODE == "30B" & PARAM == "HG") %>%
    select(PARAM, Substance.Group, LATIN_NAME, TISSUE_NAME, STATION_CODE, Basis, 
           Yr_2003, Yr_2010, Yr_2014, Yr_2018, Yr_2019, N_string, SD_last, EQS, Trends.2019) %>%
    View("check")
  
  # Read older version (check2) and compare number of rows and column 1:22 between check and check2: 
  fn2 <- paste0("Big_excel_table/", file_versions$Filename[2])
  check2 <- read.csv2(file = fn2)
  dim(check)
  dim(check2)
  i <- 1
  for (i in 1:22){
    cat(i, ":", sum(!check[[i]] == check2[[i]], na.rm = TRUE), "\n")
  }

    # colnames(check)
  colnames(check)[1:20]
  check <- check %>%
    rename(PARAM = Parameter.Code,
           STATION_CODE = Station.Code,
           TISSUE_NAME = Tissue)
  
  xtabs(~addNA(CLASS_CHANGE), check)
  
  check %>%
    xtabs(~addNA(CLASS_CHANGE), check)

  
  
}
```



## 8. APPENDIX 1. How to change the .csv file from this script into the finished Excel file     
This needs to be done in Excel, using some macros (stored in 'Data_xl_TEMPLATE.xlsm'). Also, opening the data in MS Excel is not straightforward, due to Linux/Windows differences in encodings.      

NOTE 1 (IMPORTANT!): Some variables in the macros must be adjusted EVERY YEAR, in order to accomodate for an increasing number of columns every year. Otherwise the macros in (4) will not work at all. The instructions for this is given in the macro script file in Excel (View : Macros : View Macros : [choose a random macro] : Edit)
  
NOTE 2: Step 1 requires Notepad++, which can be downloaded for free from https://notepad-plus-plus.org/    
  
1. Download the produced file, named "Data_xl_[some date]_[some version].csv", from Juputerhub to your own computer (in Jupyterlab, right click the file and "download"). For instance: Data_xl_2020-08-05_ver16.csv (   
    * This file should be in folder 'Big_excel_table'   
    * ...if you wondered, [some date] means the date of downloading data from Nivabasen, e.g. '2020-07-03'. The same date is used from script 101 through scripts 109, 110, 111, 120 and 201, so the actual date you run the scripts may well be later, bit that is not reflected by the file name.     
    * Also download the 'Data_xl_TEMPLATE.xlsm' file from Jupyterhub, if you haven't done so before  
    * Both should be put in the same directory. For DHJ: 'Milkys_pc/Files_from_Jupyterhub_2019/Big_excel_table'
2. Open the file in Excel in the following way:   
    * First, make a copy of the template file (for 2020, it is called 'Data_xl_TEMPLATE_2020.xlsm') using Ctrl-C + Ctrl-V and rename it with the same name as your csv file, except that you replace .csv by .xlsm (mark the csv file and press F2, Ctrl-C; mark the xlsm file and press F2, Ctrl-V)    
    * Open the xlsm file in Excel      
    * Open the csv file (the one from step 1) in Notepad++ (right-click in File Explorer, select Notepad++)
    * Mark all (Ctrl-A) and copy it (Ctrl-C)  
    * Paste (Ctrl-V) it into the top left cell in an empty sheet (e.g. sheet "Data") in the Excel file  
    * (The reason for this seemingly pointless detour is to handle encodings for Norwegian characters)
3. Now your data need to be split into columns. 
    * Mark the first column (A). 
    * Choose Data : Text to columns
    * Choose "Delimited" for file type, then click Next
    * Choose "Semicolon", then click Next
    * Click "Advanced" and make sure that decimal separetor is ",".  Click OK and hit "Finish".   
4. Go to View:Macros (may also be in Developer:Macros, depending on Excel setup) and run the macros given below (mark the macro you want and click "Run").
NOTE: if you have filtered the data, turn OFF all filtering of data before running any of the macros, or Excel may crash...
    * __Format_Cells_Lessthan_Shade_EQS__. This takes ca. 5 minutes (a pop-up will tell you when it has finished)
      (this formats cells with less-than values, shades cells according to Proref,
      and formats/and sets colors for the EQS dots)   
    * Mark the first cell in the Trends.2019 column (col. DV) and
      run __'Set_character_1_and_3_to_Wingdings'__  
    * Do the same for Trends.2018 (col. EG). Shortcut:  Ctrl+Y
    * Mark the first cell in the TREND_CHANGE column (col. EJ) and
      run __'Set_character_1_3_8_and_10_to_Wingdings'__  
5. Save excel file  
6. Copy it to K - in 2020 (2019 data) we used 'K:\Avdeling\Mar\NOG\JMG\2019\Tabeller'  

  
EXPECTED COLUMN POSITIONS FOR EXCEL MACROS TO WORK   
(these will change every year, so the macros must also be updated - see comments in macros)
2020 VERSION (last year = 2019)   
- Column Y = Yr1981  
- Column CW = Yr2019  
- Column EO = Lt_1981  
- Column HM = Lt_2019  
- Distance from Y to EO (Yr1981 to Lt_1981) = 120 columns  

## 9. APPENDIX 2. 

- Update 'Lookup for big excel - param.csv'  
- See section 2.e1  

```{r}

if (FALSE){
  
  df_par_old <- read.csv("Input_data/Lookup for big excel - param - OLD1.csv", sep = ";", dec = ",", stringsAsFactors = FALSE)
  
  df_par_original <- readxl::read_excel("Input_data/Lookup table - substance groups.xlsx") %>%
    # Add IUPAC from 'df_par_old'   
    left_join(df_par_old %>% select(Parameter.Code, IUPAC), by = c("PARAM" = "Parameter.Code"))
  
  # Check differences in Substance.Group 
  check <- df_par_original %>%
    full_join(df_par_old %>% select(Parameter.Code, Substance.Group) %>% rename(Substance.Group.old = Substance.Group), 
              by = c("PARAM" = "Parameter.Code")) %>%
    filter(!is.na(Substance.Group) & !is.na(Substance.Group.old)) %>%
    filter(Substance.Group != Substance.Group.old)
  nrow(check) # 4
  # 3 of them are Siloxanes -> Siloxans
  # the last is "Support parameters" to "Fat and dry weight"
  
  # Add lacking PARAM from df_par_old
  df_par_to_add <- df_par_old %>%
    select(Parameter.Code, Substance.Group, IUPAC) %>%
    rename(PARAM = Parameter.Code) %>%
    anti_join(df_par_original, by = "PARAM")
  
  df_par <- bind_rows(df_par_original, df_par_to_add)
  
  # Fill missing 'Parameter.Name' with PARAM values
  sel <- is.na(df_par$Parameter.Name)
  df_par$Parameter.Name[sel] <- df_par$PARAM[sel]
  
  write.csv(df_par, "Input_data/Lookup for big excel - param.csv")
  
}

```


## APPENDIX 3. Old code for getting last time trend results      

```{r, results='hold'}

# date_pattern <- "[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]"
# version_pattern <- "run[0-9][0-9]"

# cat("======================================\n")
# cat(" Trends for last year \n")
# cat("======================================\n")
# 
# pattern_10yr_last <- paste0("^120_result_10yr_", last_year, "_", 
#                             date_pattern, "_", version_pattern, ".rds$")
# pattern_long_last <- paste0("^120_result_long_", last_year, "_", 
#                             date_pattern, "_", version_pattern, ".rds$")
# 
# dir("Data", pattern = pattern_10yr_last)
# dir("Data", pattern = pattern_10yr_last)
# 
# result_10yr_last <- list_and_read_rds_file(
#   folder = "Data", 
#   pattern = pattern_10yr_last, 
#   check_date = data_list$file_date
# )
# result_long_last <- list_and_read_rds_file(
#   folder = "Data", 
#   pattern = pattern_long_last, 
#   check_date = data_list$file_date
# )



```

