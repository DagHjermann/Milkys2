---
title: "125 Calculate time trends using package leftadjusted"
output: html_document
---

Note: Ca 35 minutes run time for running all trends    

This procedure uses - at this point - data from script 105.  
- Should finally use data from script 109  


## 0. Constants (update each year)     
```{r}

last_year <- 2021

# Not used:
series_lastyear <- 2018   # The series must last at least until this year    
                          # Series without data in any of the three last years will be excluded

# folder_results <- paste0("Data/125_results_", last_year)
# 
# if (!dir.exists(folder_results)){
#   dir.create(folder_results)
# }

```
  
## 1. Libraries and functions  
```{r, results='hide', message=FALSE, warning=FALSE}

# install.packages("lubridate")

# General purpose
library(dplyr)
library(tidyr)
library(purrr)
library(mgcv)    #  mgcv_1.8-39
# install.packages("mgcv")  # for mgcv_1.8-40, b
# packageVersion("mgcv")
packageVersion("mgcv")
library(ggplot2)

# Specific for the analysis
library(rjags)
library(runjags)
if (!"leftcensored" %in% installed.packages())
  devtools::install_github("DagHjermann/leftcensored", upgrade = "never", force = TRUE)
library(leftcensored)

# For parallel computing
if (!"doParallel" %in% installed.packages())
  install.packages("doParallel")
library(doParallel)

# Load functions defined in other scripts  
source("125_Calculate_trends_leftadjusted_functions.R")
source("110_Medians_and_PROREF_functions.R")  # for homogenize_series
source("002_Utility_functions.R")


```

## 2. Read data  

### a. Main data  
Read and reformat the most recent data (by default)  
```{r, collapse=TRUE}

# If we have NOT length-adjusted the last year's data:
filepattern <- "105_data_with_uncertainty_"         # entire file name except date and extension

# Normally, if we have length-adjusted the last year's data:
# filepattern <- "109_adjusted_data_"       # entire file name except date and extension

filenumber <- 1                           # filenumber = 1 means "read the newest file"

files <- dir("Data", pattern = filepattern) %>% rev()

data_list <- read_rds_file("Data",
                     files, 
                     filenumber = filenumber,   # "1" gets the newest file   
                     get_date = TRUE, time_since_modified = TRUE)

dat_all <- data_list$data

# The file_date text will be used in part 10, when we save the resulting file
cat("File date text:", data_list$file_date, "\n")

```


### b. Homogenize time series  
Change STATION_CODE, in order to make a single time series for data with different STATION_CODE that in practice should count as the same station   
* Fixing station 227G1 and 227G2 (shall count as 227G)  
* Fixing station 36A and 36A1 (36A1 shall count as 36A)  
  
Also combines PARAM = VDSI and PARAM = Intersex to PARAM = "VDSI/Intersex" for station 71G  

```{r}

dat_all <- homogenize_series(dat_all)

```
### c. Prepare data  
```{r}

# These warnings can be ignored:
# Warning: Unknown or uninitialised column: `threshold`.
# Warning: Unknown or uninitialised column: `uncensored`.

dat_all_isotopes <- dat_all %>%
  filter(grepl("Delta", PARAM))

dat_all_with_zeros <- dat_all %>%
  filter(!grepl("Delta", PARAM)) %>%
  group_by(Substance.Group, PARAM, STATION_CODE, TISSUE_NAME, LATIN_NAME) %>%
  mutate(N_zeros = sum(VALUE_WW <= 0)) %>%
  filter(N_zeros > 0)

dat_all_sans_zeros <- dat_all %>%
  filter(!grepl("Delta", PARAM)) %>%
  group_by(Substance.Group, PARAM, STATION_CODE, TISSUE_NAME, LATIN_NAME) %>%
  mutate(N_zeros = sum(VALUE_WW <= 0)) %>%
  filter(N_zeros == 0)

dat_all_prep1_isotopes <- lc_prepare(dat_all_isotopes,
                           x = "MYEAR",
                           y = "VALUE_WW", 
                           censored = "FLAG1",
                           log = FALSE,
                           keep_original_columns = TRUE) 

dat_all_prep1_with_zeros <- lc_prepare(dat_all_with_zeros,
                           x = "MYEAR",
                           y = "VALUE_WW", 
                           censored = "FLAG1",
                           log = TRUE, const = 1,
                           keep_original_columns = TRUE) 

dat_all_prep1_sans_zeros <- lc_prepare(dat_all_sans_zeros,
                           x = "MYEAR",
                           y = "VALUE_WW", 
                           censored = "FLAG1",
                           log = TRUE,
                           keep_original_columns = TRUE) 

dat_all_prep1 <- bind_rows(
  dat_all_prep1_isotopes,
  dat_all_prep1_with_zeros,
  dat_all_prep1_sans_zeros
)

# Test
# lc_plot(dat_all_prep1 %>% filter(PARAM %in% "CB153" & STATION_CODE %in% "15A"))

```

### d. Add flags for rule 1 and rule 2 (columns Rule1 and Rule2)   


```{r}

# Test
# test1 <- dat_all_prep1 %>% filter(PARAM %in% "CB153") %>% split(.$STATION_CODE)
# test2 <- map_dfr(test1, leftcensored:::lc_flag1, show_result = FALSE)

# Make list
dat_all_prep1_list <- dat_all_prep1 %>% split(.$PARAM, .$STATION_CODE, .$LATIN_NAME, .$TISSUE_NAME)
dat_all_prep2 <- map_dfr(dat_all_prep1_list, leftcensored:::lc_flag1, show_result = FALSE)

dat_all_prep2_list <- dat_all_prep2 %>% split(.$PARAM, .$STATION_CODE, .$LATIN_NAME, .$TISSUE_NAME)
dat_all_prep3 <- map_dfr(dat_all_prep2_list, leftcensored:::lc_flag2, show_result = FALSE)

```


### e. Make dat_series  

- One line per time series  

```{r}

# version of max() that tolerates being given an x with length zero without warning
max_warningless <- function(x)
  ifelse(length(x)==0, NA, max(x))

# TEST
# sel <- c(F,F,T,T,F)
# max_warningless((1:5)[sel])
# sel <- rep(FALSE,5)
# max_warningless((1:5)[sel])

  
dat_series <- dat_all_prep3 %>%
  group_by(Substance.Group, PARAM, STATION_CODE, TISSUE_NAME, LATIN_NAME, x) %>%
  summarise(
    N = n(),
    N_over_LOQ = sum(uncensored == 1),
    P_over_LOQ = N_over_LOQ/N,
    .groups = "drop") %>%
  group_by(Substance.Group, PARAM, STATION_CODE, TISSUE_NAME, LATIN_NAME) %>%
  summarise(
    First_year = min(x),
    Last_year = max(x),
    N_years = n(),
    N_years_10yr = length(unique(x[x >= (last_year-10)])),
    Years_over_LOQ = sum(N_over_LOQ > 0),
    Last_year_over_LOQ = max_warningless(x[N_over_LOQ > 0]),
    .groups = "drop") %>% 
  filter(Last_year >= last_year) %>%
  mutate(
    Trend_model = case_when(
      Years_over_LOQ <= 1 ~ "No model",
      Years_over_LOQ %in% 2 & N_years %in% 2 ~ "No model",
      Years_over_LOQ %in% 2:4 & N_years >= 3 ~ "Mean",
      Years_over_LOQ %in% 5:6 ~ "Linear",
      Years_over_LOQ %in% 7:9 ~ "Smooth, k_max=3",
      Years_over_LOQ %in% 10:14 ~ "Smooth, k_max=4",
      Years_over_LOQ >= 15 ~ "Smooth, k_max=5"),
    Trend_model = factor(
      Trend_model,
      levels = c("No model", "Mean", "Linear", 
                 "Smooth, k_max=3", "Smooth, k_max=4", "Smooth, k_max=5")),
    k_max = case_when(
      Trend_model %in% "No model" ~ as.numeric(NA),
      Trend_model %in% "Mean" ~ 1,
      Trend_model %in% "Linear" ~ 2,
      Trend_model %in% "Smooth, k_max=3" ~ 3,
      Trend_model %in% "Smooth, k_max=4" ~ 4,
      Trend_model %in% "Smooth, k_max=5" ~ 5)
    )
      
nrow(dat_series)

table(dat_series$Trend_model)
# xtabs(~Substance.Group + Trend_model,  dat_series)
  

```



### f. Statistics per group  
```{r}

dat_series %>%
  mutate(
    Substance.Group = substr(Substance.Group, 1,14)) %>%
  count(Substance.Group, Trend_model) %>%
  pivot_wider(Substance.Group, names_from = Trend_model, values_from = n, values_fill = 0,
              names_sort= TRUE)

```



### g. Last_year_over_LOQ  
```{r}

# Last_year_over_LOQ vs Last_year

xtabs(~Last_year + Last_year_over_LOQ, dat_series)

```

### h. Data series to run  
```{r}

dat_series_trend <- dat_series %>%
  filter(!Trend_model %in% "No model") 

```

### i. Save  
```{r}

saveRDS(dat_series, "Data/125_dat_series.rds")
saveRDS(dat_series_trend, "Data/125_dat_series_trend.rds")
saveRDS(dat_all_prep3, "Data/125_dat_all_prep3.rds")

```


## 3. Test  

### Single series  
```{r}

# param <- "AG"
# station_code <- "30A"
# param <- "HG"
# station_code <- "30B"

param <- "PB"
station_code <- "02B"

param <- "MCCP eksl. LOQ"
station_code <- "71B"

data_prep <- dat_all_prep3 %>%
  filter(PARAM == param & STATION_CODE == station_code)

i <- with(dat_series_trend, which(PARAM == param & STATION_CODE == station_code))
i

lc_plot(data_prep)

last_year_over_LOQ <- dat_series %>%
  filter(PARAM == param & STATION_CODE == station_code) %>% # View
  pull(Last_year_over_LOQ)

k_max <- dat_series %>%
  filter(PARAM == param & STATION_CODE == station_code) %>%
  pull(k_max)
k_values <- 1:k_max
# k_values <- 2:k_max

raftery <- FALSE

if (FALSE){
  
  # Test for a single 'k' value 
  
  # debugonce(leftcensored::lc_fixedsplines_tp)
  check <- leftcensored::lc_fixedsplines_tp(
    data = data_prep, 
    k = 5, 
    normalize = FALSE, raftery = raftery, measurement_error = "Uncertainty", 
    predict_x = seq(min(data_prep$x), max(data_prep$x), by = 0.25), 
    reference_x = last_year_over_LOQ, set_last_equal_x = last_year_over_LOQ)
  View(check$plot_data)
  
}

if (FALSE){
  
  # Test for all 'k' values ('k_values') 
  
  results_all <- purrr::map(
    k_values, 
    ~leftcensored::lc_fixedsplines_tp(
      data = data_prep, 
      k = .x, 
      normalize = FALSE, raftery = raftery, measurement_error = "Uncertainty", 
      predict_x = seq(min(data_prep$x), max(data_prep$x)), 
      reference_x = last_year_over_LOQ, set_last_equal_x = last_year_over_LOQ)
  )
  
}

# lc_plot(data_prep)
lc_plot(data_prep, results = results_all, facet = "wrap")

```

### get_splines_results_seriesno  

```{r, results='hide', message=FALSE, warning=FALSE}

get_splines_results_seriesno_s(972, 
                             data = dat_all_prep3, 
                             data_series = dat_series_trend, 
                             foldername = "Data/125_results_2021", 
                             raftery = FALSE)

# debugonce(get_splines_results_seriesno)
get_splines_results_seriesno_s(52, 
                             data = dat_all_prep3, 
                             data_series = dat_series_trend, 
                             foldername = "Data/125_results_2021_01",  # test site 
                             raftery = TRUE)

```

### Check result  
```{r}

i <- 58
fn <- sprintf("trend_%04i.rda", i)
check <- readRDS(paste0("Data/125_results_2021/", fn))

str(check, 1)

get_pointdata <- function(seriesno, data, data_series){
  subset(data, 
         PARAM %in% data_series$PARAM[seriesno] & 
           STATION_CODE %in% data_series$STATION_CODE[seriesno] & 
           TISSUE_NAME %in% data_series$TISSUE_NAME[seriesno] &
           LATIN_NAME %in% data_series$LATIN_NAME[seriesno])
  
}

# debugonce(get_pointdata)
df_points <- get_pointdata(i, data = dat_all_prep3, data_series = dat_series_trend)

ggplot(check$plot_data, aes(x, y)) +
  geom_ribbon(aes(ymin = y_q2.5, ymax = y_q97.5), fill = "lightblue") +
  geom_point(data = df_points) +
  geom_point(data = df_points, aes(y = threshold), shape = 6) +
  geom_line()

```


## 4. Analysing time trends and saving results    

- We save results as R files as we go, in case something goes wrong  

### Run analyses using doParallel  

```{r, results='hide'}

if (FALSE){
# if (T){
  
  # Do only once
  future::availableCores()
  # 4 / 16 / 64 
  cl <- makeCluster(64)
  registerDoParallel(cores = 64)
  
}

#
# Parallel 
#

# From section 7:
# series_no <- c(ser1, ser2)

range(series_no)
length(series_no) # 1507

# Note folder name!

folder_results <- "Data/125_results_2021_02"
check_contents <- dir(folder_results)

if (length(check_contents) > 0){
  warning("You are writing to a folder which already contains ", length(check_contents), ". THESE WILL BE OVERWRITTEN.")
}

t0 <- Sys.time()
result <- foreach(i = series_no, 
                  .export = c("dat_all_prep3","dat_series_trend")) %dopar%
                   get_splines_results_seriesno_s(i, 
                                 dat_all_prep3, dat_series_trend, foldername = folder_results,
                                 raftery = TRUE)
t1 <- Sys.time()
t1-t0
# 30 min for 100 on 16 cores  
# 4.8 hours for 1960 on 64 cores



```

## 5. Check results  


### Read files  

```{r}

fns <- dir(folder_results, full.names = TRUE) %>% sort()
result_list <-lapply(fns, readRDS)
length(fns)

fileinfo <- file.info(fns)
# fileinfo
fileinfo_no <- substr(rownames(fileinfo)[1], nchar(folder_results) + 8, nchar(folder_results) + 11)

```

### Extract data frame for "successes"  

- Meaning that fitting worked (DIC exists)

```{r}

jags_finished <- map_lgl(result_list, ~!is.null(.x$k_values_ok))
ok <- map_lgl(result_list, ~!is.null(.x$DIC))

plotno <- map_dbl(result_list, "seriesno")
PARAM <- map_chr(result_list, "PARAM")
STATION_CODE <- map_chr(result_list, "STATION_CODE")
TISSUE_NAME <- map_chr(result_list, "TISSUE_NAME")
LATIN_NAME <- map_chr(result_list, "LATIN_NAME")
k_sel <- NA
k_sel[ok] <- map_int(result_list[ok], "k_sel")

dat_success <- data.frame(ok, jags_finished, plotno, PARAM, STATION_CODE, TISSUE_NAME, LATIN_NAME, k_sel)

tail(dat_success, 100)
plot(dat_success$jags_finished)
check <- plotno == as.numeric(fileinfo_no)
if (sum(check) == 1){
  dat_success <- dat_success %>%
  bind_cols(fileinfo %>% select(mtime, size))
} else {
  warning("fileinfo not in the same order")
}

```


### Plot a single series  
```{r}

tsplot_seriesno(58)

```

### Check one group of compounds  

```{r}

pno <- dat_success %>%
  filter(PARAM == "MCCP eksl. LOQ" & ok) %>%
  pull(plotno)

df_modelfit <- map_dfr(pno, extract_modelfit_data, folder = folder_results)
df_rawdata <- map_dfr(pno, extract_raw_data)

ggplot(df_modelfit, aes(x, y)) +
  geom_ribbon(aes(ymin = y_q2.5, ymax = y_q97.5), fill = "lightblue") +
  geom_point(data = df_rawdata %>% filter(!is.na(y))) +
  geom_point(data = df_rawdata %>% filter(!is.na(threshold)), aes(y = threshold), shape = 6) +
  geom_line() +
  facet_wrap(vars(STATION_CODE), scales = "free_y")

```

## 6. Check Rule1 and Rule2   

- Rule 1. Time series should be truncated from the left until Nplus/N >= 0.5      
- Rule 2. If a linear/smooth trend is fitted, the first year must be non-censored     
- Forgot to think of these when the estimations were ran  

```{r}

df_rule1 <- dat_all_prep3 %>%
  group_by(PARAM, STATION_CODE, TISSUE_NAME, LATIN_NAME) %>%
  summarise(Rule1_first = first(Rule1)) 
table(df_rule1$Rule1_first)

df_rule2 <- dat_all_prep3 %>%
  group_by(PARAM, STATION_CODE, TISSUE_NAME, LATIN_NAME) %>%
  summarise(Rule2_first = first(Rule2)) 
table(df_rule2$Rule2_first)

dat_success <- dat_series_trend %>%
  left_join(df_rule1) %>%
  left_join(df_rule2) 

table(dat_success$Rule1_first)  # 6   - should be run again
table(dat_success$Rule2_first)  # 20  - should be run again

```
## 7. Run the rest   

- To use if your analyses were interrupted  

```{r}

# Series not run at all   

ser_all <- 1:nrow(dat_series_trend)
ser1 <- ser_all[!ser_all %in% dat_success$plotno]
length(ser1)
# head(ser1, 100)
# tail(ser1, 100)

# Series not finished     
ser2 <- dat_success %>%
  filter(!jags_finished) %>%
  pull(plotno)

length(ser2)

# used in 4

```

